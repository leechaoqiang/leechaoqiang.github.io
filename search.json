[{"title":"Dify vs Coze vs n8n三大AI自动化工具，到底哪个最好用？","url":"http://www.vincentli.top/2025/04/15/comparator-analysis-with-dify-coze-n8n/","content":"&nbsp;&nbsp;在AI Agent应用爆发式增长的2025年，快速搭建智能自动化工作流、高效落地AI Agent已成为开发者和企业的核心诉求。面对市面上三大主流平台 ——n8n、Dify、Coze—— 各自瞄准不同场景，我们到底选择哪一个比较合适呢？本文为你一网打尽这三大工具的对比测评、经验总结与实际应用建议。以下是Dify、Coze、n8n三大工具的深度对比分析，结合核心功能、适用场景与局限性：\n\n一、核心能力对比\n\n\n维度\nDify\nCoze\nn8n\n\n\n\n\n定位\n企业级AI应用开发平台\n低代码对话机器人搭建工具\n自动化工作流集成平台\n\n\n技术门槛\n中高（需技术背景）\n极低（拖拽式界面）\n中高（需API集成知识）\n\n\n部署方式\n开源/私有化部署\n仅云端托管\n开源/自托管或云端\n\n\n多模型支持\n√（接入Llama2、GPT等）\n√（内置豆包、GPT-4o等）\n×（依赖外部API调用）\n\n\n工作流复杂度\n复杂流程支持（多步骤/条件分支）\n基础工作流（轻量级任务）\n超强集成（连接1000+应用）\n\n\n成本模型\n开源免费（自备算力）\n基础免费（高级功能付费）\n开源免费（云版按用量收费）\n\n\n\n\n二、典型场景推荐\nDify  \n\n✅ 企业级定制：需私有化部署的金融分析、多语言客服系统；  \n✅ 复杂AI工作流：如多模态票据识别（条件分支+变量聚合）；  \n❌ 不适合：快速原型验证或非技术团队使用。\n\n\nCoze  \n\n✅ 快速搭建对话应用：15分钟内创建电商客服、社交媒体机器人；  \n✅ 字节生态集成：抖音、飞书场景的语音助手；  \n❌ 局限性：无法私有部署，企业数据安全顾虑。\n\n\nn8n  \n\n✅ 跨系统自动化：连接CRM/邮件/数据库的批处理任务；  \n✅ API密集型场景：定时数据同步、跨平台通知提醒；  \n❌ 不足：AI原生能力弱，需额外集成语言模型。\n\n\n\n\n三、关键缺陷警示\nDify：配置繁琐，学习曲线陡峭（需调试工作流节点）；  \nCoze：云服务绑定，高级API调用需订阅；  \nn8n：免费版有执行次数限制，复杂逻辑需编码扩展。\n\n\n四、选型决策树\n\n总结：技术团队选Dify构建复杂AI系统；业务人员用Coze试水对话交互；IT运维团队通过N8n实现跨系统自动化。三者互补，实际中可组合使用（如n8n+Dify）。\n\n","categories":["博客","AI","人工智能"],"tags":["人工智能","dify","coze","n8n","编程辅助","ai"]},{"title":"智能生产之AI辅助编程工具对比分析及使用场景推荐","url":"http://www.vincentli.top/2025/03/14/ai-code-tool-recommond/","content":"&nbsp;&nbsp;你还在用传统的编程工具进行编程么？高效的AI辅助编程时代以及来临，推荐几款主流AI辅助编程工具，我会同时对比分析各自的优缺点和使用场景1. 通义灵码（阿里巴巴）● 来源：阿里云研发。● 优点：中文交互友好，支持行级/函数级代码补全、自然语言生成代码、单元测试生成；企业级数据安全，适合金融、政府等敏感项目；对阿里云API及云服务场景深度优化。● 缺点：对海外框架（如Svelte）兼容性较弱；需手动切换模型以应对生成质量波动。● 适用场景：国内企业级项目、阿里云生态开发、编程新手学习。\n2. Marscode（豆包）● 来源：豆包（字节豆包）。● 优点：完全免费且云端即开即用，无需本地配置；支持自然语言交互和Webview调试工具，适合轻量级开发。● 缺点：功能单一，缺乏代码解释、测试生成等高级功能；代码提示的实时性较弱。● 适用场景：个人开发者快速验证原型、小型项目开发。\n3. Trae（字节跳动）● 来源：字节跳动研发。● 优点：支持多模态交互（如上传图像生成前端代码）；内置Claude 3.5模型，原生中文界面交互流畅；支持项目级代码库分析，适合复杂需求拆解。● 缺点：语言支持较少（仅主流语言），跨平台兼容性有限；仍处于Beta阶段，功能稳定性待提升。● 适用场景：前端页面快速生成、游戏开发、多模态需求分析。\n4. Copilot（GitHub/微软）● 来源：GitHub与OpenAI合作开发。● 优点：行业标杆，基于GPT-4模型，生成代码质量高；深度集成VS Code/JetBrains等IDE，支持30+语言。● 缺点：付费门槛高（个人版10美元/月），企业版隐私争议大；中文支持较弱，对国内云服务适配有限。● 适用场景：专业开发者高效编码、海外框架（如React/Vue）项目。\n5.Cursor● 来源：基于VS Code二次开发的AI原生IDE，独立团队运营。● 优点：    ○  智能重构能力：支持划词修改和全局上下文引用，优化代码结构效率；    ○ 多语言支持：覆盖Python、Java、JavaScript等主流语言，生成代码质量较高；    ○  原生IDE体验：深度集成开发环境，提供实时错误检测与修复建议。● 缺点：    ○ 复杂逻辑处理不足：生成代码在复杂业务场景下可能需人工调整；    ○ 学习成本较高：需熟悉快捷键和交互模式才能高效使用。    ○ 适用场景：代码重构、多语言项目开发、快速原型迭代。\n总结对比表\n\n\n工具\n适合人群\n核心优势\n主要局限\n\n\n\n\n通义灵码\n国内企业开发者\n安全合规、阿里云生态集成；企业级数据安全、多语言场景优化\n海外框架支持弱\n\n\nMarscode\n个人/轻量项目开发者\n免费、云端即用\n功能单一\n\n\nTrae\n前端/多模态开发者\n图像生成代码、中文交互友好\n跨平台支持有限\n\n\nCursor\n多语言/重构开发者\n智能代码重构、原生IDE体验\n复杂逻辑处理不足\n\n\nCopilot\n专业/海外项目开发者\n多语言支持、生成质量高\n付费及隐私风险\n\n\n\n场景推荐● 企业级全栈开发：通义灵码（后端+云服务） + Trae（前端生成）；● 个人快速验证：Marscode（轻量原型） + Cursor（代码优化）；● 复杂项目重构：Cursor（智能修改） + Copilot（高效补全）。\n后记以上信息综合自各工具官方文档及第三方实测数据，实际情况大家可以自己试试，选择满足自己场景的趁手的AI辅助工具，说不定就能做到事半功倍的效果了\n","categories":["博客","AI","人工智能"],"tags":["AI","AI编码","人工智能","辅助编程"]},{"title":"Golang安装说明","url":"http://www.vincentli.top/2021/04/16/golang-install-description/","content":"1.1安装 GoGo的三种安装方式Go有多种安装方式，你可以选择自己喜欢的。这里我们介绍三种最常见的安装方式：\n\nGo标准包安装：Go提供了方便的安装包，支持Windows、Linux、Mac等系统。这种方式适合快速安装，可根据自己的系统位数下载好相应的安装包，一路 next 就可以轻松安装了。推荐这种方式\n第三方工具安装：目前有很多方便的第三方软件包工具，例如 Ubuntu 的 apt-ge t和 wget、Mac 的 homebrew 等。这种安装方式适合那些熟悉相应系统的用户。\nGo源码安装：这是一种标准的软件安装方式。对于经常使用Unix类系统的用户，尤其对于开发者来说，从源码安装可以自己定制。\n\n最后，如果你想在同一个系统中安装多个版本的Go，你可以参考第三方工具GVM，这是目前在这方面做得最好的工具，除非你知道怎么处理。\nGo标准包安装Go 提供了每个平台打好包的一键安装，这些包默认会安装到如下目录：/usr/local/go (Windows系统：c:\\Go)，当然你可以改变他们的安装位置，但是改变之后你必须在你的环境变量中设置如下信息：\nexport GOROOT=$HOME/go  \nexport GOPATH=$HOME/gopath (可选配置)\nexport PATH=$PATH:$GOROOT/bin:$GOPATH/bin\n上面这些命令对于Mac和Unix用户来说最好是写入.bashrc或者.zshrc或者.bash_profile文件，对于windows用户来说当然是写入环境变量。    \n如何判断自己的操作系统是32位还是64位？(建议直接跳过, 现在操作系统一般都是 64位)我们接下来的Go安装需要判断操作系统的位数，所以这小节我们先确定自己的系统类型。\nWindows系统用户请按Win+R运行cmd，输入systeminfo后回车，稍等片刻，会出现一些系统信息。在“系统类型”一行中，若显示“x64-based PC”，即为64位系统；若显示“X86-based PC”，则为32位系统。\nMac系统用户建议直接使用64位的，因为Go所支持的Mac OS X版本已经不支持纯32位处理器了。\nLinux系统用户可通过在Terminal中执行命令arch(即uname -m)来查看系统信息：\n64位系统显示    x86_64\n32位系统显示    i386\nMac 安装访问下载地址，64位系统下载 go1.17.8.darwin-amd64.pkg，双击下载文件，一路默认安装点击下一步，这个时候go已经安装到你的系统中，默认已经在PATH中增加了相应的~/go/bin, 这个时候打开终端，输入go version\n显示如下\ngo version go1.17.8 darwin/amd64\n看到类似上面提示说明已经安装成功\n如果出现go的Usage信息，那么说明go已经安装成功了；如果出现该命令不存在，那么可以检查一下自己的PATH环境变中是否包含了go的安装目录。\nLinux 安装访问下载地址，64位系统下载go1.17.8.linux-arm64.tar.gz，32位系统下载go1.17.8.linux-386.tar.gz，\n直接使用 tar -C /usr/local -xzf go1.17.8.linux-amd64.tar.gz 解压到 local 目录设置PATH，export PATH=$PATH:/usr/local/go/bin\n假定你想要安装Go的目录为 $GO_INSTALL_DIR，后面替换为相应的目录路径。解压缩tar.gz包到安装目录下：tar zxvf go1.17.8.linux-amd64.tar.gz -C $GO_INSTALL_DIR。\n设置PATH，export PATH=$PATH:$GO_INSTALL_DIR/go/bin\n然后执行go\n\n图1.2 Linux系统下安装成功之后执行go显示的信息\n如果出现go的Usage信息，那么说明go已经安装成功了；如果出现该命令不存在，那么可以检查一下自己的PATH环境变中是否包含了go的安装目录。\nWindows 安装访问Golang 下载页，64 位请选择名称中包含 windows-amd64 的, 32 位请选择名称中包含 windows-386 的 msi 安装包。下载好后运行，不要修改默认安装目录 C:\\Go\\，若安装到其他位置会导致不能执行自己所编写的 Go 代码。安装完成后默认会在环境变量 Path 后添加 Go 安装目录下的 bin 目录 C:\\Go\\bin\\，并添加环境变量 GOROOT，值为 Go 安装根目录 C:\\Go\\ 。\n验证是否安装成功\n在运行中输入 cmd 打开命令行工具，在提示符下输入 go，检查是否能看到 Usage 信息。输入 cd %GOROOT%，看是否能进入 Go 安装目录。若都成功，说明安装成功。\n不能的话请检查上述环境变量 Path 和 GOROOT 的值。若不存在请卸载后重新安装，存在请重启计算机后重试以上步骤。\n第三方工具安装GVMgvm是第三方开发的Go多版本管理工具，类似ruby里面的rvm工具。使用起来相当的方便，安装gvm使用如下命令：\nbash &lt; &lt;(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)\n安装完成后我们就可以安装go了：\ngvm install go1.17.8gvm use go1.17.8\n也可以使用下面的命令，省去每次调用gvm use的麻烦：        gvm use go1.17.8 –default\n执行完上面的命令之后GOPATH、GOROOT等环境变量会自动设置好，这样就可以直接使用了。\napt-getUbuntu是目前使用最多的Linux桌面系统，使用apt-get命令来管理软件包，我们可以通过下面的命令来安装Go，为了以后方便，应该把 git mercurial 也安装上：\nsudo apt-get install python-software-propertiessudo add-apt-repository ppa:gophers/gosudo apt-get updatesudo apt-get install golang-stable git-core mercurial\nwgetwget https://studygolang.com/dl/golang/go1.17.8.linux-amd64.tar.gzsudo tar -xzf go1.17.8.linux-amd64.tar.gz -C /usr/local \n配置环境变量:\nexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBINexport GOPATH=$HOME/gopath (可选设置)\n或者使用: \nsudo vim /etc/profile \n并添加下面的内容：\nexport GOROOT=/usr/local/goexport GOBIN=$GOROOT/binexport PATH=$PATH:$GOBINexport GOPATH=$HOME/gopath (可选设置)\n重新加载 profile 文件\nsource /etc/profile \nhomebrewhomebrew是Mac系统下面目前使用最多的管理软件的工具，目前已支持Go，可以通过命令直接安装Go，为了以后方便，应该把 git mercurial 也安装上：\n1.安装homebrew\n/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot;\n2.安装go\nbrew update &amp;&amp; brew upgradebrew install gobrew install gitbrew install mercurial // 可选安装\nGo源码安装Go 1.5彻底移除 C 代码，Runtime、Compiler、Linker均由Go编写,实现自举。只需要安装了上一个版本,即可从源码安装。\n在Go 1.5前,Go的源代码中，有些部分是用Plan 9 C和AT&amp;T汇编写的，因此假如你要想从源码安装，就必须安装C的编译工具。\n在Mac系统中，只要你安装了Xcode，就已经包含了相应的编译工具。\n在类Unix系统中，需要安装gcc等工具。例如Ubuntu系统可通过在终端中执行sudo apt-get install gcc libc6-dev来安装编译工具。\n在 Windows 系统中，你需要安装 MinGW，然后通过 MinGW 安装 gcc，并设置相应的环境变量。\n你可以直接去官网下载源码，找相应的goVERSION.src.tar.gz的文件下载，下载之后解压缩到$HOME目录，执行如下代码：\ncd go/src\n./all.bash\n运行all.bash后出现”ALL TESTS PASSED”字样时才算安装成功。\n上面是Unix风格的命令，Windows下的安装方式类似，只不过是运行all.bat，调用的编译器是MinGW的gcc。\n如果是Mac或者Unix用户需要设置几个环境变量，如果想重启之后也能生效的话把下面的命令写到.bashrc或者.zshrc里面，\nexport GOPATH=$HOME/gopath\nexport PATH=$PATH:$HOME/go/bin:$GOPATH/bin\n如果你是写入文件的，记得执行bash .bashrc或者bash .zshrc使得设置立马生效。\n如果是window系统，就需要设置环境变量，在path里面增加相应的go所在的目录，设置gopath变量。\n当你设置完毕之后在命令行里面输入go，看到如下图片即说明你已经安装成功\n\n图1.1 源码安装之后执行Go命令的图\n如果出现Go的Usage信息，那么说明Go已经安装成功了；如果出现该命令不存在，那么可以检查一下自己的PATH环境变中是否包含了Go的安装目录。\n从go 1.8开始，GOPATH 环境变量现在有一个默认值，如果它没有被设置。 它在Unix上默认为$HOME/go,在Windows上默认为%USERPROFILE%/go。从 Go1.11 开始, Go 官方加入了 Go Module 支持.\n\n关于上面的 GO Module 和 GOPATH 将在下面小节详细讲解\n\n## \n","categories":["Golang学习笔记"],"tags":["Golang"]},{"title":"SpringWebFlux响应式编程从入门到实践","url":"http://www.vincentli.top/2021/03/04/springwebflux-from-zero-to-deep/","content":"Spring Boot 2.0简介\nSpring Boot （Boot 顾名思义，是引导的意思）框架是用于简化 Spring 应用从搭建到开发的过程。应用开箱即用，只要通过一个指令，包括命令行 java -jar 、SpringApplication 应用启动类 、 Spring Boot Maven 插件等，就可以启动应用了。\n另外，Spring Boot 强调只需要很少的配置文件，所以在开发生产级 Spring 应用中，让开发变得更加高效和简易。目前，Spring Boot 版本是 2.x 版本，而且Spring Boot 包括 了WebFlux。\n\nSpring Boot 2.0 WebFlux\n什么是 Reactive Streams？\nReactive Streams 是 JVM 中面向流的库标准和规范\n处理可能无限数量的元素\n按顺序处理\n组件之间异步传递\n强制性非阻塞背压（Backpressure）\n\nBackpressure(背压)​     背压是一种常用策略，使得发布者拥有无限制的缓冲区存储元素，用于确保发布者发布元素太快时，不会去压制订阅者。\nReactive Streams（响应式流）\n发布者：发布元素到订阅者\n订阅者：消费元素\n订阅：在发布者中，订阅被创建时，将与订阅者共享\n处理器：发布者与订阅者之间处理数据\n\n什么是Reactive programming响应式编程？​     响应式编程是基于异步和事件驱动的非阻塞程序，只是垂直通过在 JVM 内启动少量线程扩展，而不是水平通过集群扩展，是一个编程范例。\nSpring Webflux是由什么实现的Spring Boot Webflux 就是基于 Reactor 实现的。Spring Boot 2.0 包括一个新的 spring-webflux 模块。该模块包含对响应式 HTTP 和 WebSocket 客户端的支持，以及对 REST，HTML 和 WebSocket 交互等程序的支持。\nReactor 一般提供两种响应式 API\nMono：实现发布者，并返回 0 或 1 个元素\nFlux：实现发布者，并返回 N 个元素\n\nSpring Boot Webflux 有两种编程模型实现，一种类似 Spring MVC 注解方式，另一种是使用其功能性端点方式。\nSpring Boot 2.0 WebFlux 特性响应式 API​       Reactor 框架是 Spring Boot Webflux 响应库依赖，通过 Reactive Streams 并与其他响应库交互。提供了 两种响应式 API : Mono 和 Flux。一般是将 Publisher 作为输入，在框架内部转换成 Reactor 类型并处理逻辑，然后返回 Flux 或 Mono 作为输出。\n编程模型​      Spring 5 web 模块包含了 Spring WebFlux 的 HTTP 抽象。类似 Servlet API , WebFlux 提供了 WebHandler API 去定义非阻塞 API 抽象接口。可以选择以下两种编程模型实现：-注解控制层。和 MVC 保持一致，WebFlux 也支持响应性 @RequestBody 注解。-功能性端点。基于 lambda 轻量级编程模型，用来路由和处理请求的小工具。和上面最大的区别就是，这种模型，全程控制了请求 – 响应的生命流程\n内嵌容器​     跟 Spring Boot 大框架一样启动应用，但 WebFlux 默认是通过 Netty 启动，并且自动设置了默认端口为 8080。另外还提供了对 Jetty、Undertow 等容器的支持。开发者自行在添加对应的容器 Starter 组件依赖，即可配置并使用对应内嵌容器实例。但是要注意，必须是 Servlet 3.1+ 容器，如 Tomcat、Jetty；或者非 Servlet 容器，如 Netty 和 Undertow。\nSpring Boot 2.0 WebFlux 组件\n Spring Boot WebFlux 官方提供了很多 Starter 组件，每个模块会有多种技术实现选型支持，来实现各种复杂的业务需求：\n\nWeb：Spring WebFlux\n模板引擎：Thymeleaf\n存储：Redis、MongoDB、Cassandra、Mysql(r2dbc)\n内嵌容器：Tomcat、Jetty ; Netty(非 Servlet 容器)、Undertow(非 Servlet 容器)\n\n\nSpring Webflux实践开发运行环境要求：\n\nJDK 1.8+ Spring Boot 2.x 要求 JDK 1.8 环境及以上版本。另外，Spring Boot 2.x 只兼容 Spring Framework 5.0 及以上版本。\nMaven 3.2+ 为 Spring Boot 2.x 提供了相关依赖构建工具是 Maven，版本需要 3.2 及以上版本。\nIntelliJ IDEA IntelliJ IDEA （简称 IDEA）是常用的开发工具，目前最新版本2020.3.2,推荐使用旗舰版，当然社区版也可以。\n\n\n构建项目骨架Spring Initializr 快速构建项目骨架在浏览器中打开域名https://start.spring.io/，然后按照如下步骤操作:\n\n\n第一步，选择 Maven 或者 Gradle 构建工具，开发语言 Java 、Kotlin 或者 Groovy，最后确定 Spring Boot 版本号。\n第二步，输入 Maven 工程信息，即项目组 groupId 和名字 artifactId。这里对应 Maven 信息为：groupId：com.vincentartifactId：springboot-webflux-practise这里默认版本号 version 为 0.0.1-SNAPSHOT 。三个属性在 Maven 依赖仓库是唯一标识的。\n第三步，选择工程需要的 Starter 组件和其他依赖。最后点击生成按钮，即可获得骨架工程压缩包。这里快速入门，只要选择 Reactive Web 即可。\n\n生成项目配置 POM 依赖检查\nspring-boot-starter-webflux 依赖，是我们核心需要学习 webflux 的包，里面默认包含了 spring-boot-starter-reactor-netty 、spring 5 webflux 包。也就是说默认是通过 netty 启动的。\nreactor-test、spring-boot-starter-test 两个依赖搭配是用于单元测试。\nspring-boot-maven-plugin 是 Spring Boot Maven 插件，可以运行、编译等调用。\n\nspringboot-webflux-practise\n\nspringboot-webflux-practise是webflux的一个学习练习demo工程.\n\n其中Spring WebFlux有两种版本：基于功能和注释。\n\nCURD的demo(mysql)\n\nWebFlux集成Thymeleaf\n\nWebFlux集成redis\n\n\n\n基于注释非常接近Spring MVC模型(CRUD)：UserFluxController\n基于功能版本：HelloRouter,HelloHandler是路由处理\nWebFlux集成Thymeleaf：UserThymleafController\n\nwebFlux集成redis：UserFluxReactiveController\n\n服务启动运行SpringbootWebfluxPractiseApplication的main()方法\n示例源码下载地址：https://github.com/leechaoqiang/springboot-webflux-practise\n\n\n\n","categories":["Spring","SpringWebFlux","博客","SpringCloud"],"tags":["SpringBoot","SpringCloud","Spring","SpringWebFlux"]},{"title":"uName类似首字符小写属性Json序列化接收不到数据问题及解决办法","url":"http://www.vincentli.top/2021/03/01/lowcase-start-word-json-serialize-error/","content":"问题背景最近因为发现有一个表字段被设计成u_name，然后用工具生产的实体的属性字段是uName，就是首字母是小写，第二个字母是大写的这类属性，然后我们关于这个字段的一个接口的请求对象VO中字段也是沿用的uName。然后postman测试提交数据的时候，json请求体中字段属性也是uName。\n我们这个项目是采用SpringBoot 2.1.5.RELEASE的，json序列化的工具是jackson，版本是2.9.8，这可能是jackson对于这类字段属性json序列号支持不太友好的地方。\n解决方案\n采用@JsonProperty注解给uName属性字段定义json字段别名./** * 姓名 */@JsonProperty(&quot;uName&quot;)private String uName;\n给请求VO实体添加@JsonAutoDetect注解@Data@JsonAutoDetect(fieldVisibility=JsonAutoDetect.Visibility.ANY, getterVisibility=JsonAutoDetect.Visibility.NONE)public class UserVO &#123;    /**     - 姓名     */     private String uName;&#125;\n\n\n注解说明@JsonAutoDetect该注解的作用是配置自动识别的类型：\n有以下四个属性：\n\ngetterVisibility：定义getter方法的识别范围。\nisGetterVisibility：定义is-getter方法的识别范围(boolean类型的getter，很少用)。\nsetterVisibility：定义setter方法的识别范围。\ncreatorVisibility：定义构造器识别范围。\nfieldVisibility：定义属性识别范围。识别范围是一个枚举，包括：\nVisibility.ANY：表示从 private 到 public 修饰，都可识别。\nVisibility.NON_PRIVATE：表示除 private 修饰不可识别，其他都识别。\nVisibility.PROTECTED_AND_PUBLIC：protected 和 public都识别。\nVisibility.PUBLIC_ONLY：仅 public 可见。\nVisibility.NONE：所有皆不可见。\nVisibility.DEFAULT：缺省，所有被 public 修饰的属性、 getter 和所有 setter皆可见。\n\n","categories":["SpringBoot","Java"],"tags":["Java","SpringBoot","Json","jackson"]},{"title":"Java快起开启一个gRPC示例","url":"http://www.vincentli.top/2021/01/22/quick-start-gRPC-in-Java-simple/","content":"概述在gRPC中，客户机应用程序可以直接调用另一台机器上的服务器应用程序上的方法，就好像它是本地对象一样，这使得您更容易创建分布式应用程序和服务。与许多RPC系统一样，gRPC基于定义服务的思想，指定可以使用参数和返回类型远程调用的方法。在服务器端，服务器实现此接口并运行gRPC服务器来处理客户端调用。在客户端，客户端有一个存根（在某些语言中称为客户端），它提供与服务器相同的方法。\n\ngRPC客户端和服务器可以在各种环境中运行并相互通信——从谷歌内部的服务器到您自己的桌面——并且可以用gRPC支持的任何语言编写。因此，例如，您可以轻松地用Java创建一个gRPC服务器，客户端使用Go、Python或Ruby。此外，最新的谷歌API将有gRPC版本的界面，让您可以轻松地将谷歌功能构建到应用程序中。\n 默认情况下，gRPC使用Protocol Buffers，这是Google用于序列化结构化数据的成熟开源机制（尽管它可以与JSON等其他数据格式一起使用）。\n快速开始一个Java的gRPC的应用环境要求\n安装好JDK(需要7或者更高的版本)\n\n安装Gradle(3.5及以上)\n\n\n获得样例代码\n下载grpc-java的压缩包, 或者克隆github的仓库地址：\ngit clone -b v1.42.1 https://github.com/grpc/grpc-java\n\n进入examples目录\ncd grpc-java/examples\n\n\n运行example\n编译client和server\n./gradlew installDist\n\n运行server\n    ./build/install/examples/bin/hello-world-server    io.grpc.examples.helloworld.HelloWorldServer start信息: Server started, listening on 50051\n\n在另外一个终端运行client\n    ./build/install/examples/bin/hello-world-client    io.grpc.examples.helloworld.HelloWorldClient greet信息: Will try to greet world ...io.grpc.examples.helloworld.HelloWorldClient greet信息: Greeting: Hello world\n\n\n以上的操作，我们刚刚使用gRPC运行了一个client-server应用程序。\n\n我们省略了本页中显示的客户端和服务器跟踪输出中的时间戳。\n\n更新gRPC服务\n在本节中，您将通过添加额外的服务器方法来更新应用程序。gRPC服务是使用协议缓冲区定义的。要了解有关如何在.proto文件中定义服务的更多信息，请参阅基础教程。现在，您需要知道的是服务器和客户端存根都有一个SayHello（）RPC方法，该方法从客户端获取HelloRequest参数并从服务器返回HelloReply，该方法的定义如下：\n\n// The greeting service definition.service Greeter &#123;  // Sends a greeting  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// The request message containing the user&#x27;s name.message HelloRequest &#123;  string name = 1;&#125;// The response message containing the greetingsmessage HelloReply &#123;  string message = 1;&#125;\n\n打开 src/main/proto/helloworld.proto 文件，然后添加一个新的SayHelloAgain() 方法，和SayHello()采用一样的请求参数和响应参数:\n\n// The greeting service definition.service Greeter &#123;  // Sends a greeting  rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;  // Sends another greeting  rpc SayHelloAgain (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// The request message containing the user&#x27;s name.message HelloRequest &#123;  string name = 1;&#125;// The response message containing the greetingsmessage HelloReply &#123;  string message = 1;&#125;\n\n记得保存文件\n\n更新应用的client和server构建示例时，构建过程将重新生成GreeterGrpc.java，其中包含生成的gRPC客户端和服务器类。这还会重新生成用于填充、序列化和检索请求和响应类型的类。\n但是，您仍然需要在示例应用程序的手写部分实现并调用新方法。\n更新Server\n在同一目录中，打开src/main/java/io/grpc/examples/helloworld/HelloWorldServer.java。按如下方式实施新方法：private class GreeterImpl extends GreeterGrpc.GreeterImplBase &#123;  @Override  public void sayHello(HelloRequest req, StreamObserver&lt;HelloReply&gt; responseObserver) &#123;    HelloReply reply = HelloReply.newBuilder().setMessage(&quot;Hello &quot; + req.getName()).build();    responseObserver.onNext(reply);    responseObserver.onCompleted();  &#125;  @Override  public void sayHelloAgain(HelloRequest req, StreamObserver&lt;HelloReply&gt; responseObserver) &#123;    HelloReply reply = HelloReply.newBuilder().setMessage(&quot;Hello again &quot; + req.getName()).build();    responseObserver.onNext(reply);    responseObserver.onCompleted();  &#125;&#125;\n\n\n更新Client在同一目录,打开src/main/java/io/grpc/examples/helloworld/HelloWorldClient.java. 按如下调用新的方法：\npublic void greet(String name) &#123;  logger.info(&quot;Will try to greet &quot; + name + &quot; ...&quot;);  HelloRequest request = HelloRequest.newBuilder().setName(name).build();  HelloReply response;  try &#123;    response = blockingStub.sayHello(request);  &#125; catch (StatusRuntimeException e) &#123;    logger.log(Level.WARNING, &quot;RPC failed: &#123;0&#125;&quot;, e.getStatus());    return;  &#125;  logger.info(&quot;Greeting: &quot; + response.getMessage());  try &#123;    response = blockingStub.sayHelloAgain(request);  &#125; catch (StatusRuntimeException e) &#123;    logger.log(Level.WARNING, &quot;RPC failed: &#123;0&#125;&quot;, e.getStatus());    return;  &#125;  logger.info(&quot;Greeting: &quot; + response.getMessage());&#125;\n运行已经更新后的应用服务像以前一样运行client和Server。从examples目录执行以下命令：\n\n编译client和Server\n./gradlew installDist\n\n运行server\n ./build/install/examples/bin/hello-world-server io.grpc.examples.helloworld.HelloWorldServer start信息: Server started, listening on 50051\n\n在另外一个终端运行client\n\n\n ./build/install/examples/bin/hello-world-client io.grpc.examples.helloworld.HelloWorldClient greet信息: Will try to greet world ... io.grpc.examples.helloworld.HelloWorldClient greet信息: Greeting: Hello world io.grpc.examples.helloworld.HelloWorldClient greet信息: Greeting: Hello againworld\n\n\n以上就是我们过一个简单的工作示例让大家开始使用Java中的gRPC，感觉也还是比较容易上手。\n参考文件\nIntroduction to gRPC\nThis guide gets you started with gRPC in Java with a simple working example.\n\n","categories":["gRPC","Java"],"tags":["Java","微服务","gRPC"]},{"title":"分布式配置中心技术选型以及我们推荐选择哪个？","url":"http://www.vincentli.top/2020/10/27/distribute-config-center-cmp-and-choose/","content":"目前新项目基本是微服务架构，关于配置的常规方案是将配置信息抽离写入 xml、properties文件中，然后随着应用一块打包发布。如果有开发、测试、预发、生产等多套环境，则通过配置各自独立的文件以区分不同的环境，维护起来特别麻烦。虽然具备了一定的扩展性，但每次配置参数变更都要重新启动或者发布应用，灵活性较差，所以我们需要一个统一的配置中心，以下是技术选型的对比。\n一、开源配置中心经过一段时间的整理，大概有以下几个开源配置中心：\n1、ApolloApollo（阿波罗）是2016年5月携程框架部门研发的开源的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。服务端基于Spring Boot和Spring Cloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。Java客户端不依赖任何框架，能够运行于所有Java运行时环境，同时对Spring/Spring Boot环境也有较好的支持。.Net客户端不依赖任何框架，能够运行于所有.Net运行时环境。\n2、Diamond（不在维护，这里就不作介绍了）\nDiamond是淘宝研发的分布式配置管理系统。使用Diamond可以让集群中的服务进程动态感知数据的变化，无需重启服务就可以实现配置数据的更。\n\n项目地址：https://github.com/gzllol/diamond\n\n3、Disconf\n专注于各种「分布式系统配置管理」的「通用组件」和「通用平台」, 提供统一的「配置管理服务」。2014年7月百度开源的配置管理中心，同样具备配置的管理能力，不过目前已经不维护了，最近的一次提交是两年前了。\n\n项目地址：https://github.com/knightliao/disconf\n\n4、spring-cloud/spring-cloud-config\n2014年9月开源，Spring Cloud 生态组件，可以和Spring Cloud体系无缝整合。\n\n项目地址：https://github.com/spring-cloud/spring-cloud-config\n\n5、Nacos\n2018年6月，阿里开源的配置中心，Nacos致力于帮助您发现、配置和管理微服务。Nacos提供了一组简单易用的特性集，帮助您快速实现动态服务发现、服务配置、服务元数据及流量管理。\n\n项目地址： https://github.com/alibaba/nacos\n\n\n二、配置中心对比1、功能特性\n先从功能层面来进行对比：\n\n\n\n功能特性\n重要性\nSpring Cloud Config\nApollo\nDisconf\nNacos\n\n\n\n\n静态配置管理\n高\n基于file\n支持\n支持\n支持\n\n\n动态配置管理\n高\n支持\n支持\n支持\n支持\n\n\n统一管理\n高\n无，需要github\n支持\n支持\n支持\n\n\n多环境\n中\n无，需要github\n支持\n支持\n支持\n\n\n本地配置缓存\n高\n无\n支持\n支持\n支持\n\n\n配置锁\n中\n支持\n不支持\n不支持\n不支持\n\n\n配置校验\n中\n无\n无\n无\n无\n\n\n配置生效时间\n高\n重启生效，或手动refresh生效\n实时\n实时\n实时\n\n\n配置更新推送\n高\n需要手工触发\n支持\n支持\n支持\n\n\n配置定时拉取\n高\n无\n支持\n配置更新目前依赖事件驱动， client重启或者server端推送操\n支持\n\n\n用户权限管理\n中\n无，需要github\n支持\n支持\n支持\n\n\n授权、审核、审计\n中\n无，需要github\n支持\n无\n支持\n\n\n配置版本管理\n高\nGit做版本管理\n界面上直接提供发布历史和回滚按钮\n操作记录有落数据库，但无查询接口\n界面操作，支持回滚\n\n\n配置合规检测\n高\n不支持\n支持（但还需完善）\n支持\n支持\n\n\n实例配置监控\n高\n需要结合spring admin    支持\n支持，可以查看每个配置在哪些机器上加载\n支持\n支持\n\n\n灰度发布\n中\n不支持\n支持\n不支持部分更新\n支持\n\n\n告警通知\n中\n不支持\n支持，邮件方式告警\n支持，邮件方式告警\n支持\n\n\n\n2、技术路线兼容性\n引入配置中心，需要考虑和现有项目的兼容性，以及是否引入额外的第三方组件。\n\n\n\n功能点\n优先级\nSpring Cloud Config\nApollo\nDisconf\nNacos\n\n\n\n\nSpringBoot支持\n高\n原生支持\n支持\n与spring boot无相关\n支持\n\n\nSpringCloud支持\n高\n原生支持\n支持\n与spring cloud无相关\n支持\n\n\n客户端支持\n低\nJava\nJava,.Net Go、Python、NodeJS、PHP、C++\nJava\nJava,Go,.Net,C++,Python等\n\n\n业务系统侵入性\n高\n侵入性弱\n侵入性弱\n侵入性弱，支持注解及xml方式\n侵入性弱\n\n\n依赖组件\n高\nEureka\nEureka\nzookeeper\n无\n\n\n\n3、可用性与易用性\n引入配置中心后，所有的应用都需要依赖配置中心，因此可用性需要重点关注。\n\n\n\n功能点\n优先级\nSpring Cloud Config\nApollo\nDisconf\nNacos\n\n\n\n\n单点故障(SPOF)\n高\n支持HA部署\n支持HA部署\n支持HA部署,高可用由zookeeper保证\n支持HA部署\n\n\n多数据中心部署\n高\n支持\n支持\n支持\n支持\n\n\n配置获取性能\n高\nunknown\n比较高（据官方说比Spring快）\n\n比较高\n\n\n配置界面\n中\n无，需要通过git操作\n统一界面\n统一界面\n统一界面\n\n\n\n三、结论综合来说，Nacos配置文件支持比较多的格式，支持yaml、text、json、xml、html、Properties，apollo只支持xml、text、Properties的格式，没有兼容spring boot中比较通用的yaml配置。虽然 Nacos支持多格式的配置文件，但是解析上没有Apollo做的好，Apollo虽然支持的配置格式较少，不过会进行解析，使每个配置看起来比较直观，修改的时候比较直观，可以对单个进行修改。\n另外，Apollo用户管理以及权限管理做的比较好和全面，适合做部门或者公司级的配置中心。Nacos比较简洁，权限这块目前还比较偏弱。Apollo的社区生态活跃，github最近一直都有活跃提交，而且文档也比较清晰和完善。另外使用的公司特别多，常见的坑基本都被踩完了，也经过了更多社区用户的验证，使用踩坑的几率会比较低。\n\n当然Nacos作为后起之秀，又有互联网大厂阿里巴巴做背书，目前市场活跃度也非常高，大家可以结合自家情况选择，如果想稳妥点建议选择Apollo。\nApollo 介绍Apollo（阿波罗）是一款可靠的分布式配置管理中心，诞生于携程框架研发部，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。\n服务端基于Spring Boot和Spring Cloud开发，打包后可以直接运行，不需要额外安装Tomcat等应用容器。\nJava客户端不依赖任何框架，能够运行于所有Java运行时环境，同时对Spring/Spring Boot环境也有较好的支持。\n.Net客户端不依赖任何框架，能够运行于所有.Net运行时环境。\n\n开源地址：https://github.com/ctripcorp/apollo\n\n特性基于配置的特殊性，Apollo在设计之初就立志于成为一个有治理能力的配置发布平台，目前提供了以下的特性：\n\n统一管理不同环境、不同集群的配置\nApollo提供了一个统一界面集中式管理不同环境（environment）、不同集群（cluster）、不同命名空间（namespace）的配置。\n同一份代码部署在不同的集群，可以有不同的配置，比如zk的地址等\n通过命名空间（namespace）可以很方便的支持多个不同应用共享同一份配置，同时还允许应用对共享的配置进行覆盖\n配置界面支持多语言（中文，English）\n\n\n\n\n配置修改实时生效（热发布）\n用户在Apollo修改完配置并发布后，客户端能实时（1秒）接收到最新的配置，并通知到应用程序。\n\n\n版本发布管理\n所有的配置发布都有版本概念，从而可以方便的支持配置的回滚\n\n\n灰度发布\n支持配置的灰度发布，比如点了发布后，只对部分应用实例生效，等观察一段时间没问题后再推给所有应用实例。\n\n\n权限管理、发布审核、操作审计\n\n应用和配置的管理都有完善的权限管理机制，对配置的管理还分为了编辑和发布两个环节，从而减少人为的错误。\n所有的操作都有审计日志，可以方便的追踪问题。\n\n\n客户端配置信息监控\n\n可以方便的看到配置在被哪些实例使用\n\n\n提供Java和.Net原生客户端\n\n提供了Java和.Net的原生客户端，方便应用集成\n支持Spring Placeholder，Annotation和Spring Boot的ConfigurationProperties，方便应用使用（需要Spring 3.1.1+）\n同时提供了Http接口，非Java和.Net应用也可以方便的使用\n\n\n提供开放平台API\nApollo自身提供了比较完善的统一配置管理界面，支持多环境、多数据中心配置管理、权限、流程治理等特性。\n不过Apollo出于通用性考虑，对配置的修改不会做过多限制，只要符合基本的格式就能够保存。\n在我们的调研中发现，对于有些使用方，它们的配置可能会有比较复杂的格式，如xml, json，需要对格式做校验。\n还有一些使用方如DAL，不仅有特定的格式，而且对输入的值也需要进行校验后方可保存，如检查数据库、用户名和密码是否匹配。\n对于这类应用，Apollo支持应用方通过开放接口在Apollo进行配置的修改和发布，并且具备完善的授权和权限控制\n\n\n部署简单\n配置中心作为基础服务，可用性要求非常高，这就要求Apollo对外部依赖尽可能地少\n目前唯一的外部依赖是MySQL，所以部署非常简单，只要安装好Java和MySQL就可以让Apollo跑起来\nApollo还提供了打包脚本，一键就可以生成所有需要的安装包，并且支持自定义运行时参数\n\n\n\n说明\n\n更多Apollo的文档资料可以查阅使用文档\n\n\n\nApollo本地快速部署请参见Quick Start\n\n\n\n选择Nacos的小伙伴也可以查看官方文档，了解更多Nacos的特性和使用方法.\n\n\n\n","categories":["配置中心"],"tags":["配置中心","SpringBoot","SpringCloud","Apollo","Nacos","Disconf","SpringCloudConfig"]},{"title":"手机摄影之城市一角（一）","url":"http://www.vincentli.top/2020/09/16/photo/","content":"\n","categories":["摄影"],"tags":["美图欣赏"]},{"title":"JVM高性能本地缓存Caffeine使用案例","url":"http://www.vincentli.top/2020/09/01/jvm-local-cache-case-caffeine/","content":"Background对于服务消费，响应时间（RT）的长短是衡量一个系统高效处理业务的重要指标，缓存就是必不可少的优化工具，在一个高并发的场景中往往占有着非常重要的角色，所以开发人员需要根据不同的应用场景来选择不同的缓存框架，比如分布式缓存redis，或者内存缓存GuavaCache。\n我们团队有一个调用比较频繁的服务，之前是和别的团队共用的Redis缓存服务，前不久突然得到消息，维护该redis团队要收回使用权，而我们服务使用也比较简单，只是用来做一个接口调用鉴权，从redis中拿出所有授权方的appKey，然后校验调用方的appKey是否合法。所以我第一想法是采用jvm本地缓存，因为这个调用方不会很多，而且数据是比较静态的，变化不会很频繁，放在jvm本地内存中，也不会占用很大空间，而且也不用担心多个部署实例缓存不一致的问题，经过调用有很多比较优秀的本地缓存比如GuavaCache，Caffeine等。我最后采用了Caffeine。    \nWhat is Caffeine？内存缓存与Map之间的本质区别就是能自动的回收存储的元素，而GuavaCache是一款非常优秀的内存缓存框架，很好的提供了读写和自动失效的功能。而今天要介绍的内存缓存Caffeine，在设计上参考了GuavaCache的经验，也进行了大量的改进优化，除了之前提到的GuavaCache的优点，还可以支持自动刷新，失效后自动加载等优点。以下数据图片均来源于Caffeine GitHub，首先是读写性能的比较：\n8个线程同时从缓存中读取 8个线程同时从缓存中写入  6个线程读取，2个线程写入 从上面的测试结果图，我们可以看出caffeine在读写方面明显优与其他框架，在缓存命中率上Caffeine也不同于Guava，采用了更为优秀的Window TinyLfu算法，该算法是在LRU的基础上改进的版本。\nFeature填充策略\n1、手动填充\n  Caffeine.newBuilder()方法只是Caffeine类的一个空的构造函数，类属性的实例化是在build方法中进行的，put方法就是手动填充缓存。newBuilder方法后面还能跟很多配置方法，比如\nCache&lt;String, Map&lt;String, String&gt;&gt; cache = Caffeine.newBuilder().maximumSize(5000).expireAfterWrite(172800L, TimeUnit.MILLISECONDS).build();Map&lt;String, String&gt; value = Maps.newHashMap();cache.put(&quot;key&quot;, value)\n\n\n我们也可以使用 get 方法获取值，该方法将一个参数为 key 的 Function 作为参数传入。如果缓存中不存在该 key，则该函数将用于提供默认值，该值在计算后插入缓存中。Caffeine类是Caffeine的基础类，里面提供了很多配置方法和参数：maximumSize：设置缓存最大条目数，超过条目则触发回收。 maximumWeight：设置缓存最大权重，设置权重是通过weigher方法， 需要注意的是权重也是限制缓存大小的参数，并不会影响缓存淘汰策略，也不能和maximumSize方法一起使用。 weakKeys：将key设置为弱引用，在GC时可以直接淘汰weakValues：将value设置为弱引用，在GC时可以直接淘汰softValues：将value设置为软引用，在内存溢出前可以直接淘汰expireAfterWrite：写入后隔段时间过期expireAfterAccess：访问后隔断时间过期refreshAfterWrite：写入后隔断时间刷新removalListener：缓存淘汰监听器，配置监听器后，每个条目淘汰时都会调用该监听器writer：writer监听器其实提供了两个监听，一个是缓存写入或更新是的write，一个是缓存淘汰时的delete，每个条目淘汰时都会调用该监听器手动填充表示任何数据都需要手动put到cache中，没有任何自动加载策略。put方法会覆盖相同key的条目\n\n同步填充\n异步填充异步填充于同步填充大致相似，区别是传入一个执行器进行异步执行，并且返回一个CompletableFuture对象，可以通过CompletableFuture.get来获取数据并设置超时时间。\n\n回收策略条目的自动淘汰回收是map于cache最大的区别，Caffeine同样包含了3中缓存回收机制，分别是基于大小，基于时间，基于引用类型。\n\n基于大小\n基于时间\n基于引用类型自动刷新cache除了会自动淘汰缓存数据，也能进行自动刷新缓存数据。private static Cache&lt;String, String&gt; cache = Caffeine.newBuilder().expireAfterWrite(10000, TimeUnit.MILLISECONDS).refreshAfterWrite(10000, TimeUnit.MILLISECONDS).build();\nrefreshAfterWrite就是设置写入后多就会刷新，expireAfterWrite和refreshAfterWrite的区别是，当缓存过期后，配置了expireAfterWrite，则调用时会阻塞，等待缓存计算完成，返回新的值并进行缓存，refreshAfterWrite则是返回一个旧值，并异步计算新值并缓存。\n\nCaffeine的使用案例代码/** * @author vincent.li * @Description ConfigCache本地缓存类 * @since 2020/9/01 */@Component@Slf4jpublic class ConfigCache &#123;    /**     * 自己实现的一个查询配置表数据的服务     */    @Autowired    private ConfigService configService;    private static Lock lock = new ReentrantLock();    /**     * key过期时间     * 全量刷新没有用invalidateAll（为了时并发线程可以获取到缓存旧值），对于数据库中已删除的key，需要靠过期来使其失效     *     */    private static final long EXPIRE_TIME = 172800L;    /**     * 上一次字典全量刷新的时间     */    private static long lastRefreshTime = 0L;    /**     * 全量字典数据刷新时间间隔，需小于单个key过期时间，否则刷新字典时，并发线程可能遇到key过期的情况     */    private static final long REFRESH_INTERVAL = 86400L;    private static Cache&lt;String, Map&lt;String, String&gt;&gt; configTypeCache = Caffeine.newBuilder().maximumSize(5000).expireAfterWrite(EXPIRE_TIME, TimeUnit.MILLISECONDS).build();    private static Cache&lt;String, String&gt; cache = Caffeine.newBuilder().expireAfterWrite(10000, TimeUnit.MILLISECONDS).refreshAfterWrite(10000, TimeUnit.MILLISECONDS).build();    /**     * 加载全量字典数据到缓存     */    @PostConstruct    public void reload() &#123;        try &#123;            log.info(&quot;start reload ConfigCache cache&quot;);            //获取全量字典数据            Map&lt;String, Map&lt;String, String&gt;&gt; configMap = configService.selectConfigItemMap();            configTypeCache.putAll(configMap);            lastRefreshTime = System.currentTimeMillis();            log.info(&quot;finish reload ConfigCache cache&quot;);        &#125; catch (Exception e) &#123;            log.warn(&quot;加载OrderPrintConfig失败&quot;, e);        &#125;    &#125;    /**     * 根据type获取configMap&lt;key,value&gt;，会判断是否需要全量刷新缓存     * @param type 类型     * @return Map&lt;String, String&gt;     */    public static Map&lt;String, String&gt; getByType(String type) &#123;        if (StringUtils.isEmpty(type)) &#123;            return Maps.newHashMap();        &#125;        try &#123;            if (System.currentTimeMillis() - lastRefreshTime &gt; REFRESH_INTERVAL) &#123;                if (lock.tryLock()) &#123;                    try &#123;                        if (System.currentTimeMillis() - lastRefreshTime &gt; REFRESH_INTERVAL) &#123;                            ApplicationContext ctx = SpringBeanUtil.getContext();                            if (Objects.nonNull(ctx) &amp;&amp; Objects.nonNull(ctx.getBean(OrderPrintConfigCache.class))) &#123;            ConfigCache configCache = ctx.getBean(ConfigCache.class);                                configCache.reload();                            &#125;                            return configTypeCache.getIfPresent(type);                        &#125;                    &#125; catch (Exception e) &#123;                        log.info(&quot;configTypeCache数据更新异常&quot;, e);                    &#125; finally &#123;                        lock.unlock();                    &#125;                &#125; else &#123;                    //获取锁失败，表明另一线程正在更新全量字典，直接从缓存中拿旧值                    return configTypeCache.getIfPresent(type);                &#125;            &#125;            return configService.get(type, ConfigCache::loadDictByType);        &#125; catch (Exception e) &#123;            log.info(&quot;configTypeCache缓存未命中&quot;, e);            return Maps.newHashMap();        &#125;    &#125;    private static Map&lt;String, String&gt; loadDictByType(String type) &#123;        ApplicationContext ctx = SpringBeanUtil.getContext();        if (Objects.nonNull(ctx) &amp;&amp;  Objects.nonNull(ctx.getBean(ConfigCache.class))) &#123;            ConfigCache dictCache = ctx.getBean(ConfigCache.class);            return dictCache.loadByKey(type);        &#125;        return Maps.newHashMap();    &#125;    private Map&lt;String, String&gt; loadByKey(String type) &#123;       return ConfigService.selectConfigItemMap(type);    &#125;&#125;","categories":["缓存"],"tags":["缓存","JVM","caffeine","redis"]},{"title":"减少重复劳动,使用Mysql存储过程批量创建表","url":"http://www.vincentli.top/2020/08/25/mysql-procedure-batch-create-table-pratise/","content":"背景相信很多公司发展到一定规模，数据量达到千万级甚至亿级别的时候，开始考虑分库分表，最近我们团队一个同事接到别的团队交接过来的一个应用服务，每天的数据增量在1千万，由于时间紧迫，存储数据在Mysql中，经过短暂调研我们采用了分库分表的中间件Apache ShardingSphere的分库分表组件ShardingSphere-JDBC,这不是本文的重点，重点是我们做分库分表时，需要一次性创建几十甚至上百张分表，如果Ctrl+C和Ctrl+V也是极其累的，同事问我有木有简单的方法，减少重复劳动，我第一个想法就是用Mysql的存储过程或者函数批量创建表，解放生产力。\nMysql批量创建分表的过程\n下面我以简化版的order表来举例说明操作过程\n准备一个基本表orderCREATE TABLE `order` (  `order_id` bigint(20) NOT NULL COMMENT &#x27;住建ID&#x27;,  `order_no` varchar(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;订单号&#x27;,  `is_deleted` tinyint(2) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;是否逻辑删除(0-否,1-是)&#x27;,  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;,  `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;,  `remarks` varchar(255) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;备注&#x27;,  PRIMARY KEY (`order_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&#x27;订单表&#x27;;\n\n创建一个批量创建order分表的存储过程CREATE DEFINER=`root`@`%` PROCEDURE `batch_create_table_order`()begindeclare i int default 0;declare tab_name varchar(200) default &#x27;&#x27;;while i &lt; 20 do        set tab_name = concat(&#x27;create table  order_&#x27;,i, &#x27; as select * from         `order` where 1=2;&#x27;);        SET @SQL = CONCAT(tab_name);            PREPARE stmt FROM @SQL ;    EXECUTE stmt;    DEALLOCATE PREPARE stmt;        set i = i + 1;end while;end\n执行存储过程\n执行SQL命令call batch_create_table_order();\n执行结果和耗时：从执行的结果和耗时来看，不到1s就创建出了20张分表，如果是100张分表执行也只有1到2s,比起传统的Ctrl+C,Ctrl+V效率提升真是开心到飞起，多余的时间去刷刷虎扑，看看球，真香。\n\n","categories":["博客","Mysql"],"tags":["Mysql,存储过程"]},{"title":"Tomcat高危安全漏洞影响SpringBoot和SpringCloud多个版本及解决方案","url":"http://www.vincentli.top/2020/07/06/tomcat-unsafe-hole-solution/","content":"事件背景2020是庚子年，是不平凡的一年，据2020年6月25日Apache官方安全团队通过邮件公开报告显示，Tomcat版本8.5.0 至 8.5.55，9.0.0.M1 至 9.0.35，10.0.0-M1 至10.0.0-M5爆出了一个高危漏洞， 主要涉及HTTP/2拒绝服务漏洞的细节及解决方案。    漏洞细节如下图所示：\n\n漏洞名称：Apache Tomcat HTTP/2 拒绝服务漏洞\n漏洞编号：CVE-2020-11996\n严重程度: 重要\n软件提供商: Apache 软件基金会\n受影响的版本：Apache Tomcat 10.0.0-M1 ~ 10.0.0-M5Apache Tomcat 9.0.0.M1 ~ 9.0.35Apache Tomcat 8.5.0 ~ 8.5.55\n漏洞描述：一个特别制作的 HTTP/2 请求序列，在短短数秒内能导致 CPU 满负载率，如果有足够数量多的此类请求连接（HTTP/2）并发放在服务器上，服务器可能会失去响应。如果条件允许，可以通过升级到Tomcat新版本来解决漏洞。下面为受影响版本对应的安全版本：Apache Tomcat 10.0.0-M6+Apache Tomcat 9.0.36+Apache Tomcat 8.5.56+\nSpringCloud/SpringBoot框架影响\n\nApache Tomcat HTTP/2 拒绝服务漏洞给SpringCloud /SpringBoot框架带来了一定的影响。下面是所有受影响的版本列表，大家可以查看并对照下自己的代码，看看是否受到影响。\nSpring Cloud Edgware / Spring Boot 1.5.xSpring Cloud [Edgware.RELEASE - Edgware.SR6] 版本受到影响。\nSpring Boot [1.5.0.RELEASE - 1.5.22.RELEASE] 版本受到影响。\nSpring Cloud Finchley / Spring Boot 2.0.xSpring Cloud [Finchley.RELEASE - Finchley.SR4] 版本受到影响。\nSpring Boot [2.0.0.RELEASE - 2.0.9.RELEASE] 版本受到影响。\nSpring Cloud Greenwich / Spring Boot 2.1.xSpring Cloud [Greenwich.RELEASE - Greenwich.SR6] 版本受到影响。\nSpring Boot [2.1.0.RELEASE - 2.1.14.RELEASE] 版本受到影响。\nSpring Boot [2.1.15.RELEASE] 版本已修复。\nSpring Cloud Hoxton / Spring Boot 2.2.xSpring Cloud [Hoxton.RELEASE - Hoxton.SR6] 版本受到影响。\nSpring Boot [2.2.0.RELEASE - 2.2.7.RELEASE] 版本受到影响。\nSpring Boot [2.2.8.RELEASE] 版本已修复。\nSpring Boot 2.3.xSpring Boot [2.3.0.RELEASE] 版本受到影响。\nSpring Boot [2.3.1.RELEASE] 版本已修复。\n解决方案为了解决上述漏洞，我和我们团队的小伙伴摸索出两种升级方案：\n\n直接升级Spring Boot版本。\n手动升级Tomcat版本。\n\n升级 Spring Cloud Edgware / Spring Boot 1.5.x\nEdgware无法通过升级Spring Boot版本解决问题。\n\n&lt;properties&gt;    &lt;tomcat.version&gt;8.5.56&lt;/tomcat.version&gt;&lt;/properties&gt;\n升级SpringCloud Finchley / SpringBoot 2.0.x\nFinchley无法通过升级Spring Boot版本解决问题。\n\n&lt;properties&gt;    &lt;tomcat.version&gt;8.5.56&lt;/tomcat.version&gt;&lt;/properties&gt;\n升级SpringCloud Greenwich / SpringBoot 2.1.x\n升级Spring Boot\n\n&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.1.15.RELEASE&lt;/version&gt;&lt;/parent&gt;\n\n升级Tomcat\n\n&lt;properties&gt;    &lt;tomcat.version&gt;9.0.37&lt;/tomcat.version&gt;&lt;/properties&gt;\n升级Spring Cloud Hoxton / Spring Boot 2.2.x\n升级SpringBoot\n\n&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.2.8.RELEASE&lt;/version&gt;&lt;/parent&gt;\n\n升级Tomcat\n\n&lt;properties&gt;    &lt;tomcat.version&gt;9.0.37&lt;/tomcat.version&gt;&lt;/properties&gt;\n升级Spring Boot 2.3.x\n升级SpringBoot\n\n&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.3.1.RELEASE&lt;/version&gt;&lt;/parent&gt;\n\n升级Tomcat\n\n&lt;properties&gt;    &lt;tomcat.version&gt;9.0.37&lt;/tomcat.version&gt;&lt;/properties&gt;\n后记我们有个现有的服务SpringBoot的版本是2.1.10.RELEAS,SpringCloud的版本是Greenwich.SR3,还集成了很多其他微服务组件，我们考虑到升级SpringBoot版本带来的兼容风险，我们采取了直接升级Tomcat版本的方式，建议由同样担忧的小伙伴也可以采取类似方案。\n","categories":["Tomcat","SpringBoot","SpringCloud"],"tags":["SpringBoot","SpringCloud","Tomcat","安全漏洞"]},{"title":"Kafka开启JMX监控操作实践","url":"http://www.vincentli.top/2020/06/04/kafka-jmx-monitor-open/","content":"前段时间，我们团队使用的kafka集群压力比较大，需要接入监控，而运维给搭建kafka集群的时候没有开启JMX监控,于是我调用了3种开启方式，并本地进行了开启验证，方便后续接入kafka eagle监控平台。\n一、开启JMX的方式方式1：修改bin/kafka-run-class.sh脚本,在开始运行的最上方加入JMX_PORT=9999(可以自行指定一个没有占用的端口)。# Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.#open jmx monitorJMX_PORT=9999if [ $# -lt 1 ];\n方式2：修改bin/kafka-server-start.sh脚本，在开始运行的最上方加入如下代码:if [ &quot;x$JMX_PORT&quot; = &quot;x&quot;]; then    export JMX_PORT=&quot;9999&quot;fi\n方式3：在运行启动命令前 加上系统预留的JMX_PORT.JMX_PORT=9999 bin/kafka-server-start.sh -daemon config/server.properties\n我们采用了方式2，先用命令停止服务。修改启动脚本后，重新启动kafka服务，然后进行验证。\n二、验证JMX是否开启的方式Kafka的每个监控指标都是以JMX MBEAN的形式定义的，MBEAN是一个被管理的资源实例。我们可以使用Jconsole （Java Monitoring and Management Console），一种基于JMX的可视化监视、管理工具。\n方式1：通过jmx的9999端口访问观察MBean及metric数据\n1.1 启动jconsole。\n1.2 在远程连接输入service:jmx:rmi:///jndi/rmi://127.0.0.1:9999/jmxrmi 或者 127.0.0.1:9999（127.0.0.1 可以换成kafka服务器所在的ip),然后点击连接，可以查看Kafka的各种监控指标，都是以 kafka.xxx:type=xxx,xxx=xxx 打头MBean。方式2：使用Kafka默认提供的一个工具JmxTool，用于实时查看JMX监控指标。\n2.1 打开终端进入到Kafka安装目录下，输入命令bin/kafka-run-class.sh kafka.tools.JmxTool便可以得到JmxTool工具的帮助信息。比如我们要监控入站速率，可以输入以下命令，BytesInPerSec的值每5秒会打印在控制台上。bin/kafka-run-class.sh kafka.tools.JmxTool --object-name kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec --jmx-url service:jmx:rmi:///jndi/rmi://ip:9999/jmxrmi --date-format &quot;YYYY-MM-dd HH:mm:ss&quot; --attributes FifteenMinuteRate --reporting-interval 5000\n\n\n","categories":["缓存","博客","消息队列","kafka"],"tags":["Java","kafka","消息队列","MQ","jmx","监控"]},{"title":"Zookeeper从入门到精通（二）","url":"http://www.vincentli.top/2020/04/26/zookeeper-from-start-to-deep-known-two/","content":"\nZookeeper工作原理\nZookeeper 的核心是原子广播，这个机制保证了各个 server 之间的同步。实现这个机制的协议叫做 Zab 协议。Zab 协议有两种模式，它们分别是恢复模式和广播模式。\n\n当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 server 的完成了和 leader 的状态同步以后，恢复模式就结束了。\n\n状态同步保证了 leader 和 server 具有相同的系统状态。\n\n一旦 leader 已经和多数的 follower 进行了状态同步后，他就可以开始广播消息了，即进入广播状态。这时候当一个 server 加入 zookeeper 服务中，它会在恢复模式下启动，发现 leader，并和 leader 进行状态同步。待到同步结束，它也参与消息广播。Zookeeper服务一直维持在 Broadcast 状态，直到 leader 崩溃了或者 leader 失去了大部分的followers 支持。\n\n广播模式需要保证 proposal 被按顺序处理，因此 zk 采用了递增的事务 id 号(zxid)来保证。所有的提议(proposal)都在被提出的时候加上了 zxid。\n\n实现中 zxid 是一个 64 为的数字，它高 32 位是 epoch 用来标识 leader 关系是否改变，每次一个 leader 被选出来，它都会有一个新的 epoch。低 32 位是个递增计数。\n\n当 leader 崩溃或者 leader 失去大多数的 follower，这时候 zk 进入恢复模式，恢复模式需要重新选举出一个新的 leader，让所有的 server 都恢复到一个正确的状态。\n\n\nZnode介绍Znode 有四种形式的目录节点\nPERSISTENT：持久的节点。\nEPHEMERAL：临时的节点。\nPERSISTENT_SEQUENTIAL：持久化顺序编号目录节点。\nEPHEMERAL_SEQUENTIAL：临时化顺序编号目录节点。\n\nZnode的常用使用场景目前我们所熟知的分布式服务框架Dubbo,消息队列Kafka都是采用zookeeper做分布式服务的协调器，也是利用了Znode的暂时节点的一个特性，就是当client和server端的心跳会话断开后，临时节点会被删除，并通知注册监听了该临时节点的其他节点。此外我们也可以利用顺序临时节点去实现一个分布式锁，尤其是我们分布式服务中处理一些有顺序性的业务场景的时候。\n","categories":["Zookeeper"],"tags":["分布式","微服务","Zookeeper"]},{"title":"Zookeeper从入门到精通（一）","url":"http://www.vincentli.top/2020/04/17/zookeeper-from-start-to-deep-known-one/","content":"Zookeeper 概念Zookeeper是一个分布式协调服务，可用于服务发现，分布式锁，分布式领导选举，配置管理等。Zookeeper 提供了一个类似于 Linux 文件系统的树形结构（可认为是轻量级的内存文件系统，但只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与通知机制。\nZookeeper 角色Zookeeper 集群是一个基于主从复制的高可用集群，每个服务器承担如下三种角色中的一种.\nLeader\n一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader，它会发起并维护与各 Follwer及 Observer 间的心跳。\n所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。只要有超过半数节点（不包括 observeer 节点）写入成功，该写请求就会被提交（类 2PC 协议）。 Follower\n一个 Zookeeper 集群可能同时存在多个 Follower，它会响应 Leader 的心跳，\nFollower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，\n并且负责在 Leader 处理写请求时对请求进行投票。Observer角色与 Follower 类似，但是无投票权。Zookeeper 需保证高可用和强一致性，为了支持更多的客\n户端，需要增加更多 Server；Server 增多，投票阶段延迟增大，影响性能；引入 Observer，Observer 不参与投票； Observers 接受客户端的连接，并将写请求转发给 leader 节点； 加入更多 Observer 节点，提高伸缩性，同时不影响吞吐率。\n\n\nZAB 协议事务编号 Zxid（事务请求计数器+ epoch）在 ZAB ( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议） 协议的事务编号 Zxid设计中，Zxid 是一个 64 位的数字，其中低 32 位是一个简单的单调递增的计数器，针对客户端每一个事务请求，计数器加 1；而高 32 位则代表 Leader 周期 epoch 的编号，每个当选产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务的 ZXID，并从中读取epoch 值，然后加 1，以此作为新的 epoch，并将低 32 位从 0 开始计数。Zxid（Transaction id）类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal（提议）ID。为了保证顺序性，该 zkid 必须单调递增。\nepochepoch：可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所以每次改朝换代，leader 变更之后，都会在前一个年代的基础上加 1。这样就算旧的 leader 崩溃恢复之后，也没有人听他的了，因为 follower 只听从当前年代的 leader 的命令。\nZab 协议有两种模式-恢复模式（选主）、广播模式（同步）Zab 协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。\nZAB 协议 4 阶段\n  Leader election（选举阶段-选出准 Leader）\nLeader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。只有到达 广播阶段（broadcast） 准 leader 才会成为真正的 leader。这一阶段的目的是就是为了选出一个准 leader，然后进入下一个阶段。\n\n Discovery（发现阶段-接受提议、生成 epoch、接受 epoch）\n\n\nDiscovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers最近接收的事务提议。这个一阶段的主要目的是发现当前大多数节点接收的最新提议，并且准 leader 生成新的 epoch，让 followers 接受，更新它们的 accepted Epoch。一个 follower 只会连接一个 leader，如果有一个节点 f 认为另一个 follower p 是 leader，f在尝试连接 p 时会被拒绝，f 被拒绝之后，就会进入重新选举阶段。\n\n Synchronization（同步阶段-同步 follower 副本）\n\nSynchronization（同步阶段）：同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。只有当 大多数节点都同步完成，准 leader 才会成为真正的 leader。follower 只会接收 zxid 比自己的 lastZxid 大的提议。\n\n Broadcast（广播阶段-leader 消息广播）\n\nBroadcast（广播阶段）：到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。ZAB 提交事务并不像 2PC 一样需要全部 follower 都 ACK，只需要得到超过半数的节点的 ACK 就可以了。\n\n ZAB 协议 JAVA 实现（FLE-发现阶段和同步合并为 Recovery Phase（恢复阶段）\n\n协议的 Java 版本实现跟上面的定义有些不同，选举阶段使用的是 Fast Leader Election（FLE），它包含了 选举的发现职责。因为 FLE 会选举拥有最新提议历史的节点作为 leader，这样就省去了发现最新提议的步骤。实际的实现将 发现阶段 和 同步合并为 Recovery Phase（恢复阶段）。所以，ZAB 的实现只有三个阶段：Fast Leader Election；Recovery Phase；Broadcast Phase。\n投票机制每个 sever 首先给自己投票，然后用自己的选票和其他 sever 选票对比，权重大的胜出，使用权重较大的更新自身选票箱。具体选举过程如下：\n\n每个 Server 启动以后都询问其它的 Server 它要投票给谁。对于其他 server 的询问，server 每次根据自己的状态都回复自己推荐的 leader 的 id 和上一次处理事务的 zxid（系统启动时每个 server 都会推荐自己）\n\n收到所有 Server 回复以后，就计算出 zxid 最大的哪个 Server，并将这个 Server 相关信息设置成下一次要投票的 Server。\n\n\n\n计算这过程中获得票数最多的的 sever 为获胜者，如果获胜者的票数超过半数，则改server 被选为 leader。否则，继续这个过程，直到 leader 被选举出来\n\nleader 就会开始等待 server 连接\n\nFollower 连接 leader，将最大的 zxid 发送给 leader\n\nLeader 根据 follower 的 zxid 确定同步点，至此选举阶段完成。\n\n选举阶段完成 Leader 同步后通知 follower 已经成为 uptodate 状态\n\nFollower 收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了\n\n\n投票过程举例：目前有 5 台服务器，每台服务器均没有数据，它们的编号分别是 1,2,3,4,5,按编号依次启动，它们的选择举过程如下。\n\n服务器 1 启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器 1 的状态一直属于 Looking。\n\n服务器 2 启动，给自己投票，同时与之前启动的服务器 1 交换结果，由于服务器 2 的编号大所以服务器 2 胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。\n\n服务器 3 启动，给自己投票，同时与之前启动的服务器 1,2 交换信息，由于服务器 3 的编号最大所以服务器 3 胜出，此时投票数正好大于半数，所以服务器 3 成为领导者，服务器1,2 成为小弟。\n\n服务器 4 启动，给自己投票，同时与之前启动的服务器 1,2,3 交换信息，尽管服务器 4 的编号大，但之前服务器 3 已经胜出，所以服务器 4 只能成为小弟。\n\n服务器 5 启动，后面的逻辑同服务器 4 成为小弟。\n\n\n小结本篇幅，我们一起熟悉了zookeeper的基本概念，以及它的一些基本角色，以及ZAB协议和投票机制，后续我们再来讨论一下Zookeeper相关的工作原理和Znode。\n","categories":["Zookeeper"],"tags":["分布式","微服务","Zookeeper"]},{"title":"推荐Git提交规范","url":"http://www.vincentli.top/2020/03/30/git-commit-recommend-form/","content":"Git 每次提交代码，都要写 Commit message（提交说明），否则就不允许提交。\ngit commit -m &quot;init project....&quot;\n上面代码的-m参数，就是用来指定 commit mesage 的。\n如果一行不够，可以只执行git commit，就会跳出文本编辑器，让你写多行.一般来说，commit message 应该清晰明了，说明本次提交的目的。\n本文介绍Angular 规范（见上图），这是目前使用最广的写法，比较合理和系统化，并且有配套的工具。\nCommit message 的作用格式化的Commit message，有几个好处。\n\n1）提供更多的历史信息，方便快速浏览。\n\n比如，下面的命令显示上次发布后的变动，每个commit占据一行。你只看行首，就知道某次 commit 的目的。\ngit log &lt;last tag&gt; HEAD --pretty=format:%s\n\n\n2）可以过滤某些commit（比如文档改动），便于快速查找信息。\n\n比如，下面的命令仅仅显示本次发布新增加的功能。\ngit log &lt;last release&gt; HEAD --grep feature\n\n3）可以直接从commit生成Change log。\n\nChange Log 是发布新版本时，用来说明与上一个版本差异的文档，详见后文。\n二、Commit message 的格式每次提交，Commit message 都包括三个部分：Header，Body 和 Footer。\n&lt;type&gt;(&lt;scope&gt;): &lt;subject&gt;// 空一行&lt;body&gt;// 空一行&lt;footer&gt;\n其中，Header 是必需的，Body 和 Footer 可以省略。\n不管是哪一个部分，任何一行都不得超过72个字符（或100个字符）。这是为了避免自动换行影响美观。\n\n2.1 Header\n\nHeader部分只有一行，包括三个字段：type（必需）、scope（可选）和subject（必需）。\n+ 1）type\ntype用于说明 commit 的类别，只允许使用下面7个标识。\nfeat：新功能（feature）fix：修补bugdocs：文档（documentation）style： 格式（不影响代码运行的变动）refactor：重构（即不是新增功能，也不是修改bug的代码变动）test：增加测试chore：构建过程或辅助工具的变动\n如果type为feat和fix，则该 commit 将肯定出现在 Change log 之中。其他情况（docs、chore、style、refactor、test）由你决定，要不要放入 Change log，建议是不要。\n+ 2）scope\nscope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。\n+ 3）subject\nsubject是 commit 目的的简短描述，不超过50个字符。以动词开头，使用第一人称现在时，比如change，而不是changed或changes第一个字母小写结尾不加句号（.）\n\n2.2 BodyBody 部分是对本次 commit 的详细描述，可以分成多行。下面是一个范例。\n\nMore detailed explanatory text, if necessary.  Wrap it to about 72 characters or so. Further paragraphs come after blank lines.- Bullet points are okay, too- Use a hanging indent\n有两个注意点。\n（1）使用第一人称现在时，比如使用change而不是changed或changes。\n（2）应该说明代码变动的动机，以及与以前行为的对比。\n\n2.3 Footer\n\nFooter 部分只用于两种情况。\n+ 1）不兼容变动\n如果当前代码与上一个版本不兼容，则 Footer 部分以BREAKING CHANGE开头，后面是对变动的描述、以及变动理由和迁移方法。BREAKING CHANGE: isolate scope bindings definition has changed.    To migrate the code follow the example below:    Before:    scope: &#123;      myAttr: &#x27;attribute&#x27;,    &#125;    After:    scope: &#123;      myAttr: &#x27;@&#x27;,    &#125;    The removed `inject` wasn&#x27;t generaly useful for directives so there should be no code using it.\n+ 2）关闭 Issue\n如果当前 commit 针对某个issue，那么可以在 Footer 部分关闭这个 issue 。Closes #234也可以一次关闭多个 issue 。Closes #123, #245, #992\n\n2.4 Revert还有一种特殊情况，如果当前 commit 用于撤销以前的 commit，则必须以revert:开头，后面跟着被撤销 Commit 的 Header。\n\nrevert: feat(pencil): add &#x27;graphiteWidth&#x27; optionThis reverts commit 667ecc1654a317a13331b17617d973392f415f02.\nBody部分的格式是固定的，必须写成This reverts commit &amp;lt;hash&gt;.，其中的hash是被撤销 commit 的 SHA 标识符。\n如果当前 commit 与被撤销的 commit，在同一个发布（release）里面，那么它们都不会出现在 Change log 里面。如果两者在不同的发布，那么当前 commit，会出现在 Change log 的Reverts小标题下面。\n","categories":["工具学习"],"tags":["git"]},{"title":"Mysql好的使用规范","url":"http://www.vincentli.top/2019/11/28/mysql-good-using-rule/","content":"(一)建表规约1.【强制】表达是与否概念的字段，必须使用 is_xxx的方式命名，数据类型是 unsigned tinyint（ 1表示是，0表示否），此规则同样适用于 odps建表。说明：任何字段如果为非负数，必须是 unsigned。个人备注：Open Data Processing Service， 简称ODPS；是由阿里云自主研发，提供针对TB/PB级数据、实时性要求不高的分布式处理能力，应用于数据分析、挖掘、商业智能等领域；阿里巴巴的离线数据业务都运行在ODPS上；。2.【强制】表名、字段名必须使用小写字母或数字；禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。正例：getter_admin，task_config，level3_name反例：GetterAdmin，taskConfig，level_3name3.【强制】表名不使用复数名词。说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO类名也是单数形式，符合表达习惯。4.【强制】禁用保留字，如 desc、range、match、delayed等，请参考 MySQL官方保留字。5.【强制】唯一索引名为 uk字段名；普通索引名则为 idx字段名。说明：uk 即 unique key；idx_ 即 index的简称。6.【强制】小数类型为 decimal，禁止使用 float和 double。说明：float和 double在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal的范围，建议将数据拆成整数和小数分开存储。7.【强制】如果存储的字符串长度几乎相等，使用 char定长字符串类型。8.【强制】varchar是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。9.【强制】表必备三字段：id, gmt_create, gmt_modified。说明：其中 id必为主键，类型为 unsigned bigint、单表时自增、步长为 1。gmt_create,gmt_modified的类型均为 datetime类型。10.【推荐】表的命名最好是加上“业务名称表的作用”。正例：tiger_task / tiger_reader / mpp_config11.【推荐】库名与应用名称尽量一致。12.【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。13.【推荐】字段允许适当冗余，以提高性能，但是必须考虑数据同步的情况。冗余字段应遵循：1）不是频繁修改的字段。2）不是 varchar超长字段，更不能是 text字段。正例：商品类目名称使用频率高，字段长度短，名称基本一成不变，可在相关联的表中冗余存储类目名称，避免关联查询。14.【推荐】单表行数超过 500万行或者单表容量超过 2GB，才推荐进行分库分表。说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。15.【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。正例：人的年龄用 unsigned tinyint（表示范围 0-255，人的寿命不会超过 255岁）；海龟就必须是 smallint，但如果是太阳的年龄，就必须是 int；如果是所有恒星的年龄都加起来，那么就必须使用 bigint。\n(二)索引规约1.【强制】业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。说明：不要以为唯一索引影响了 insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，即使在应用层做了非常完善的校验和控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。2.【强制】 超过三个表禁止 join。需要 join的字段，数据类型保持绝对一致；多表关联查询时，保证被关联的字段需要有索引。说明：即使双表 join也要注意表索引、SQL性能。3.【强制】在 varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度。说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20的索引，区分度会高达 90%以上，可以使用 count(distinct left(列名, 索引长度))/count(*)的区分度来确定。4.【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。说明：索引文件具有 B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。5.【推荐】如果有 order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现 file_sort的情况，影响查询性能。正例：where a=? and b=? order by c; 索引：a_b_c反例：索引中有范围查找，那么索引有序性无法利用，如：WHERE a&gt;10 ORDER BY b; 索引a_b无法排序。6.【推荐】利用覆盖索引来进行查询操作，来避免回表操作。说明：如果一本书需要知道第 11章是什么标题，会翻开第 11章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索引的作用。正例：能够建立索引的种类：主键索引、唯一索引、普通索引，而覆盖索引是一种查询的一种效果，用 explain的结果，extra列会出现：using index。7.【推荐】利用延迟关联或者子查询优化超多分页场景。说明：MySQL并不是跳过 offset行，而是取 offset+N行，然后返回放弃前offset行，返回N行，那当 offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL改写。正例：先快速定位需要获取的 id段，然后再关联：\nSELECT    a.*FROM    表1 a,    (        SELECT            id        FROM            表1        WHERE            条件        LIMIT 100000,        20    ) bWHERE    a.id = b.id\n8.【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是 ref级别，如果可以是 consts最好。说明：1）consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。2）ref 指的是使用普通的索引（normal index）。3）range 对索引进行范围检索。反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个 index级别比较 range还低，与全表扫描是小巫见大巫。9.【推荐】建组合索引的时候，区分度最高的在最左边。正例：如果 where a=? and b=? ，a列的几乎接近于唯一值，那么只需要单建 idx_a索引即可。说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where a&gt;?and b=? 那么即使 a的区分度更高，也必须把 b放在索引的最前列。10.【参考】创建索引时避免有如下极端误解：1）误认为一个查询就需要建一个索引。2）误认为索引会消耗空间、严重拖慢更新和新增速度。3）误认为唯一索引一律需要在应用层通过“先查后插”方式解决。\n(三)SQL规约1.【强制】不要使用 count(列名)或 count(常量)来替代 count()，count()就是 SQL92定义的标准统计行数的语法，跟数据库无关，跟 NULL和非 NULL无关。说明：count(*)会统计值为 NULL的行，而 count(列名)不会统计此列为 NULL值的行。2.【强制】count(distinct col) 计算该列除 NULL之外的不重复数量。注意 count(distinct col1, col2) 如果其中一列全为 NULL，那么即使另一列有不同的值，也返回为 0。3.【强制】当某一列的值全是 NULL时，count(col)的返回结果为 0，但 sum(col)的返回结果为NULL，因此使用 sum()时需注意 NPE问题。正例：可以使用如下方式来避免 sum的 NPE问题：\nSELECTIF (ISNULL(SUM(g)), 0, SUM(g))FROM    TABLE;\n4.【强制】使用 ISNULL()来判断是否为 NULL值。注意：NULL与任何值的直接比较都为 NULL。说明：1） NULL&lt;&gt;NULL的返回结果是 NULL，而不是 false。2） NULL=NULL的返回结果是 NULL，而不是 true。3） NULL&lt;&gt;1的返回结果是 NULL，而不是 true。5.【强制】 在代码中写分页查询逻辑时，若 count为 0应直接返回，避免执行后面的分页语句。6.【强制】不得使用外键与级联，一切外键概念必须在应用层解决。说明：（概念解释）学生表中的 student_id是主键，那么成绩表中的 student_id则为外键。如果更新学生表中的 student_id，同时触发成绩表中的 student_id更新，则为级联更新。外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度。7.【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。8.【强制】数据订正时，删除和修改记录时，要先 select，避免出现误删除，确认无误才能执行更新语句。9.【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估 in后边的集合元素数量，控制在 1000个之内。10.【参考】如果有全球化需要，所有的字符存储与表示，均以 utf-8编码，那么字符计数方法注意：说明：SELECT LENGTH(“轻松工作”)； 返回为 12SELECT CHARACTER_LENGTH(“轻松工作”)； 返回为 4如果要使用表情，那么使用 utfmb4来进行存储，注意它与 utf-8编码的区别。11.【参考】TRUNCATETABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但 TRUNCATE无事务且不触发 trigger，有可能造成事故，故不建议在开发代码中使用此语句。说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。\n(四)ORM规约1.【强制】在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。说明：1）增加查询分析器解析成本。2）增减字段容易与 resultMap配置不一致。2.【强制】POJO类的 boolean属性不能加 is，而数据库字段必须加 is_，要求在 resultMap中进行字段与属性之间的映射。说明：参见定义 POJO类以及数据库字段定义规定，在 sql.xml增加映射，是必须的。3.【强制】不要用 resultClass当返回参数，即使所有类属性名与数据库字段一一对应，也需要定义；反过来，每一个表也必然有一个与之对应。说明：配置映射关系，使字段与 DO类解耦，方便维护。4.【强制】xml配置中参数注意使用：#{}，#param# 不要使用${} 此种方式容易出现 SQL注入。5.【强制】iBATIS自带的 queryForList(String statementName,int start,int size)不推荐使用。说明：其实现方式是在数据库取到statementName对应的SQL语句的所有记录，再通过subList取 start,size的子集合，线上因为这个原因曾经出现过 OOM。正例：在 sqlmap.xml中引入 #start#, #size#\nMap&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();map.put(&quot;start&quot;, start);map.put(&quot;size&quot;, size);\n6.【强制】不允许直接拿 HashMap与 Hashtable作为查询结果集的输出。7.【强制】更新数据表记录时，必须同时更新记录对应的 gmt_modified字段值为当前时间。8.【推荐】不要写一个大而全的数据更新接口，传入为 POJO类，不管是不是自己的目标更新字段，都进行\nUPDATE TABLESET  c1 = value1, c2 = value2, c3 = value3;\n这是不对的。执行 SQL时，尽量不要更新无改动的字段，一是易出错；二是效率低；三是 binlog增加存储。9.【参考】@Transactional事务不要滥用。事务会影响数据库的 QPS，另外使用事务的地方需要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。10.【参考】&lt; isEqual&gt;中的compareValue是与属性值对比的常量，一般是数字，表示相等时带上此条件；&lt; isNotEmpty&gt;表示不为空且不为 null时执行；&lt; isNotNull&gt;表示不为 null值时执行。\n","categories":["技术学习笔记","Mysql"],"tags":["Mysql","数据库"]},{"title":"从微服务到SpringCloud","url":"http://www.vincentli.top/2019/10/28/from-micro-service-to-springcloud/","content":"什么是微服务架构？微服务架构就是将单体的应用程序分成多个应用程序，这多个应用程序就成为微服务，每个微服务运行在自己的进程中，并使用轻量级的机制通信。这些服务围绕业务能力来划分，并通过自动化部署机制来独立部署。这些服务可以使用不同的编程语言，不同数据库，以保证最低限度的集中式管理。\n为什么需要学习Spring Cloud首先springcloud基于spingboot的优雅简洁，可还记得我们被无数xml支配的恐惧？可还记得springmvc，mybatis错综复杂的配置，有了spingboot，这些东西都不需要了，spingboot好处不再赘诉，springcloud就基于SpringBoot把市场上优秀的服务框架组合起来，通过Spring Boot风格进行再封装屏蔽掉了复杂的配置和实现原理,什么叫做开箱即用？即使是当年的黄金搭档dubbo+zookeeper下载配置起来也是颇费心神的！而springcloud完成这些只需要一个jar的依赖就可以了！springcloud大多数子模块都是直击痛点，像zuul解决的跨域，fegin解决的负载均衡，hystrix的熔断机制等等等等\nSpring Cloud 是什么?Spring Cloud是一系列框架的有序集合。它利用Spring Boot的开发便利性巧妙地简化了分布式系统基础设施的开发，如服务发现注册、配置中心、智能路由、消息总线、负载均衡、断路器、数据监控等，都可以用Spring Boot的开发风格做到一键启动和部署。Spring Cloud并没有重复制造轮子，它只是将各家公司开发的比较成熟、经得起实际考验的服务框架组合起来，通过SpringBoot风格进行再封装屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂、易部署和易维护的分布式系统开发工具包。\nSpringCloud的优缺点优点：\n耦合度比较低。不会影响其他模块的开发。 \n减轻团队的成本，可以并行开发，不用关注其他人怎么开发，先关注自己的开发。\n配置比较简单，基本用注解就能实现，不用使用过多的配置文件。 \n微服务跨平台的，可以用任何一种语言开发。 \n每个微服务可以有自己的独立的数据库也有用公共的数据库。 \n直接写后端的代码，不用关注前端怎么开发，直接写自己的后端代码即可，然后暴露接口，通过组件进行 服务通信。\n\n缺点：\n部署比较麻烦，给运维工程师带来一定的麻烦。 \n针对数据的管理比麻烦，因为微服务可以每个微服务使用一个数据库。 \n系统集成测试比较麻烦 \n性能的监控比较麻烦。【最好开发一个大屏监控系统】\n\n总的来说优点大过于缺点，目前看来Spring Cloud是一套非常完善的分布式框架，目前很多企业开始用微服务、Spring Cloud的优势是显而易见的。因此对于想研究微服务架构的同学来说，学习Spring Cloud是一个不错的选择。\nSpringBoot和SpringCloud的区别？\nSpringBoot专注于快速方便的开发单个个体微服务。SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务整合并管理起来，为各个微服务之间提供，配置管理、服务发现、断路器、路由、微代理、事件总线、全局锁、决策竞选、分布式会话等等集成服务.\n\nSpringBoot可以离开SpringCloud独立使用开发项目， 但是SpringCloud离不开SpringBoot ，属于依赖的关系,SpringBoot专注于快速、方便的开发单个微服务个体，SpringCloud关注全局的服务治理框架。\n\n\n","categories":["微服务","SpringCloud"],"tags":["SpringBoot","SpringCloud","微服务"]},{"title":"Kafka简析以及SpringBoot整合Kafka应用实践","url":"http://www.vincentli.top/2019/09/04/springcloud-app-kafka/","content":"一、Kafka介绍\nKafka创建背景Kafka 是一个消息系统，原本开发自 LinkedIn，用作 LinkedIn 的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被多家不同类型的公司 作为多种类型的数据管道和消息系统使用。\n活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（Page View）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据（CPU、IO 使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。\nKafka简介Kafka是一种分布式的，基于发布/订阅的消息系统。 \n主要设计目标如下：\n\n以时间复杂度为 O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。\n高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。\n支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。\n同时支持离线数据处理和实时数据处理。\nScale out：支持在线水平扩展。\n\nKafka基础概念专业名称解释\nBroker一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。\nProducer消息生产者，就是向kafka broker发消息的客户端。\nConsumer消息消费者，向kafka broker取消息的客户端。\nTopic每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\nConsumer Group每个Consumer属于一个特定的Consumer Group，可为每个Consumer指定group name，若不指定group name则属于默认的分组。\nPartition一个庞大大的topic可以分布到多个broker上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体的顺序。Partition是物理上的概念，方便在集群中扩展，提高并发。\n\n消息功能\n点对点模式\n\n点对点模型通常是一个基于拉取或者轮询的消息传递模型，消费者主动拉取数据，消息收到后从队列移除消息，这种模型不是将消息推送到客户端，而是从队列中请求消息。特点是发送到队列的消息被一个且只有一个消费者接收处理，即使有多个消费者监听队列也是如此。\n\n发布订阅模式\n\n发布订阅模型则是一个基于推送的消息传送模型，消息产生后，推送给所有订阅者。发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息，即使当前订阅者不可用，处于离线状态。\nKafka如何保证可靠性当我们讨论可靠性的时候，我们总会提到保证*这个词语。可靠性保证是基础，我们基于这些基础之上构建我们的应用。比如关系型数据库的可靠性保证是ACID，也就是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。\nKafka 中的可靠性保证有如下四点：\n\n对于一个分区来说，它的消息是有序的。如果一个生产者向一个分区先写入消息A，然后写入消息B，那么消费者会先读取消息A再读取消息B。\n当消息写入所有in-sync状态的副本后，消息才会认为已提交（committed）。这里的写入有可能只是写入到文件系统的缓存，不一定刷新到磁盘。生产者可以等待不同时机的确认，比如等待分区主副本写入即返回，后者等待所有in-sync状态副本写入才返回。\n一旦消息已提交，那么只要有一个副本存活，数据不会丢失。\n消费者只能读取到已提交的消息。\n\n使用这些基础保证，我们构建一个可靠的系统，这时候需要考虑一个问题：究竟我们的应用需要多大程度的可靠性？可靠性不是无偿的，它与系统可用性、吞吐量、延迟和硬件价格息息相关，得此失彼。因此，我们往往需要做权衡，一味的追求可靠性并不实际。\nQuick Start下载安装Kafka,解压安装包\n从官网下载Kafka的安装包。#1.1 浏览器打开链接 https://www.apache.org/dyn/closer.cgi?path=/kafka/2.6.0/kafka_2.13-2.6.0.tgz#1.2 命令下载 wget https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.6.0/kafka_2.13-2.6.0.tgz  tar -xzf kafka_2.13-2.6.0.tgz cd kafka_2.13-2.6.0\n修改配置,启动服务\n\n\n2.1 修改配置\nvim config/server.properties\n把参数修改成如下图：\n\n2.2 启动服务\n# Start the ZooKeeper service# Note: Soon, ZooKeeper will no longer be required by Apache Kafka.$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties# Start the Kafka broker service$ bin/kafka-server-start.sh -daemon config/server.properties\n\n\n生产消息\nMaven依赖配置&lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;     &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring-kafka--&gt; &lt;dependency&gt;     &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;     &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;     &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;/dependency&gt;\n生产消息application.properties配置spring.application.name=springboot-kafka-app-providerserver.port=8081# ============== kafka ==================# 指定kafka 代理地址，可以多个spring.kafka.bootstrap-servers=127.0.0.1:9092# =============== provider  =======================spring.kafka.producer.retries=0# 每次批量发送消息的数量spring.kafka.producer.batch-size=16384spring.kafka.producer.buffer-memory=33554432# 指定消息key和消息体的编解码方式spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer\n具体生产消息核心代码KafkaProducer/** * kafka消息生产 */@Component@Slf4jpublic class KafkaProducer &#123;    @Resource    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;    private Gson gson = new GsonBuilder().create();    AtomicLong atomicLong = new AtomicLong(0L);    public void send() &#123;        String msg = &quot;中国崛起:&quot;+atomicLong.incrementAndGet();        send(msg);    &#125;    public void send(final String msg) &#123;        Message message = new Message();        message.setId(System.currentTimeMillis());        message.setMsg(msg);        message.setSendTime(new Date());        log.info(&quot;+++++++++++++++++++++send  message = &#123;&#125;&quot;, gson.toJson(message));        kafkaTemplate.send(KafkaTopicConstant.testTopicName, message.getId().toString() , gson.toJson(message));    &#125;\n具体生产消息核心代码MessageController/** * 消息发送controller * @author vincent.li */@RestController@Slf4jpublic class MessageController &#123;    @Autowired    KafkaProducer kafkaProducer;    @GetMapping(value = &quot;/send&quot;)    public String send(String msg)&#123;        try &#123;            kafkaProducer.send(msg);        &#125; catch (Exception e) &#123;            log.error(e.getMessage(), e);            return &quot;failure&quot;;        &#125;        return &quot;success&quot;;    &#125;&#125;\n生产消息服务启动类SpringBootKafkaProducerApplication/*** kafka消息生产服务SpringBoot 启动类* @author vincent.li*/@SpringBootApplication(scanBasePackages = &#123;&quot;com.vincent.app.kafka.producer&quot;&#125;)public class SpringBootKafkaProducerApplication &#123;  public static void main(String[] args) &#123;      ConfigurableApplicationContext context = SpringApplication.run(SpringBootKafkaProducerApplication.class, args);      System.out.println(&quot;O(∩_∩)O哈哈~    【TEST-KAFKA-APP-PRODUCER】启动成功      O(∩_∩)O哈哈~&quot;);      KafkaProducer sender = context.getBean(KafkaProducer.class);      for (int i = 0; i &lt; 1000; i++) &#123;          sender.send();          try &#123;              Thread.sleep(2000);          &#125; catch (InterruptedException e) &#123;              e.printStackTrace();          &#125;      &#125;  &#125;&#125;\n消费消息\nMaven配置&lt;dependency&gt;          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;          &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;          &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;          &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;          &lt;scope&gt;test&lt;/scope&gt;      &lt;/dependency&gt;      &lt;!--spring-kafka--&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;          &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;          &lt;artifactId&gt;gson&lt;/artifactId&gt;      &lt;/dependency&gt;\n消费消息application.properties配置spring.application.name=springboot-kafka-app-consumerserver.port=8082# ============== kafka ==================# 指定kafka 代理地址，可以多个spring.kafka.bootstrap-servers=127.0.0.1:9092#=============== consumer  =======================# 指定默认消费者group idspring.kafka.consumer.group-id=test-demo-consumer-groupspring.kafka.consumer.auto-offset-reset=earliestspring.kafka.consumer.enable-auto-commit=truespring.kafka.consumer.auto-commit-interval=2000# 指定消息key和消息体的编解码方式spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer\n消费消息核心代码/*** kafka消息消费* @author vincent.li*/@Component@Slf4jpublic class KafkaConsumer &#123;  @KafkaListener(topics = &#123;KafkaConsumerTopicConstant.testTopicName&#125;)  public void listen(ConsumerRecord&lt;?, ?&gt; record) &#123;      Optional&lt;?&gt; kafkaMessage = Optional.ofNullable(record.value());      if (kafkaMessage.isPresent()) &#123;          Object message = kafkaMessage.get();          log.info(KafkaConsumerTopicConstant.testTopicName+&quot;----------------- record==&gt;&#123;&#125;&quot;, record);          log.info(KafkaConsumerTopicConstant.testTopicName+&quot;------------------ message==&gt;&#123;&#125;&quot; , message);      &#125;  &#125;&#125;\n消费消息启动服务类SpringBootKafkaConsumerApplication/** * kafka消息消费服务SpringBoot 启动类 * @author vincent.li */@SpringBootApplication(scanBasePackages = &#123;&quot;com.vincent.app.kafka.consumer&quot;&#125;)public class SpringBootKafkaConsumerApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SpringBootKafkaConsumerApplication.class, args);        System.out.println(&quot;O(∩_∩)O哈哈~    【TEST-KAFKA-APP-CONSUMER】启动成功      O(∩_∩)O哈哈~&quot;);    &#125;&#125;\n运行结果\n通过controller方法生产消息\n生产消息服务控制台打印日志\n消费消息服务控制台打印日志\n\n完整demo代码地址Github地址: https://github.com/leechaoqiang/springcloud-app-parentGitee地址：https://gitee.com/chaoqianglee/springcloud-app-parent\n参考资料\n\n官方文档\nKafka 设计解析（一）：Kafka 背景及架构介绍\nKafka技术内幕——图文详解Kafka源码设计与实现\n\n","categories":["博客","消息队列","kafka"],"tags":["Java","kafka","消息队列","MQ","zookeeper"]},{"title":"使用Folk/Join框架实现多核并行计算学习笔记","url":"http://www.vincentli.top/2019/08/12/fork-join-pool-study-note/","content":"背景最近温习《Java虚拟机精讲》的时候，里面有提到使用Folk/Join框架实现多核并行计算，似乎有点陌生又有点熟悉，原来真的好久没用了，根据书上的相关资料，自Java7开始新增在java.util.concurrent包下面新增了基于细粒度的多核并行计算Folk/Join框架。它的主要思想就是讲一个大任务分割成若干小任务，最终汇总每个小任务的结果得到这个大任务的结果。这种思想和开源基金会Apache提供的Hadoop里面MapReduce很像（input –&gt; split –&gt; map –&gt; reduce –&gt; output）\n主要有两步：\n第一、任务切分（Folk）\n第二、结果合并 (Join)\n\n使用说明自JDK1.7开始，java.util.concurrent包下提供了ForkJoinPool来支持将一个任务拆分成多个“小任务”并行计算，再把多个“小任务”的结果合并成总的计算结果。多线程ForkJoinPool运用了Fork/Join原理，使用“分而治之”的思想，将大任务分拆成小任务分配给多个线程执行，最后合并得到最终结果，加快运算。它的模型大致是这样的：线程池中的每个线程都有自己的工作队列（这一点和ThreadPoolExecutor不同，ThreadPoolExecutor是所有线程共用一个工作队列。ForkJoinPool是ExecutorService的实现类，因此是一种特殊的线程池。\n使用方法：创建了ForkJoinPool实例之后，就可以调用ForkJoinPool的submit(ForkJoinTask task) 或invoke(ForkJoinTask task)方法来执行指定任务了。\n其中ForkJoinTask代表一个可以并行、合并的任务。ForkJoinTask是一个抽象类，它还有两个抽象子类：RecusiveAction和RecusiveTask。其中RecusiveTask代表有返回值的任务，而RecusiveAction代表没有返回值的任务。\n代码DEMO\nDemo 1.使用ForkJoinPool完成一个任务的分段执行\n简单的打印0-500的数值。用多线程实现并行执行实现\npackage com.vincent.demo.folkjoin;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.RecursiveAction;import java.util.concurrent.TimeUnit;/** * @Desc 使用ForkJoinPool完成一个任务的分段执行 * 简单的打印0-500的数值。用多线程实现并行执行 * @author   vincent.li * @version   1.0 * @since    JDK 1.7 * @see */public class ForkJoinPoolAction &#123;    public static void main(String[] args) throws Exception &#123;        PrintTask task = new PrintTask(0, 500);        //创建实例，并执行分割任务        ForkJoinPool forkJoinPool = new ForkJoinPool();        forkJoinPool.submit(task);        //线程阻塞，等待所有任务完成        forkJoinPool.awaitTermination(2, TimeUnit.SECONDS);        forkJoinPool.shutdown();    &#125;&#125;/** * @Desc: 继承RecursiveAction来实现“可分解”的任务。 * * @author vincent.li * @version 1.0 * @since JDK 1.7 */class PrintTask extends RecursiveAction &#123;    //最多只能打印50个数    private static final int THRESHOLD = 50;    private int start;    private int end;    public PrintTask(int start, int end) &#123;        super();        this.start = start;        this.end = end;    &#125;    @Override    protected void compute() &#123;        if(end - start &lt; THRESHOLD)&#123;            for(int i = start; i &lt; end; i++)&#123;                System.out.println(Thread.currentThread().getName()+&quot;打印i值&gt;&gt;&gt;&quot;+i);            &#125;        &#125;else &#123;            int middle = (start + end) / 2;            PrintTask left = new PrintTask(start, middle);            PrintTask right = new PrintTask(middle, end);            //并行执行两个“小任务”            left.fork();            right.fork();        &#125;    &#125;&#125;\n\n执行结果如下：··················ForkJoinPool-1-worker-6打印i值&gt;&gt;&gt;282ForkJoinPool-1-worker-2打印i值&gt;&gt;&gt;219ForkJoinPool-1-worker-3打印i值&gt;&gt;&gt;343ForkJoinPool-1-worker-4打印i值&gt;&gt;&gt;97ForkJoinPool-1-worker-0打印i值&gt;&gt;&gt;31ForkJoinPool-1-worker-4打印i值&gt;&gt;&gt;98ForkJoinPool-1-worker-3打印i值&gt;&gt;&gt;344ForkJoinPool-1-worker-2打印i值&gt;&gt;&gt;220ForkJoinPool-1-worker-6打印i值&gt;&gt;&gt;283ForkJoinPool-1-worker-7打印i值&gt;&gt;&gt;2ForkJoinPool-1-worker-5打印i值&gt;&gt;&gt;408··················\n\n\n\n我的Macbook是2.2 GHz Intel Core i7,是8核的，由线程名称可以知道，8个CPU都参与了执行，其实我们ForkJoinPool默认会开启和CPU核数一样的线程数。\n\n\nDemo 2.对一个长度为100000000的数组的元素进行累加求和package com.vincent.demo.folkjoin;import java.util.Random;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.Future;import java.util.concurrent.RecursiveTask;/** * @Desc 对一个长度为100000000的数组的元素进行累加求和 * @author   vincent.li * @version   1.0 * @since    JDK 1.7 * @see */public class ForJoinPollTask &#123;    public static void main(String[] args) throws Exception &#123;        long[] arr = new long[100000000];        Random random = new Random();        long total =0L;        int len = arr.length;        //初始化10000000个数组元素        for(int i=0; i&lt;len; i++)&#123;            int temp = random.nextInt(50);            arr[i]=Long.valueOf(temp).longValue() ;        &#125;        System.out.println(&quot;数组初始化完成。。。&quot;);        long start = System.currentTimeMillis();        for(int i=0; i&lt;len; i++)&#123;            //对数组元素赋值，并将数组元素的值添加到sum总和中            total += arr[i];        &#125;        long timeCost = System.currentTimeMillis() - start;        System.out.println(&quot;for循环累加求和结果：&quot; + total + &quot;,耗时：&quot; + timeCost + &quot; ms&quot;);        start = System.currentTimeMillis();        SumTask task = new SumTask(arr, 0, len);//        创建一个通用池，这个是jdk1.8提供的功能        ForkJoinPool pool = ForkJoinPool.commonPool();        Future&lt;Long&gt; future = pool.submit(task); //提交分解的SumTask 任务        timeCost = System.currentTimeMillis() - start;        System.out.println(&quot;多线程执行求和结果：&quot;+future.get()+ &quot;,耗时：&quot; + timeCost + &quot; ms&quot;);        pool.shutdown(); //关闭线程池    &#125;&#125;/** * @Desc: 继承抽象类RecursiveTask，通过返回的结果，来实现数组的多线程分段累累加 *  RecursiveTask 具有返回值 * * @author vincent.li * @version 1.0 * @since JDK 1.7 */class SumTask extends RecursiveTask&lt;Long&gt; &#123;    private static final int THRESHOLD = 50; //每个小任务 最多只累加50个数    private long arry[];    private int start;    private int end;    /**     * Creates a new instance of SumTask.     * 累加从start到end的arry数组     * @param arry     * @param start     * @param end     */    public SumTask(long[] arry, int start, int end) &#123;        super();        this.arry = arry;        this.start = start;        this.end = end;    &#125;    @Override    protected Long compute() &#123;        long sum = 0L;        //当end与start之间的差小于threshold时，开始进行实际的累加        if(end - start &lt; THRESHOLD)&#123;            for(int i = start; i &lt; end; i++)&#123;                sum += arry[i];            &#125;            return sum;        &#125; else &#123;            //当end与start之间的差大于threshold，即要累加的数超过50个时候，将大任务分解成小任务            int middle = (start+ end)/2;            SumTask left = new SumTask(arry, start, middle);            SumTask right = new SumTask(arry, middle, end);            //并行执行两个 小任务            left.fork();            right.fork();            //把两个小任务累加的结果合并起来            return left.join()+right.join();        &#125;    &#125;&#125;\n执行结果如下：数组初始化完成。。。for循环累加求和结果：2450102493,耗时：86 ms多线程执行求和结果：2450102493,耗时：3 ms\n我们这次是针对长度1亿的数组的所有元素求和，很明显看出多核并行计算执行效率缴传统for循环累加高了20多将近30倍，如果我们采用这个多核并行计算框架来处理海量数据，那效率必须杠杠的。\n\n分析自JDK1.7开始，Java中引入了可以多核并行计算一种新的线程池：ForkJoinPool。它同ThreadPoolExecutor一样，也实现了Executor和ExecutorService接口。它使用了一个无限队列来保存需要执行的任务，而线程的数量则是通过构造函数传入，如果没有向构造函数中传入希望的线程数量，那么当前计算机可用的CPU数量会被设置为线程数量作为默认值。ForkJoinPool主要用来使用 分治算法(Divide-and-Conquer Algorithm)来解决问题。典型的应用比如快速排序算法。\n他们区别在于，ForkJoinPool可以使用相对少的线程来处理大量的任务，对于有限资源可以充分使用。\n比如要对1000万个数据进行排序，那么会将这个任务分割成两个500万的排序任务和一个针对这两组500万数据的合并任务。以此类推，对于500万的数据也会做出同样的分割处理，到最后会设置一个阈值来规定当数据规模到多少时，停止这样的分割处理。比如，当元素的数量小于10时，会停止分割，转而使用插入排序对它们进行排序。\n那么到最后，所有的任务加起来会有大概2000000+个。问题的关键在于，对于一个任务而言，只有当它所有的子任务完成之后，它才能够被执行。\n所以当使用ThreadPoolExecutor时，使用分治法会存在问题，因为ThreadPoolExecutor中的线程无法像任务队列中再添加一个任务并且在等待该任务完成之后再继续执行。而使用ForkJoinPool时，就能够让其中的线程创建新的任务，并挂起当前的任务，此时线程就能够从队列中选择子任务执行。\n 以上程序的关键方法是fork()和join()方法。在ForkJoinPool使用的线程中，会使用一个内部队列来对需要执行的任务以及子任务进行操作来保证它们的执行顺序。\n那么使用ThreadPoolExecutor或者ForkJoinPool，会有什么性能的差异呢？\n首先，使用ForkJoinPool能够使用数量有限的线程来完成非常多的具有父子关系的任务，比如使用4个线程来完成超过200万个任务。但是，使用ThreadPoolExecutor时，是不可能完成的，因为ThreadPoolExecutor中的Thread无法选择优先执行子任务，需要完成200万个具有父子关系的任务时，也需要200万个线程，显然这是不可行的。\nNotice: ForkJoinPool在执行过程中，会创建大量的子任务，这会导致GC进行垃圾回收，这里可能带来一些系统卡顿的风险。\n","categories":["博客","Java"],"tags":["Java","多线程","ForkJoinPool"]},{"title":"RabbitMQ分析全解之快速开始实现一个demo","url":"http://www.vincentli.top/2019/08/10/rabbitmq-quitstart-practise/","content":"RabbitMQ的安装、Web管理、命令行控制基础操作主要包括：安装服务器，查看Web管理页面，使用控制行操作相关内容。\n安装服务器安装ErlangRabbitMQ主要依赖Erlang，因此必须先安装erlang。\nerlang主要有三个方式来安装。具体内容参考： http://www.rabbitmq.com/install-rpm.html这里选择第二种进行安装。\n\n安装erlang-solution的配置信息wget http://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpm\n运行yum，安装erlang.rpm表sudo yum install erlang``` 3. 测试，运行 erl命令#### 安装RabbitMQ1. 我们这里选择手动下载rabbitmq安装包，当然也可以选择rpm和yum进行安装。\nwget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.15/rabbitmq-server-mac-standalone-3.6.15.tar.xz2. 启动服务和检查服务是否正常启动\n./sbin/rabbitmq-plugins enable rabbitmq_management\n\n./sbin/rabbitmq-server -detached  #这是后台服务运行\n./sbin/rabbitmqctl status  #监测服务状态3. 查看Web管理平台界面  浏览器打开http://localhost:15672/  用户名和密码 是 guest／guest4. 新增用户admin并设置状态administrator./sbin/rabbitmqctl add_user admin 123456\n./sbin/rabbitmqctl set_user_tags admin administrator\n[rabbitmq官方参考资料：https://www.rabbitmq.com/management.html#configuration](https://www.rabbitmq.com/management.html#configuration)### 采用广播模式Fanout实现一个发送接收消息的demo#### 生产消息* Maven依赖配置```xml     &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;           &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;           &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;           &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;           &lt;scope&gt;test&lt;/scope&gt;       &lt;/dependency&gt;      &lt;!-- rabbitmq 依赖 --&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;           &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;           &lt;artifactId&gt;gson&lt;/artifactId&gt;       &lt;/dependency&gt;\n\n生产消息配置spring.application.name=springboot-rabbitmq-app-providerserver.port=8084#rabbitmq相关配置spring.rabbitmq.host = 127.0.0.1spring.rabbitmq.port = 5672spring.rabbitmq.username = adminspring.rabbitmq.password = 123456# 自定义配置应用于消息生产#交换器名称rabbitmq.config.exchange = mc.Ex.demo.test#自定义队列名称rabbitmq.producer.queue.name =mc.queue.demo.test\n生产消息Rabbitmq配置/** * @author vincent.li * @Description Rabbitmq配置 * @since 2019/8/10 */@Componentpublic class RabbitmqConfig &#123;    @Value(&quot;$&#123;rabbitmq.config.exchange&#125;&quot;)    private String fanoutExchangeName;    @Value(&quot;$&#123;rabbitmq.producer.queue.name&#125;&quot;)    private String producerQueueName;    @Bean    public FanoutExchange fanoutExchange() &#123;        return new FanoutExchange(fanoutExchangeName, true, false);    &#125;    @Bean(name = &quot;basicQueue&quot;)    public Queue basicQueue() &#123;        return new Queue(producerQueueName, true);    &#125;    @Bean    public Binding basicBinding() &#123;        return BindingBuilder.bind(basicQueue()).to(fanoutExchange());    &#125;&#125;\n生产消息方法/** * @author vincent.li * @Description Rabbitmq消息生产控制器 * @since 2019/8/9 */@Slf4j@RestController@RequestMapping(value = &quot;rabbitmq&quot;)public class RabbitmqProduceController &#123;    @Autowired    private RabbitTemplate rabbitTemplate;    @Value(&quot;$&#123;rabbitmq.config.exchange&#125;&quot;)    private String fanoutExchangeName;    /**     * 发送消息     * @param msg     * @return     */    @GetMapping(&quot;/message/send&quot;)    public BaseResponse sendMessage(@RequestParam String msg)&#123;        if (StringUtils.isEmpty(msg)) &#123;            return BaseResponse.fail(&quot;请输入有效参数&quot;);        &#125;        try &#123;            log.info(&quot;待发送的消息： &#123;&#125; &quot;, msg);            rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter());            rabbitTemplate.setExchange(fanoutExchangeName);            Message message = Message.builder()                    .id(System.currentTimeMillis())                    .msg(msg)                    .sendTime(new Date())                    .build();            rabbitTemplate.convertAndSend(message);        &#125;catch (Exception e)&#123;            log.error(&quot;发送消息发生异常： &quot;, e.fillInStackTrace());            return BaseResponse.fail(&quot;发送消息发生异常&quot;);        &#125;        return BaseResponse.success();    &#125;&#125;\n\n\n接收消息\nMaven依赖配置\n&lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;      &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt;  &lt;!-- rabbitmq 依赖 --&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;      &lt;artifactId&gt;gson&lt;/artifactId&gt;  &lt;/dependency&gt;\n\n接收消息配置\nspring.application.name=springboot-rabbitmq-app-consumerserver.port=8083spring.rabbitmq.host = 127.0.0.1spring.rabbitmq.port = 5672spring.rabbitmq.username = adminspring.rabbitmq.password = 123456# 自定义配置应用于消息消费#交换器名称rabbitmq.config.exchange = mc.Ex.demo.test#自定义队列名称rabbitmq.consumer.queue.name =mc.queue.demo.test.consumerabbitmq.consumer.2.queue.name = mc.queue.demo.test.consume2\n\n接收消息consumer-1\n/** * @author vincent.li * @Description rabbitmq广播模式消费 * @since 2019/8/9 */@Component@RabbitListener(bindings = @QueueBinding(        value = @Queue(value = &quot;$&#123;rabbitmq.consumer.queue.name&#125;&quot;, durable = &quot;true&quot;, autoDelete = &quot;false&quot;),        exchange = @Exchange(value = &quot;$&#123;rabbitmq.config.exchange&#125;&quot;, type = ExchangeTypes.FANOUT)))public class RabbitmqFanoutConsumer &#123;    /**     * 设置监听方法     *     * @param message     * @RabbitHandler 声明监听方法是下面的 isDefault属性是默认false接受的完整对象，true接受body体     */    @RabbitHandler(isDefault = true)    public void process(byte[] message) &#123;        System.out.println(&quot;Fanout-1 Receiver : &quot; + new String(message));    &#125;&#125;\n接收消息consumer-2/** * @author vincent.li * @Description rabbitmq广播模式消费 * @since 2019/8/9 */@Component@RabbitListener(bindings = @QueueBinding(        value = @Queue(value = &quot;$&#123;rabbitmq.consumer.2.queue.name&#125;&quot;, durable = &quot;true&quot;, autoDelete = &quot;false&quot;),        exchange = @Exchange(value = &quot;$&#123;rabbitmq.config.exchange&#125;&quot;, type = ExchangeTypes.FANOUT)))public class RabbitmqFanoutConsumer2 &#123;    /**     * 设置监听方法     *     * @param message     * @RabbitHandler 声明监听方法是下面的 isDefault属性是默认false接受的完整对象，true接受body体     */    @RabbitHandler(isDefault = true)    public void process(byte[] message) &#123;        System.out.println(&quot;Fanout-2 Receiver : &quot; + new String(message));    &#125;&#125;\n\n\n运行结果\n发送消息：\n\n\n\n\n接受消息：\n\n\n具体完整代码可以移步github:springcloud-app-rabbitmq\n","categories":["RabbitMQ","博客","消息队列"],"tags":["Java","消息队列","MQ","RabbitMQ"]},{"title":"RabbitMQ分析全解之RabbitMQ介绍","url":"http://www.vincentli.top/2019/08/01/rabbitmq-complete-analysis/","content":"RabbitMQ介绍什么是RabbitMQ？RabbitMQ是一套开源（MPL）的消息队列服务软件，是由 LShift 提供的一个 Advanced Message Queuing Protocol (AMQP，高级消息队列协议) 的开源实现，由以高性能、健壮以及可伸缩性出名的 Erlang 写成。最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。\nRabbitMQ主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。例如一个日志系统，很容易使用RabbitMQ简化工作量，一个Consumer可以进行消息的正常处理，另一个Consumer负责对消息进行日志记录，只要在程序中指定两个Consumer所监听的queue以相同的方式绑定到同一exchange即可，剩下的消息分发工作由RabbitMQ完成。\n单向解耦“Producer”--           |           |-----&gt;&quot;RabbitMQ Clusters&quot; ---&gt; “Consumer”&quot;Producer&quot;--\n双向解耦（如：RPC）“Producer1”--&gt;           |           |&lt;-----&gt;&quot;RabbitMQ Clusters&quot; &lt;---&gt; “Consumer2&amp;Producer2”&quot;Consumer1&quot;&lt;--\nRabbitMQ的使用基础使用RabbitMQ server需要： \n\nErLang语言包； \nRabbitMQ安装包；\n\n基础概念交换机（exchange）：\n接收消息，转发消息到绑定的队列。四种类型：direct, topic, headers and fanout\n\n\ndirect：转发消息到routigKey指定的队列\ntopic：按规则转发消息（最灵活）\nheaders：（这个还没有接触到）\nfanout：转发消息到所有绑定队列（广播模式）\n\n\n如果交换机上(Exchange）和（Queue）是多对多的关系。\n\ntopic类型交换器通过模式匹配分析消息的routing-key属性。它将routing-key和binding-key的字符串切分成单词。这些单词之间用点隔开。\n支持表达式：   *.foo.bar  # 只要包含foo.bar就可以匹配相关信息。这个是topic，性能最慢   demo   # 这个是direct,性能最好。\n\n因为交换器是在RabbitMQ是一个实际存在的实体，不能被改变。只能删除之后，重新创建。\n\n交换器的属性：\n\n\n\n持久性：如果启用，交换器将会在server重启前都有效。（对应Duration属性，持久化）\n自动删除：如果启用，那么交换器将会在其绑定的队列都被删除掉之后自动删除掉自身。（创建时候设置，如果不设置不会自动删除）。\n惰性：如果没有声明交换器，那么在执行到使用的时候会导致异常，并不会主动声明。（不会自动创建）队列（queue）：\n\n\n队列是RabbitMQ内部对象，存储消息。相同属性的queue可以重复定义。\n\n临时队列。channel.queueDeclare()，有时不需要指定队列的名字，并希望断开连接时删除队列。\n\n\n队列的属性：\n\n持久性：如果启用，队列将会在server重启前都有效。\n自动删除：如果启用，那么队列将会在所有的消费者停止使用之后自动删除掉自身。\n惰性：如果没有声明队列，那么在执行到使用的时候会导致异常，并不会主动声明。\n排他性：如果启用，队列只能被声明它的消费者使用。\n消息传递：\n\n消息在队列中保存，以轮询的方式将消息发送给监听消息队列的消费者，可以动态的增加消费者以提高消息的处理能力。为了实现负载均衡，可以在消费者端通知RabbitMQ，一个消息处理完之后才会接受下一个消息。 channel.basic_qos(prefetch_count=1) 注意：效率非常低，不能使用客户端缓存。消息有14个属性，最常用的几种：\n\ndeliveryMode：持久化属性\n\n\ncontentType：编码\nreplyTo：指定一个回调队列\ncorrelationId：消息id在client代码中，send方法时候，可以设置mandatory和immediate。设置mandatory:发送到交换器并且还未投递到队列（没有绑定器存在）得到通知。设置immediate：没有消费者能够立即处理的时候得到通知。这些投递保障机制，保证了消息可靠性。\n\n在client代码中，send方法时候persistent属性为true。数据就会被保存到队列中，但是必须Exchange,Queue,Client三者都设置为存储状态。\nRabbitMQ特性高可用性（HA）\n消息ACK，通知RabbitMQ消息已被处理，可以从内存删除。如果消费者因宕机或链接失败等原因没有发送ACK（不同于ActiveMQ，在RabbitMQ里，消息没有过期的概念），则RabbitMQ会将消息重新发送给其他监听在队列的下一个消费者。channel.basicConsume(queuename, noAck=false, consumer);\n消息和队列的持久化。定义队列时可以指定队列的持久化属性（问：持久化队列如何删除？） channel.queueDeclare(queuename, durable=true, false, false, null); 发送消息时可以指定消息持久化属性：这样，即使RabbitMQ服务器重启，也不会丢失队列和消息。channel.basicPublish(exchangeName, routingKey,MessageProperties.PERSISTENT_TEXT_PLAIN,message.getBytes());\npublisher confirms 提供批量确认消息的方法。\nmaster/slave机制，配合Mirrored Queue。Mirrored Queue通过policy和rabbitmqctl设置可以实现。具体可以参考Rabbitmq官方文档。在Mirrored Queue下，无论Producer和Consumer连接那个RabbitMq服务器，都跟连接同一个RabbitMQ上，消费和生产数据会被同步。注意：Mirrored Queue会严重的消耗性能，性能会下降到原来的1/5。当一个slave重新加入mirrored-queue时，如果queue是durable的，则会被清空。通过命令行或管理插件可以查看哪个slave是同步的：rabbitmqctl list_queues name slave_pids synchronised_slave_pids\n\n\n集群（cluster）\n不支持跨网段，因为RabbitMQ底层是Erlang，会导致脑裂（Slave Node感觉Master Node死掉了，主Master Node觉得Slave2 Node死掉了，结果数据无法复制，系统逻辑出现问题）（如需支持，需要shovel或federation插件）\n可以随意的动态增加或减少、启动或停止节点，允许节点故障。（但是数据同步会造成Queue服务暂停，所有的Producer和Consumer都被终止）\n集群分为RAM节点和DISK节点，一个集群最好至少有一个DISK节点保存集群的状态。\n集群的配置可以通过命令行，也可以通过配置文件，命令行优先。\n\n参考资料\n透彻rabbitmq\n\n","categories":["RabbitMQ","博客","消息队列"],"tags":["Java","消息队列","MQ","RabbitMQ"]},{"title":"秒杀系统扣减库存的常见几种设计","url":"http://www.vincentli.top/2019/07/29/seconds-kill-when-reduce-sku-stock-design/","content":"背景我以前参与做过一个社交电商平台，其中就有秒杀场景，现在我从事的互联网酒店行业也有类似的秒杀场景，所以准备写一点关于秒杀相关的文字，就当总结记录一下吧。秒杀最主要的一个业务部门和我们技术部门需要注意一点，就是要防止超卖，而这个是电商行业经常会出现的现象。没有接触过秒杀的童鞋，可能会觉得，库存 200 件就卖 200 件，在数据库里减到 0 不就好了啊，这有什么好麻烦的？是的，理论上是这样，但是具体到业务场景中，“减库存”就不是这么简单了。例如，我们平常在淘宝或者京东上购物都是这样，看到喜欢的商品然后下单，但并不是每个下单请求你都最后付款了。你说系统是用户下单了就算这个商品卖出去了，还是等到用户真正付款了才算卖出了呢？这是个值得我们一起探讨问题！我们可以先根据减库存是发生在下单阶段还是付款阶段，把减库存做一下划分。\n扣减库存主要有哪几种方式呢在正常的电商平台购物场景中，用户的实际购买过程一般分为两步：下单 和 付款。你想买一台佳能单反相机，在商品页面点了“立即购买”按钮，核对信息之后点击“提交订单”，这一步称为下单操作。下单之后，你只有真正完成付款操作才能算真正购买，也就是俗话说的“落袋为安”。那如果你是架构师，你会在哪个环节完成减库存的操作呢？总结来说，减库存操作一般有如下几个方式：\n\n下单减库存，即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。\n付款减库存，即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。\n预扣库存，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如30分钟,早期12306的票就是下单后保留30分钟的支付时间，现在好像是15分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。\n\n以上这几种减库存的方式也会存在一些问题，下面我们一起来看下。\n减库存可能存在的问题由于购物过程中存在两步或者多步的操作，因此在不同的操作步骤中减库存，就会存在一些可能被恶意买家利用的漏洞，例如发生恶意下单的情况。假如我们采用“下单减库存”的方式，即用户下单后就减去库存，正常情况下，买家下单后付款的概率会很高，所以不会有太大问题。但是有一种场景例外，就是当卖家参加某个活动时，此时活动的有效时间是商品的黄金售卖时间，如果有竞争对手通过恶意下单的方式将该卖家的商品全部下单，让这款商品的库存减为零，那么这款商品就不能正常售卖了。要知道，这些恶意下单的人是不会真正付款的，这正是“下单减库存”方式的不足之处。既然“下单减库存”可能导致恶意下单，从而影响卖家的商品销售，那么有没有办法解决呢？你可能会想，采用“付款减库存”的方式是不是就可以了？的确可以。但是，“付款减库存”又会导致另外一个问题：库存超卖。假如有 200 件商品，就可能出现 500 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。这样一来，就会导致很多买家下单成功但是付不了款，买家的购物体验自然比较差。可以看到，不管是“下单减库存”还是“付款减库存”，都会导致商品库存不能完全和实际售卖情况对应起来的情况，看来要把商品准确地卖出去还真是不容易啊！那么，既然“下单减库存”和“付款减库存”都有缺点，我们能否把两者相结合，将两次操作进行前后关联起来，下单时先预扣，在规定时间内不付款再释放库存，即采用“预扣库存”这种方式呢？这种方案确实可以在一定程度上缓解上面的问题。但是否就彻底解决了呢？其实没有！针对恶意下单这种情况，虽然把有效的付款时间设置为 15 分钟，但是恶意买家完全可以在 15 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。例如，给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买2件），以及对重复下单不付款的操作进行次数限制等。针对 “库存超卖” 这种情况，在 15 分钟时间内下单的数量仍然有可能超过库存数量，遇到这种情况我们只能区别对待：对普通的商品下单数量超过库存数量的情况，可以通过补货来解决；但是有些卖家完全不允许库存为负数的情况，那只能在买家付款时提示库存不足。大型秒杀中如何减库存？目前来看，业务系统中最常见的就是预扣库存方案，像你在买火车票、买电影票时，下单后一般都有个“有效付款时间”，超过这个时间订单自动释放，这都是典型的预扣库存方案。而具体到秒杀这个场景，应该采用哪种方案比较好呢？由于参加秒杀的商品，一般都是“抢到就是赚到”，所以成功下单后却不付款的情况比较少，再加上卖家对秒杀商品的库存有严格限制，所以秒杀商品采用“下单减库存”更加合理。另外，理论上由于 “下单减库存”比 “预扣库存”以及涉及第三方支付的“付款减库存”在逻辑上更为简单，所以性能上更占优势。“下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种 解决方案：\n\n一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；\n另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错；\n再有一种就是使用 CASE WHEN 判断语句，例如这样的 SQL 语句：\nUPDATE goods SET stock = CASE WHEN stock &gt;= ? THEN stock- ? ELSE stock END  \n秒杀减库存的极致优化在交易环节中，“库存”是个关键数据，也是个热点数据，因为交易的各个环节中都可能涉及对库存的查询。但是，我在前面介绍分层过滤时提到过，秒杀中并不需要对库存有精确的一致性读，把库存数据放到缓存（Cache）中，可以大大提升读性能。解决大并发读问题，可以采用 LocalCache（即在秒杀系统的单机上缓存商品相关的数据）和对数据进行分层过滤的方式，但是像减库存这种大并发写无论如何还是避免不了，这也是秒杀场景下最为核心的一个技术难题。因此，这里我想专门来说一下秒杀场景下减库存的极致优化思路，包括如何在缓存中减库存以及如何在数据库中减库存。秒杀商品和普通商品的减库存还是有些差异的，例如商品数量比较少，交易时间段也比较短，因此这里有一个大胆的假设，即能否把秒杀商品减库存直接放到缓存系统中实现，也就是直接在缓存中减库存或者在一个带有持久化功能的缓存系统（如 Redis）中完成呢？如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。由于MySQL存储数据的特点，同一数据在数据库里肯定是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁，而并发度越高时等待线程会越多，TPS（Transaction Per Second，即每秒处理的消息数）会下降，RT（Request Time,即响应时间）会上升，数据库的吞吐量就会严重受影响。这就可能引发一个问题，就是单个热点商品会影响整个数据库的性能， 导致 0.01% 的商品影响 99.99% 的商品的售卖，这是我们不愿意看到的情况。一个解决思路是遵循前面介绍的原则进行隔离，把热点商品放到单独的热点库中。但是这无疑会带来维护上的麻烦，比如要做热点数据的动态迁移以及单独的数据库等。而分离热点商品到单独的数据库还是没有解决并发锁的问题，我们应该怎么办呢？要解决并发锁的问题，有两种办法：\n\n应用层做排队。按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。\n\n数据库层做排队。应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。阿里的数据库团队开发了针对这种 MySQL 的 InnoDB 层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。\n\n你可能有疑问了，排队和锁竞争不都是要等待吗，有啥区别？如果熟悉 MySQL 的话，你会知道 InnoDB 内部的死锁检测，以及 MySQL Server 和 InnoDB 的切换会比较消耗性能，据说淘宝的MySQL 核心团队还做了很多其他方面的优化，如 COMMIT_ON_SUCCESS 和 ROLLBACK_ON_FAIL 的补丁程序，配合在 SQL 里面加提示（hint），在事务里不需要等待应用层提交（COMMIT），而在数据执行完最后一条 SQL 后，直接根据 TARGET_AFFECT_ROW 的结果进行提交或回滚，可以减少网络等待时间（平均约 0.7ms）。据说目前阿里MySQL团队已经将包含这些补丁程序的 MySQL 开源。另外，数据更新问题除了前面介绍的热点隔离和排队处理之外，还有些场景（如对商品的 last_updated_time 字段的）更新会非常频繁，在某些场景下这些多条 SQL 是可以合并的，一定时间内只要执行最后一条 SQL 就行了，以便减少对数据库的更新操作。\nSUMMARY围绕商品减库存的场景，本文介绍了减库存的三种实现方案，以及分别存在的问题和可能的缓解办法。当然减库存还有很多细节问题，例如预扣的库存超时后如何进行库存回补，再比如目前都是第三方支付，如何在付款时保证减库存和成功付款时的状态一致性，都是值得我们去探讨和研究的。\n\n本文参考很多网络上的材料，如有侵权，请联系vincentlee99@126.com删除。\n\n","categories":["博客","Java","分布式"],"tags":["分布式","秒杀","电商","扣减库存","超卖","淘宝","京东","12306"]},{"title":"Docker容器化部署SpringBoot应用实践","url":"http://www.vincentli.top/2019/06/19/docker-java-app-practise/","content":"一、Background\nSpring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can &quot;just run&quot;.\n用SpringBoot开发构建基于Spring的SpringBoot Apps应用服务是超级简单，但是多个实例同时部署到虚机，需要先上传包然后使用类似java -Dserver.port=8080 -jar app.jar命令启动。现在docker容器化技术已经发展很成熟，采用docker容器化部署SpringBoot Apps也是so easy.\n二、构建基于SpringBoot的Java应用容器化Docker部署1. 项目结构\n2. 基于SpringBoot的Java应用构建准备\npom.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;parent&gt;        &lt;artifactId&gt;springcloud-app-docker&lt;/artifactId&gt;        &lt;groupId&gt;com.licq&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;springcloud-app-docker-java-helloworld&lt;/artifactId&gt;    &lt;name&gt;springcloud-app-docker-java-helloworld&lt;/name&gt;    &lt;packaging&gt;jar&lt;/packaging&gt;    &lt;description&gt;docker-java应用helloworld&lt;/description&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt;        &lt;pluginManagement&gt;            &lt;plugins&gt;                &lt;plugin&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                    &lt;configuration&gt;                    &lt;skip&gt;true&lt;/skip&gt;                    &lt;/configuration&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/pluginManagement&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;source&gt;8&lt;/source&gt;                    &lt;target&gt;8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;\n\n创建一个Api测试HelloController\npackage com.vincent.springcloud.app.docker.controller;import com.alibaba.fastjson.JSONObject;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.bind.annotation.RestController;/** * @author vincent.li * @Description docker-app-hello-world * @since 2019/6/29 */@RestControllerpublic class HelloController &#123;    @Value(&quot;$&#123;server.port&#125;&quot;)    private String serverPort;    @Value(&quot;$&#123;spring.application.name&#125;&quot;)    private String applicationName;    @ResponseBody    @GetMapping(&quot;/hello/&#123;name&#125;&quot;)    public JSONObject hello(@PathVariable(&quot;name&quot;) String name)&#123;        return new JSONObject()                .fluentPut(&quot;hello&quot;, name)                .fluentPut(&quot;application&quot;, applicationName)                .fluentPut(&quot;port&quot;, serverPort);    &#125;&#125;\n\nSpringBoot应用启动类\n\n\npackage com.vincent.springcloud.app.docker;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import java.util.TimeZone;/** * @author vincent.li * @Description api提供服务 * @since 2019/6/29 */@SpringBootApplication(scanBasePackages = &#123;&quot;com.vincent.springcloud.app.docker&quot;&#125;)public class SpringCloudAppDockerApplication &#123;    public static void main(String[] args) &#123;        TimeZone.setDefault(TimeZone.getTimeZone(&quot;Asia/Shanghai&quot;));        SpringApplication.run(SpringCloudAppDockerApplication.class, args);        System.out.println(&quot;(#^.^#)   【SpringCloud-docker-app-hello-world】启动成功      (#^.^#)&quot;);    &#125;&#125;\n3. SpringBoot应用打包成jarmvn clean install -DskipTests\n4. 编写Dockerfile#从公共仓库下载java:8到本地容器FROM java:8#申明作者可以不写MAINTAINER vincent.li vincentlee99@126.com#WORKDIR：工作目录，类似于cd命令#把maven打包好的jar拷贝到容器中并命名为app.jarCOPY target/springcloud-app-docker-java-helloworld.jar app.jar#ENV：设置环境变量ENV LANG C.UTF-8#配置容器，使其可执行化。配合CMD可省去&quot;application&quot;，只使用参数。ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/app.jar&quot;]#EXPOSE：指定于外界交互的端口EXPOSE 8080#VOLUME：用于指定持久化目录\n5. 构建Docker镜像在Dockerfile文件所在的目录执行以下docker命令构建镜像\ndocker build -t demo-helloworld .\n镜像构建完成后可以采用以下docker命令查看我们自己构建的镜像\ndocker image ls\n\n6. 使用镜像启动容器执行如下docker命令可以启动镜像\ndocker run -d -p 8099:8080 demo-helloworld\n启动命令中-d是以后台守护进程的方式执行，-p映射宿主机和容器内部执行应用服务的端口，上面的命令是把宿主机的8099端口映射到容器的8080端口，通过这些配置，我们就把docker容器的8080端口对应的服务提供给外面访问了。\n三、验证容器化部署应用\n我可以通过docker命令查看容器进程,可以查看到我们demo-helloworld镜像的容器在运行,以及相关端口映射信息。\n\ndocker ps\n命令执行结果如下图：\n\n\n也可以通过执行下面的docker命令进入容器内部查看应用的jar包位置。docker exec -it 3156c04e6d6c /bin/bash其中3156c04e6d6c为对应的容器id.命令执行结果如下图：\n\n\n通过http请求调用验证我们的应用是否能正常提供服务，在宿主上的浏览器上打开链接 http://localhost:8099/hello/docker，可以看到如下返回就说明服务正常了。&#123;    &quot;application&quot;:&quot;springcloud-docker-app-hello-world&quot;,    &quot;port&quot;:&quot;8080&quot;,    &quot;hello&quot;:&quot;docker&quot;&#125;\n也可以使用curl http://localhost:8099/hello/docker命令验证。\nOne More Thing我们如果想在同一台虚机上采用容器化部署多个应用怎么做了呢？很简单，只需要执行以下类似命令多条就可以实现，很方便。\ndocker run -d -p 8081:8080 demo-helloworlddocker run -d -p 8082:8080 demo-helloworlddocker run -d -p 8083:8080 demo-helloworld\n当然实际情况我们不可能是只有一台虚机，是多台虚机资源来部署，重复一条一条去执行命令肯定是不行的，这个可以结合jenkins,gitlab等工具，这个后面就涉及到CI/CD以及使用k8s来管理虚机资源和docker容器化服务治理和编排，后面有时间的时候再写一篇关于k8s可落地实践的文章。\n","categories":["Docker","SpringBoot"],"tags":["Java","SpringBoot","Docker","容器化"]},{"title":"Docker入门","url":"http://www.vincentli.top/2019/06/18/docker-introduce/","content":"概念\n\n\n名词\n解释\n\n\n\n\nDocker 镜像 (Images)\nDocker 镜像是用于创建 Docker 容器的模板。\n\n\nDocker 容器(Container)\n容器是独立运行的一个或一组应用。\n\n\nDocker 客户端(Client)\nDocker 客户端通过命令行或者其他工具使用 Docker API 与 Docker 的守护进程通信。\n\n\nDocker 客户端(Client)\nDocker 客户端通过命令行或者其他工具使用 Docker API 与 Docker 的守护进程通信。\n\n\n\nDocker 主机(Host)|一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。|Docker 仓库(Registry)|Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。Docker Hub 提供了庞大的镜像集合供使用。|Docker  Machine |Docker Machine 是一个简化 Docker 安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装 Docker，比如 VirtualBox、 Digital Ocean、Microsoft Azure。|\nDocker 的出现一定是因为目前的后端在开发和运维阶段确实需要一种虚拟化技术解决开发环境和生产环境环境一致的问题，通过 Docker 我们可以将程序运行的环境也纳入到版本控制中，排除因为环境造成不同运行结果的可能。但是上述需求虽然推动了虚拟化技术的产生，但是如果没有合适的底层技术支撑，那么我们仍然得不到一个完美的产品。本文剩下的内容会介绍几种 Docker 使用的核心技术，如果我们了解它们的使用方法和原理，就能清楚 Docker 的实现原理。Docker 使用客户端-服务器 (C/S) 架构模式，使用远程 API 来管理和创建 Docker 容器。Docker 容器通过Docker 镜像来创建。\n\nNamespaces命名空间（namespaces）是  Linux 为我们提供的用于分离进程树、网络接口、挂载点以及进程间通信等资源的方法  。在日常使用 Linux 或者 macOS 时，我们并没有运行多个完全分离的服务器的需要，但是如果我们在服务器上启动了多个服务，这些服务其实会相互影响的，每一个服务都能看到其他服务的进程，也可以访问宿主机器上的任意文件，这是很多时候我们都不愿意看到的，我们更希望运行在同一台机器上的不同服务能做到完全隔离，就像运行在多台不同的机器上一样。\nLinux 的命名空间机制提供了以下七种不同的命名空间，包括  CLONE_NEWCGROUP、CLONE_NEWIPC、CLONE_NEWNET、CLONE_NEWNS、CLONE_NEWPID、CLONE_NEWUSER 和 CLONE_NEWUTS ，通过这七个选项我们能在创建新的进程时设置新进程应该在哪些资源上与宿主机器进行隔离。\n进程(CLONE_NEWPID 实现的进程隔离)docker 创建新进程时传入 CLONE_NEWPID 实现的进程隔离，也就是使用 Linux 的命名空间实现进程的隔离，Docker 容器内部的任意进程都对宿主机器的进程一无所知。当我们每次运行docker run 或者 docker start 时，都会在创建一个用于设置进程间隔离的 Spec，同时会设置进程相关的命名空间，还会设置与用户、网络、IPC 以及 UTS 相关的命名空间，所有命名空间相关的设置 Spec 最后都会作为 Create 函数的入参在创建新的容器时进行设置。\nLibnetwork 与网络隔离如果 Docker 的容器通过 Linux 的命名空间完成了与宿主机进程的网络隔离，但是却有没有办法通过宿主机的网络与整个互联网相连，就会产生很多限制，所以 Docker 虽然可以通过命名空间创建一个隔离的网络环境，但是 Docker 中的服务仍然需要与外界相连才能发挥作用。\nDocker 整个网络部分的功能都是通过 Docker 拆分出来的 libnetwork 实现的，它提供了一个连接不同容器的实现，同时也能够为应用给出一个能够提供一致的编程接口和网络层抽象的容器网络模型。\nlibnetwork 中最重要的概念，容器网络模型由以下的几个主要组件组成，分别是 Sandbox、Endpoint 和 Network。在容器网络模型中，每一个容器内部都包含一个 Sandbox，其中存储着当前容器的网络栈配置，包括容器的接口、路由表和 DNS 设置，Linux 使用网络命名空间实现这个Sandbox，每一个 Sandbox 中都可能会有一个或多个 Endpoint，在 Linux 上就是一个虚拟的网卡veth，Sandbox 通过 Endpoint 加入到对应的网络中，这里的网络可能就是我们在上面提到的 Linux 网桥或者 VLAN。\n每一个使用 docker run 启动的容器其实都具有单独的网络命名空间，Docker 为我们提供了四种不同的网络模式， Host、Container、None  和  Bridge  模式。\n在这一部分，我们将介绍 Docker 默认的网络设置模式：网桥模式。在这种模式下，除了分配隔离的网络命名空间之外，Docker 还会为所有的容器设置 IP 地址。当 Docker 服务器在主机上启动之后会创建新的虚拟网桥 docker0，随后在该主机上启动的全部服务在默认情况下都与该网桥相连。在默认情况下，每一个容器在创建时都会创建一对虚拟网卡，两个虚拟网卡组成了数据的通道，其中一个会放在创建的容器中，会加入到名为 docker0 网桥中。\n\n资源隔离与 CGroupsControl Groups（简称 CGroups）能够隔离宿主机器上的物理资源，例如 CPU、内存、磁盘 I/O 和网络带宽。每一个 CGroup 都是一组被相同的标准和参数限制的进程，不同的CGroup之间是有层级关系的，也就是说它们之间可以从父类继承一些用于限制资源使用的标准和参数。\n镜像与 UnionFSLinux 的命名空间和控制组分别解决了不同资源隔离的问题，前者解决了进程、网络以及文件系统的隔离，后者实现了 CPU、内存等资源的隔离，但是在 Docker 中还有另一个非常重要的问题需要解决 - 也就是镜像。\nDocker 镜像其实本质就是一个压缩包，我们可以使用命令将一个 Docker 镜像中的文件导出，你可以看到这个镜像中的目录结构与 Linux 操作系统的根目录中的内容并没有太多的区别，可以说Docker 镜像就是一个文件。\n存储驱动Docker 使用了一系列不同的存储驱动管理镜像内的文件系统并运行容器，这些存储驱动与Docker 卷（volume）有些不同，存储引擎管理着能够在多个容器之间共享的存储。当镜像被 docker run 命令创建时就会在镜像的最上层添加一个可写的层，也就是容器层，所有对于运行时容器的修改其实都是对这个容器读写层的修改。\n容器和镜像的区别就在于，所有的镜像都是只读的，而每一个容器其实等于镜像加上一个可读写的层，也就是同一个镜像可以对应多个容器UnionFS 其实是一种为 Linux 操作系统设计的用于把多个文件系统『联合』到同一个挂载点的文件系统服务。而 AUFS 即 Advanced UnionFS 其实就是 UnionFS 的升级版，它能够提供更优秀的性能和效率。\nAUFS 只是 Docker 使用的存储驱动的一种，除了 AUFS 之外，Docker 支持了不同的存储驱动，包括aufs、devicemapper、overlay2、zfs 和 vfs 等等，在最新的 Docker 中，overlay2 取代了aufs 成为了推荐的存储驱动，但是在没有 overlay2 驱动的机器上仍然会使用 aufs 作为 Docker 的默认驱动。\n","categories":["Docker"],"tags":["虚拟化技术","Docker","容器化"]},{"title":"git常用命令","url":"http://www.vincentli.top/2019/03/16/git-cmd-often-use-list/","content":"很多人都知道，Linus在1991年创建了开源的Linux，从此，Linux系统不断发展，已经成为最大的服务器系统软件了。Linus虽然创建了Linux，但Linux的壮大是靠全世界热心的志愿者参与的，这么多人在世界各地为Linux编写代码，那Linux的代码是如何管理的呢？事实是，在2002年以前，世界各地的志愿者把源代码文件通过diff的方式发给Linus，然后由Linus本人通过手工方式合并代码！你也许会想，为什么Linus不把Linux代码放到版本控制系统里呢？不是有CVS、SVN这些免费的版本控制系统吗？因为Linus坚定地反对CVS和SVN，这些集中式的版本控制系统不但速度慢，而且必须联网才能使用。有一些商用的版本控制系统，虽然比CVS、SVN好用，但那是付费的，和Linux的开源精神不符。Linus花了两周时间自己用C写了一个分布式版本控制系统，这就是Git！一个月之内，Linux系统的源码已经由Git管理了！牛是怎么定义的呢？大家可以体会一下。真的让人膜拜，让我们技术渣五体投地。Git迅速成为最流行的分布式版本控制系统，尤其是2008年，GitHub网站上线了，它为开源项目免费提供Git存储，无数开源项目开始迁移至GitHub，包括jQuery，PHP，Ruby等等。扯了这么多，接下来说一说git的常用命令有哪些，以及怎样使用的吧。\ngit config配置 Git 的相关参数。\n\nGit 一共有3个配置文件：\n\n仓库级的配置文件：在仓库的 .git/.gitconfig，该配置文件只对所在的仓库有效。\n\n\n\n全局配置文件：Mac 系统在 ~/.gitconfig，Windows 系统在 C:\\Users\\&lt;用户名&gt;.gitconfig。\n\n\n\n系统级的配置文件：在 Git 的安装目录下（Mac 系统下安装目录在 /usr/local/git）的 etc 文件夹中的 gitconfig。\n\n\n\n\n\n# 查看配置信息# --local：仓库级，--global：全局级，--system：系统级$ git config &lt;--local | --global | --system&gt; -l# 查看当前生效的配置信息$ git config -l# 编辑配置文件# --local：仓库级，--global：全局级，--system：系统级$ git config &lt;--local | --global | --system&gt; -e# 添加配置项# --local：仓库级，--global：全局级，--system：系统级$ git config &lt;--local | --global | --system&gt; --add &lt;name&gt; &lt;value&gt;# 获取配置项$ git config &lt;--local | --global | --system&gt; --get &lt;name&gt;# 删除配置项$ git config &lt;--local | --global | --system&gt; --unset &lt;name&gt;# 配置提交记录中的用户信息$ git config --global user.name &lt;用户名&gt;$ git config --global user.email &lt;邮箱地址&gt;# 更改Git缓存区的大小# 如果提交的内容较大，默认缓存较小，提交会失败# 缓存大小单位：B，例如：524288000（500MB）$ git config --global http.postBuffer &lt;缓存大小&gt;# 调用 git status/git diff 命令时以高亮或彩色方式显示改动状态$ git config --global color.ui true# 配置可以缓存密码，默认缓存时间15分钟$ git config --global credential.helper cache# 配置密码的缓存时间# 缓存时间单位：秒$ git config --global credential.helper &#x27;cache --timeout=&lt;缓存时间&gt;&#x27;# 配置长期存储密码$ git config --global credential.helper store\ngit clone从远程仓库克隆一个版本库到本地。# 默认在当前目录下创建和版本库名相同的文件夹并下载版本到该文件夹下$ git clone &lt;远程仓库的网址&gt;# 指定本地仓库的目录$ git clone &lt;远程仓库的网址&gt; &lt;本地目录&gt;# -b 指定要克隆的分支，默认是master分支$ git clone &lt;远程仓库的网址&gt; -b &lt;分支名称&gt; &lt;本地目录&gt;\ngit init初始化项目所在目录，初始化后会在当前目录下出现一个名为 .git 的目录。# 初始化本地仓库，在当前目录下生成 .git 文件夹$ git initgit status查看本地仓库的状态。# 查看本地仓库的状态$ git status# 以简短模式查看本地仓库的状态# 会显示两列，第一列是文件的状态，第二列是对应的文件# 文件状态：A 新增，M 修改，D 删除，?? 未添加到Git中$ git status -s\ngit remote操作远程库。# 列出已经存在的远程仓库$ git remote# 列出远程仓库的详细信息，在别名后面列出URL地址$ git remote -v$ git remote --verbose# 添加远程仓库$ git remote add &lt;远程仓库的别名&gt; &lt;远程仓库的URL地址&gt;# 修改远程仓库的别名$ git remote rename &lt;原远程仓库的别名&gt; &lt;新的别名&gt;# 删除指定名称的远程仓库$ git remote remove &lt;远程仓库的别名&gt;# 修改远程仓库的 URL 地址$ git remote set-url &lt;远程仓库的别名&gt; &lt;新的远程仓库URL地址&gt;\ngit branch操作 Git 的分支命令。# 列出本地的所有分支，当前所在分支以 &quot;*&quot; 标出$ git branch# 列出本地的所有分支并显示最后一次提交，当前所在分支以 &quot;*&quot; 标出$ git branch -v# 创建新分支，新的分支基于上一次提交建立$ git branch &lt;分支名&gt;# 修改分支名称# 如果不指定原分支名称则为当前所在分支$ git branch -m [&lt;原分支名称&gt;] &lt;新的分支名称&gt;# 强制修改分支名称$ git branch -M [&lt;原分支名称&gt;] &lt;新的分支名称&gt;# 删除指定的本地分支$ git branch -d &lt;分支名称&gt;# 强制删除指定的本地分支$ git branch -D &lt;分支名称&gt;\ngit checkout检出命令，用于创建、切换分支等。# 切换到已存在的指定分支$ git checkout &lt;分支名称&gt;# 创建并切换到指定的分支，保留所有的提交记录# 等同于 &quot;git branch&quot; 和 &quot;git checkout&quot; 两个命令合并$ git checkout -b &lt;分支名称&gt;# 创建并切换到指定的分支，删除所有的提交记录$ git checkout --orphan &lt;分支名称&gt;# 替换掉本地的改动，新增的文件和已经添加到暂存区的内容不受影响$ git checkout &lt;文件路径&gt;git cherry-pick把已经提交的记录合并到当前分支。# 把已经提交的记录合并到当前分支$ git cherry-pick &lt;commit ID&gt;\ngit add把要提交的文件的信息添加到暂存区中。当使用 git commit 时，将依据暂存区中的内容来进行文件的提交。# 把指定的文件添加到暂存区中$ git add &lt;文件路径&gt;# 添加所有修改、已删除的文件到暂存区中$ git add -u [&lt;文件路径&gt;]$ git add --update [&lt;文件路径&gt;]# 添加所有修改、已删除、新增的文件到暂存区中，省略 &lt;文件路径&gt; 即为当前目录$ git add -A [&lt;文件路径&gt;]$ git add --all [&lt;文件路径&gt;]# 查看所有修改、已删除但没有提交的文件，进入一个子命令系统$ git add -i [&lt;文件路径&gt;]$ git add --interactive [&lt;文件路径&gt;]\ngit commit将暂存区中的文件提交到本地仓库中。# 把暂存区中的文件提交到本地仓库，调用文本编辑器输入该次提交的描述信息$ git commit# 把暂存区中的文件提交到本地仓库中并添加描述信息$ git commit -m &quot;&lt;提交的描述信息&gt;&quot;# 把所有修改、已删除的文件提交到本地仓库中# 不包括未被版本库跟踪的文件，等同于先调用了 &quot;git add -u&quot;$ git commit -a -m &quot;&lt;提交的描述信息&gt;&quot;# 修改上次提交的描述信息$ git commit --amend\ngit fetch从远程仓库获取最新的版本到本地的 tmp 分支上。# 将远程仓库所有分支的最新版本全部取回到本地$ git fetch &lt;远程仓库的别名&gt;# 将远程仓库指定分支的最新版本取回到本地$ git fetch &lt;远程主机名&gt; &lt;分支名&gt;\ngit merge合并分支。# 把指定的分支合并到当前所在的分支下$ git merge &lt;分支名称&gt;\ngit diff比较版本之间的差异。# 比较当前文件和暂存区中文件的差异，显示没有暂存起来的更改$ git diff# 比较暂存区中的文件和上次提交时的差异$ git diff --cached$ git diff --staged# 比较当前文件和上次提交时的差异$ git diff HEAD# 查看从指定的版本之后改动的内容$ git diff &lt;commit ID&gt;# 比较两个分支之间的差异$ git diff &lt;分支名称&gt; &lt;分支名称&gt;# 查看两个分支分开后各自的改动内容$ git diff &lt;分支名称&gt;...&lt;分支名称&gt;\ngit pull从远程仓库获取最新版本并合并到本地。首先会执行 git fetch，然后执行 git merge，把获取的分支的 HEAD 合并到当前分支。# 从远程仓库获取最新版本。$ git pull# 从远程仓库获取最新版本并和本地代码变基合并,推荐使用这个。$ git pull --rebase\ngit push把本地仓库的提交推送到远程仓库。# 把本地仓库的分支推送到远程仓库的指定分支$ git push &lt;远程仓库的别名&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt;# 删除指定的远程仓库的分支$ git push &lt;远程仓库的别名&gt; :&lt;远程分支名&gt;$ git push &lt;远程仓库的别名&gt; --delete &lt;远程分支名&gt;\ngit log显示提交的记录。# 打印所有的提交记录$ git log# 打印从第一次提交到指定的提交的记录$ git log &lt;commit ID&gt;# 打印指定数量的最新提交的记录$ git log -&lt;指定的数量&gt;\ngit reset还原提交记录,如果代码合并代码被覆盖了这个还原很有用# 重置暂存区，但文件不受影响# 相当于将用 &quot;git add&quot; 命令更新到暂存区的内容撤出暂存区，可以指定文件# 没有指定 commit ID 则默认为当前 HEAD$ git reset [&lt;文件路径&gt;]$ git reset --mixed [&lt;文件路径&gt;]# 将 HEAD 的指向改变，撤销到指定的提交记录，文件未修改$ git reset &lt;commit ID&gt;$ git reset --mixed &lt;commit ID&gt;# 将 HEAD 的指向改变，撤销到指定的提交记录，文件未修改# 相当于调用 &quot;git reset --mixed&quot; 命令后又做了一次 &quot;git add&quot;$ git reset --soft &lt;commit ID&gt;# 将 HEAD 的指向改变，撤销到指定的提交记录，文件也修改了$ git reset --hard &lt;commit ID&gt;\ngit revert生成一个新的提交来撤销某次提交，此次提交之前的所有提交都会被保留。# 生成一个新的提交来撤销某次提交$ git revert &lt;commit ID&gt;\ngit tag操作标签的命令。# 打印所有的标签$ git tag# 添加轻量标签，指向提交对象的引用，可以指定之前的提交记录$ git tag &lt;标签名称&gt; [&lt;commit ID&gt;]# 添加带有描述信息的附注标签，可以指定之前的提交记录$ git tag -a &lt;标签名称&gt; -m &lt;标签描述信息&gt; [&lt;commit ID&gt;]# 切换到指定的标签$ git checkout &lt;标签名称&gt;# 查看标签的信息$ git show &lt;标签名称&gt;# 删除指定的标签$ git tag -d &lt;标签名称&gt;# 将指定的标签提交到远程仓库$ git push &lt;远程仓库的别名&gt; &lt;标签名称&gt;# 将本地所有的标签全部提交到远程仓库$ git push &lt;远程仓库的别名&gt; –tags\ngit mv重命名文件或者文件夹。# 重命名指定的文件或者文件夹$ git mv &lt;源文件/文件夹&gt; &lt;目标文件/文件夹&gt;\ngit rm删除文件或者文件夹。# 移除跟踪指定的文件，并从本地仓库的文件夹中删除$ git rm &lt;文件路径&gt;# 移除跟踪指定的文件夹，并从本地仓库的文件夹中删除$ git rm -r &lt;文件夹路径&gt;# 移除跟踪指定的文件，在本地仓库的文件夹中保留该文件$ git rm --cached\nGit操作场景示例1. 删除掉本地不存在的远程分支多人合作开发时，如果远程的分支被其他开发删除掉，在本地执行 git branch –all 依然会显示该远程分支，可使用下列的命令进行删除：# 使用 pull 命令，添加 -p 参数$ git pull -p# 等同于下面的命令$ git fetch -p$ git fetch --prune origin\n2. 多人协作\n当你从远程仓库克隆时，实际上Git自动把本地的master分支和远程的master分支对应起来了，并且，远程仓库的默认名称是origin。\n\n要查看远程库的信息，用git remote：$ git remoteorigin或者，用git remote -v显示更详细的信息：$ git remote -vorigin  git@github.com:michaelliao/learngit.git (fetch)origin  git@github.com:michaelliao/learngit.git (push)上面显示了可以抓取和推送的origin的地址。如果没有推送权限，就看不到push的地址。\n\n推送分支推送分支，就是把该分支上的所有本地提交推送到远程库。推送时，要指定本地分支，这样，Git就会把该分支推送到远程库对应的远程分支上：$ git push origin master\n如果要推送其他分支，比如dev，就改成：\n\n$ git push origin dev\n\n但是，并不是一定要把本地分支往远程推送，那么，哪些分支需要推送，哪些不需要呢？\n\nmaster分支是主分支，因此要时刻与远程同步；\ndev分支是开发分支，团队所有成员都需要在上面工作，所以也需要与远程同步；\n\nbug分支只用于在本地修复bug，就没必要推到远程了，除非老板要看看你每周到底修复了几个bug；\n\nfeature分支是否推到远程，取决于你是否和你的小伙伴合作在上面开发。\n\n\n\n\n","categories":["工具学习"],"tags":["git"]},{"title":"TensorFlow初探（一）","url":"http://www.vincentli.top/2018/11/25/tensorflow-open-practise/","content":"TensorFlow由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护，拥有包括TensorFlow Hub、TensorFlow Lite、TensorFlow Research Cloud在内的多个项目以及各类应用程序接口（Application Programming Interface, API）,是一个适合所有人学习的开源的机器学习框架。\n今天刚参加了谷歌开发者大会，了解到了\b目前TensorFlow用于很多科学实验，解决了很多社会问题，\b感触很深。所以决定更多了解下\bTensorFlow。\n\b环境准备\n具备 Python 基础\n具备数学基础（如线性代数、微积分）\n对机器学习/深度学习的概念（如CNN、RNN、强化学习）稍有了解\n配置好 Python 和 TensorFlow 环境，配置好适合的 Python IDE（如PyCharm），环境配置方法请参考 https://tf.wiki/zh/installation.html （中文）或 https://tf.wiki/en/installation.html （英文）\n\n查看python和tensorflow的版本号：\n用命令python -V 或者python3 -V查看版本号：lichaoqiang@lichaoqiangs-MacBook-Pro ~/project/python  python3 -V              Python 3.5.2\n\b查看tensoflow的版本号,可以用如下脚本\n#!/usr/local/bin/python3import tensorflow as tfprint(tf.__version__)\n运行tensorflow-version.py脚本可以查看： lichaoqiang@lichaoqiangs-MacBook-Pro  ~/project/python  python3 tensorflow-version.py1.11.0\n\n\n用TensorFlow解决实际问题案例\n具体问题描述\n  某公司有四个工厂，分布在不同地区，同时三种产品，产量（单位；t）， 试用矩阵统计这些数据。工厂/产品    P1    P2    P3 甲        5    2    4 乙        3    8    2 丙        6    0    4 丁        0    1    6 其中四行分别表示甲乙丙丁四个工厂的生产情况，三列分布表示三种产品P1，P2，P3的产量。 再设矩阵 2   4 1   3 3   2 其中第一列表示三种产品的单件利润，第二列表示三种产品的单件体积。\n\n用python实现使用tensorflow来计算,新建脚本tensorflow-demo05.py，代码如下:\n\n\n#!/usr/local/bin/python3import tensorflow as tftf.enable_eager_execution()a = tf.constant([[5,2,4], [3, 8,2],[6,0,4],[0,1,6]])b = tf.constant([[2,4],[1,3],[3,2]])c = tf.matmul(a, b)print(c)\n\n执行python脚本得到结果(venv)  ✘ lichaoqiang@lichaoqiangs-MacBook-Pro  ~/project/python  python3 tensorflow-demo05.py 2018-11-25 22:02:52.718706: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMAtf.Tensor([[24 34] [20 40] [24 32] [19 15]], shape=(4, 2), dtype=int32)\n很简单的几行代码可以轻松计算出了四个工厂的利润（结果第一列）和这四个工厂产品需要的存储空间（结果第二列）。通过这个简单的例子可以看出，\bTensorflow的很多计算模型很实用，而且也很容易上手，后面空了\b，我再试一试其他功能。\n\n","categories":["tensorflow"],"tags":["tensorflow","强化学习","python","深度增强学习"]},{"title":"Mybatis常见面试题","url":"http://www.vincentli.top/2018/09/04/mybatis-common-interview-question/","content":"Mybatis是我们常用的ORM框架，经常用，但是对于 Mybatis 的技术架构和重要组成部分，以及基本运行原理，很多人了解的不多，我在网上见到了很多常考的面试题，整理了下相关答案（有些是自己想的，有些是网上搜索的），答案有不合理或者错误的请指正提出。\n废话不多说，直接上Mybatis常考面试题，康康我们能答出来几道。\n1、#{}和${}的区别是什么？\n可能很多人只用过#{}，而很少用${}，有过分库分表经验的童鞋可能用过${}。\n\n答：\n\n$&#123;&#125;是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如${driver}会被静态替换为com.mysql.jdbc.Driver。\n#&#123;&#125;是 sql 的参数占位符，Mybatis 会将 sql 中的#&#123;&#125;替换为?号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的?号占位符设置参数值，比如 ps.setInt(0, parameterValue)，#&#123;item.name&#125; 的取值方式为使用反射从参数对象中获取 item 对象的 name 属性值，相当于 param.getItem().getName()。\n\n2、Xml 映射文件中，除了常见的 select|insert|updae|delete 标签之外，还有哪些标签？\n据说来自京东面试管的考题\n\n答：还有很多其他的标签，&lt;resultMap&gt;、&lt;parameterMap&gt;、&lt;sql&gt;、&lt;include&gt;、&lt;selectKey&gt;，加上动态 sql 的 9 个标签，trim|where|set|foreach|if|choose|when|otherwise|bind等，其中为 sql 片段标签，通过&lt;include&gt;标签引入 sql 片段，&lt;selectKey&gt;为不支持自增的主键生成策略标签。\n3、最佳实践中，通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应，请问，这个 Dao 接口的工作原理是什么？Dao 接口里的方法，参数不同时，方法能重载吗？\n据说来自京东面试管的考题\n\n答：Dao 接口，就是人们常说的 Mapper接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中MappedStatement的 id 值，接口方法内的参数，就是传递给 sql 的参数。Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到 namespace 为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement。在 Mybatis 中，每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签，都会被解析为一个MappedStatement对象。\nDao 接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。\nDao 接口的工作原理是 JDK 动态代理，Mybatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行MappedStatement所代表的 sql，然后将 sql 执行结果返回。\n4、Mybatis 是如何进行分页的？分页插件的原理是什么？答：Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页，可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。\n分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。\n举例：select \\* from student，拦截 sql 后重写为：select t.* from （select \\* from student）t limit 0，10\n5、Mybatis执行批量插入，可以返回数据库主键列表吗？答：可以，JDBC都可以，Mybatis当然也可以。\n6、简述 Mybatis 的插件运行原理，以及如何编写一个插件。答：Mybatis仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、Executor 这 4 种接口的插件，Mybatis 使用 JDK 的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler 的 invoke()方法，当然，只会拦截那些你指定需要拦截的方法。\n实现 Mybatis 的 Interceptor 接口并复写intercept()方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。\n7、Mybatis 是如何将 sql 执行结果封装为目标对象并返回的？都有哪些映射形式？答：第一种是使用&lt;resultMap&gt;标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用 sql 列的别名功能，将列别名书写为对象属性名，比如 T_NAME AS NAME，对象属性名一般是 name，小写，但是列名不区分大小写，Mybatis 会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成 T_NAME AS NaMe，Mybatis 一样可以正常工作。\n有了列名与属性名的映射关系后，Mybatis 通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。\n8、Mybatis 动态 sql 是做什么的？都有哪些动态 sql？能简述一下动态 sql 的执行原理不？答：Mybatis 动态 sql 可以让我们在 Xml 映射文件内，以标签的形式编写动态 sql，完成逻辑判断和动态拼接 sql 的功能，Mybatis 提供了 9 种动态 sql 标签 trim|where|set|foreach|if|choose|when|otherwise|bind。\n其执行原理为，使用 OGNL 从 sql 参数对象中计算表达式的值，根据表达式的值动态拼接 sql，以此来完成动态 sql 的功能。\n9、Mybatis 能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别。答：能，Mybatis 不仅可以执行一对一、一对多的关联查询，还可以执行多对一，多对多的关联查询，多对一查询，其实就是一对一查询，只需要把 selectOne()修改为 selectList()即可；多对多查询，其实就是一对多查询，只需要把 selectOne()修改为 selectList()即可。\n关联对象查询，有两种实现方式，一种是单独发送一个 sql 去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用 join 查询，一部分列是 A 对象的属性值，另外一部分列是关联对象 B 的属性值，好处是只发一个 sql 查询，就可以把主对象和其关联对象查出来。\n那么问题来了，join 查询出来 100 条记录，如何确定主对象是 5 个，而不是 100 个？其去重复的原理是&lt;resultMap&gt;标签内的&lt;id&gt;子标签，指定了唯一确定一条记录的 id 列，Mybatis 根据列值来完成 100 条记录的去重复功能，&lt;id&gt;可以有多个，代表了联合主键的语意。\n同样主对象的关联对象，也是根据这个原理去重复的，尽管一般情况下，只有主对象会有重复记录，关联对象一般不会重复。\n举例：下面 join 查询出来 6 条记录，一、二列是 Teacher 对象列，第三列为 Student 对象列，Mybatis 去重复处理后，结果为 1 个老师 6 个学生，而不是 6 个老师 6 个学生。\n|t_id|t_name|s_id| 1 | teacher | 38 || 1 | teacher | 39 || 1 | teacher | 40 || 1 | teacher | 41 || 1 | teacher | 42 || 1 | teacher | 43 |\n10、Mybatis 是否支持延迟加载？如果支持，它的实现原理是什么？答：Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询。在 Mybatis 配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。\n它的原理是，使用CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName()，拦截器 invoke()方法发现 a.getB()是 null 值，那么就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName()方法的调用。这就是延迟加载的基本原理。\n当然了，不光是 Mybatis，几乎所有的包括 Hibernate，支持延迟加载的原理都是一样的。\n11、Mybatis 的 Xml 映射文件中，不同的 Xml 映射文件，id 是否可以重复？答：不同的 Xml 映射文件，如果配置了 namespace，那么 id 可以重复；如果没有配置 namespace，那么 id 不能重复；毕竟 namespace 不是必须的，只是最佳实践而已。\n原因就是 namespace+id 是作为 Map&lt;String, MappedStatement&gt;的 key 使用的，如果没有 namespace，就剩下 id，那么，id 重复会导致数据互相覆盖。有了 namespace，自然 id 就可以重复，namespace 不同，namespace+id 自然也就不同。\n12、Mybatis 中如何执行批处理？答：使用 BatchExecutor 完成批处理。\n13、Mybatis 都有哪些 Executor 执行器？它们之间的区别是什么？答：Mybatis 有三种基本的 Executor 执行器，SimpleExecutor、ReuseExecutor、BatchExecutor。\n SimpleExecutor：每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象。\n ReuseExecutor：执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map内，供下一次使用。简言之，就是重复使用 Statement 对象。\n BatchExecutor：执行 update（没有 select，JDBC 批处理不支持 select），将所有 sql 都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个 Statement 对象，每个 Statement 对象都是 addBatch()完毕后，等待逐一执行 executeBatch()批处理。与 JDBC 批处理相同。\n作用范围：Executor 的这些特点，都严格限制在 SqlSession 生命周期范围内。\n14、Mybatis 中如何指定使用哪一种 Executor 执行器？答：在 Mybatis 配置文件中，可以指定默认的 ExecutorType 执行器类型，也可以手动给 DefaultSqlSessionFactory 的创建 SqlSession 的方法传递 ExecutorType 类型参数。\n15、为什么说 Mybatis 是半自动 ORM 映射工具？它与全自动的区别在哪里？答：Hibernate 属于全自动 ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而 Mybatis 在查询关联对象或关联集合对象时，需要手动编写 sql 来完成，所以，称之为半自动 ORM 映射工具。\n16、简述 Mybatis 的 Xml 映射文件和 Mybatis 内部数据结构之间的映射关系？答：Mybatis 将所有 Xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在 Xml 映射文件中，&lt;parameterMap&gt;标签会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。&lt;resultMap&gt;标签会被解析为 ResultMap 对象，其每个子元素会被解析为 ResultMapping 对象。每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签均会被解析为 MappedStatement 对象，标签内的 sql 会被解析为 BoundSql 对象。\n17、Mybatis 是否可以映射 Enum 枚举类？答：Mybatis 可以映射枚举类，不单可以映射枚举类，Mybatis 可以映射任何对象到表的一列上。映射方式为自定义一个 TypeHandler，实现 TypeHandler 的 setParameter()和 getResult()接口方法。TypeHandler 有两个作用，一是完成从 javaType 至 jdbcType 的转换，二是完成 jdbcType 至 javaType 的转换，体现为 setParameter()和 getResult()两个方法，分别代表设置 sql 问号占位符参数和获取列查询结果。\n18、Mybatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？答：虽然 Mybatis 解析 Xml 映射文件是按照顺序解析的，但是，被引用的 B 标签依然可以定义在任何地方，Mybatis 都可以正确识别。\n原理是，Mybatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，Mybatis 会将 A 标签标记为未解析状态，然后继续解析余下的标签，包含 B 标签，待所有标签解析完毕，Mybatis 会重新解析那些被标记为未解析的标签，此时再解析 A 标签时，B 标签已经存在，A 标签也就可以正常解析完成了。\n孙子曰：兵者，国之大事，死生之地，存亡之道，不可不察也。\n","categories":["mybatis","技术笔记"],"tags":["Mybatis","数据库中间件","ORM"]},{"title":"三个线程顺序打印ABC字符串10遍的三种实现方案","url":"http://www.vincentli.top/2017/01/12/three-print-abc-char-ten-times-solutions/","content":"What之前同事遇到过这样一个面试题，大概是用三个线程顺序打印ABC字符串，打印10遍。请给出至少一种解决方案。\nWhy面试官为什么出这个问题呢？我想大概主要是想考验一下面试者多线程的熟悉度，理解和运用。\nHow\n我想了一会儿，给出大概3种实现方案。一种使用synchronized关键字来做锁，另外两种不使用锁机制，大同小异的实现。Talk is cheap,show me your code!!!\n\n实现一，使用synchronized关键字来做锁。import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;/** * 三个线程顺序打印字符串ABC，打印10遍 * 写法一 * */public class ThreadTest &#123;    private boolean flagA =true;    private boolean flagB =false;    private boolean flagC =false;    private Object objA = new Object();    private Object objB = new Object();    private Object objC = new Object();    private void printA() throws InterruptedException&#123;        for(int i=0;i&lt;10;i++)&#123;            synchronized(objA)&#123;                synchronized(objB)&#123;                    while(flagA)&#123;                        System.out.println(&quot;A&quot;);                        flagA=false;                        flagB=true;                        objB.notify();                    &#125;                &#125;                objA.wait();            &#125;               &#125;    &#125;    private void printB() throws InterruptedException&#123;        for(int i=0;i&lt;10;i++)&#123;            synchronized(objB)&#123;                synchronized(objC)&#123;                    while(flagB)&#123;                        System.out.println(&quot;B&quot;);                        flagB=false;                        flagC=true;                        objC.notify();                    &#125;                &#125;                objB.wait();            &#125;               &#125;    &#125;        private void printC() throws InterruptedException&#123;        for(int i=0;i&lt;10;i++)&#123;            synchronized(objC)&#123;                synchronized(objA)&#123;                    while(flagC)&#123;                        System.out.println(&quot;C&quot;);                        flagA=true;                        flagC=false;                        objA.notify();                    &#125;                &#125;                objC.wait();            &#125;               &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        final ThreadTest ThreadTest =new ThreadTest();                Runnable ra = new Runnable()&#123;            public void run()&#123;                try &#123;                    ThreadTest.printA();                &#125; catch (InterruptedException e) &#123;                    // TODO Auto-generated catch block                    e.printStackTrace();                &#125;            &#125;        &#125;;        Runnable rb = new Runnable()&#123;            public void run()&#123;                try &#123;                    ThreadTest.printB();                &#125; catch (InterruptedException e) &#123;                    // TODO Auto-generated catch block                    e.printStackTrace();                &#125;            &#125;        &#125;;        Runnable rc = new Runnable()&#123;            public void run()&#123;                try &#123;                    ThreadTest.printC();                &#125; catch (InterruptedException e) &#123;                    // TODO Auto-generated catch block                    e.printStackTrace();                &#125;            &#125;        &#125;;        new Thread(ra).start();        Thread.sleep(300);         new Thread(rb).start();        Thread.sleep(300);        new Thread(rc).start();                &#125;    &#125;\n\n\n\n\n实现二import java.util.concurrent.atomic.AtomicInteger;/** * 三个线程顺序打印字符串ABC，打印10遍 * 写法二 * @author lichaoqiang * */public class ThreadTest2 implements Runnable&#123;            static Thread[] threads = new Thread[3];    static int len = 3;    static final AtomicInteger ai = new AtomicInteger(1);    String val=&quot;&quot;;        public ThreadTest2(String val)&#123;        this.val = val;    &#125;        public void run() &#123;        while(true)&#123;            if(ai.get()&lt;= 30)&#123;                                if(&quot;A&quot;.equals(val))&#123;                                        if(ai.get()%len == 1)&#123;                        // TODO Auto-generated method stub                        System.out.println(Thread.currentThread().getName()+val);                        ai.getAndIncrement();                    &#125;                 &#125;                if(&quot;B&quot;.equals(val))&#123;                    if(ai.get()%len == 2)&#123;                        // TODO Auto-generated method stub                        System.out.println(Thread.currentThread().getName()+val);                        ai.getAndIncrement();                    &#125;                &#125;                if(&quot;C&quot;.equals(val))&#123;                    if(ai.get()%len == 0)&#123;                        // TODO Auto-generated method stub                        System.out.println(Thread.currentThread().getName()+val);                        ai.getAndIncrement();                    &#125;                &#125;            &#125;else&#123;                break;            &#125;                    &#125;        //          &#125;        public static void main(String[] args) throws InterruptedException &#123;        // TODO Auto-generated method stub                        threads[0] = new Thread(new ThreadTest2(&quot;A&quot;));                threads[1] = new Thread(new ThreadTest2(&quot;B&quot;));                threads[2] = new Thread(new ThreadTest2(&quot;C&quot;));                threads[0].start();        threads[1].start();        threads[2].start();    &#125;&#125;\n实现三package com.licq.thread;import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;/** * 三个线程顺序打印字符串ABC，打印10遍 * 写法三 * */public class ThreadTest3 &#123;    private static int seq = 0;    private static Thread[] threads = new Thread[3];    private static Map&lt;String, String&gt; mapping = new HashMap&lt;String, String&gt;();    public static void main(String[] args) &#123;        mapping.put(&quot;0&quot;, &quot;A&quot;);        mapping.put(&quot;1&quot;, &quot;B&quot;);        mapping.put(&quot;2&quot;, &quot;C&quot;);        for (int i = 0; i &lt; threads.length; i++) &#123;            threads[i] = new Thread(new Runnable() &#123;                                public void run() &#123;                    while (true) &#123;                        if(seq &gt;= 30)&#123;                            break;                        &#125;                        String threadName = Thread.currentThread().getName();                        if (seq % threads.length == Integer                                .parseInt(threadName)) &#123;                            System.out.println(&quot;------------&quot; + mapping.get(threadName) + &quot;-----------&quot;);                            seq = seq + 1;                        &#125; else &#123;                            try &#123;                                TimeUnit.SECONDS.sleep(1);                            &#125; catch (InterruptedException e) &#123;                            &#125;                        &#125;                    &#125;                &#125;            &#125;);            threads[i].setName(String.valueOf(i));            threads[i].start();        &#125;    &#125;&#125;\n\n\nSUMMARY以上三种是比较简单的实现方式，当然还有其他很多实现方式，欢迎有更简单更优雅的实现方式贴在下面一起交流。\n","categories":["博客","thread","多线程"],"tags":["并发","多线程","thread"]},{"title":"Java服务之spi机制简要说明和实践","url":"http://www.vincentli.top/2016/11/10/java-spi-practise-demo-introduction-md/","content":"一、SPI概念&nbsp;&nbsp;这里先说下SPI的一个概念，SPI英文为Service Provider Interface单从字面可以理解为Service提供者接口，正如从SPI的名字去理解SPI就是Service提供者接口；我对SPI的定义：提供给服务提供厂商与扩展框架功能的开发者使用的接口。\n\n&nbsp;&nbsp;当服务的提供者，提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。 很多框架都使用了java的SPI机制，如java.sql.Driver的SPI实现（mysql驱动、oracle驱动等）、common-logging的日志接口实现、dubbo的扩展实现等等框架；基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。jdk提供服务实现查找的一个工具类：java.util.ServiceLoader.\n二、SPI机制的说明：\n1)         在META-INF/services/目录中创建以接口全限定名命名的文件该文件内容为Api具体实现类的全限定名\n\n2)         使用ServiceLoader类动态加载META-INF中的实现类\n\n3)         如SPI的实现类为Jar则需要放在主程序classPath中\n\n4)         Api具体实现类必须有一个不带参数的构造方法\n\n\n三、SPI的一个小demo假设有一个内容搜索系统，分为展示和搜索两个模块。展示和搜索基于接口编程。搜索的实现可能是基于文件系统的搜索，也可能是基于数据库的搜索。实例代码如下Search.java: 搜索接口package com.licq.spi;import java.util.List;public interface Search &#123;     List&lt;Object&gt; search(String keyword);  &#125;下面定义两实现类FileSearch.java:文件系统的搜索实现package com.licq.spi;import java.util.List;public class FileSearch implements Search &#123;    @Override    public List&lt;Object&gt; search(String keyword) &#123;        // TODO Auto-generated method stub        System.out.println(&quot;  FileSearch search.....keywords:&quot;+keyword);        return null;    &#125;&#125;DatabaseSearch.java实现类package com.licq.spi;import java.util.List;public class DatabaseSearch implements Search &#123;    @Override    public List&lt;Object&gt; search(String keyword) &#123;        // TODO Auto-generated method stub        System.out.println(&quot;  databaseSearch  search.....keywords:&quot;+keyword);        return null;    &#125;&#125;Client.java测试类：\npackage com.licq.spi;import java.util.Iterator;import java.util.ServiceLoader;public class Client &#123;    public static void main(String[] args) &#123;        // TODO Auto-generated method stub        ServiceLoader&lt;Search&gt; s = ServiceLoader.load(Search.class);          Iterator&lt;Search&gt; searchs = s.iterator();          while(searchs.hasNext())&#123;            Search sea = searchs.next();            sea.search(&quot;hello world.&quot;);        &#125;    &#125;&#125;最后创建在META-INF/searvices/com.licq.spi.Search文件。当 com.licq.spi.Search文件内容是”com.licq.spi.FileSearch”时，程序输出是：FileSearch search.....keywords:hello world.当com.licq.spi.Search文件内容是”com.licq.spi.DatabaseSearch”时，程序输出是：databaseSearch  search.....keywords:hello world.可以看出Client.java里没有任何和具体实现有关的代码，而是基于spi的机制去查找服务的实现。很多开源框架也是基于这种机制去实现的，具体的完整源码demo可以在Github上去查看。\n","categories":["博客"],"tags":["分布式服务","RPC"]},{"title":"String,StringBuffer,StringBuilder拼接操作的效率比拼","url":"http://www.vincentli.top/2016/10/21/string-stringbuilder-stringbuffer-run-efficiency-compare/","content":"前言 有很多时候，会有大量的字符串的拼接操作，但是我们很多coder，尤其是刚入职场的年轻coder,使用的方式可能就是String str +=s;而且我翻我自己所参与的项目里面的以前很久的代码也有大量的这种写法，但是很少有人知道，这种写法在操作基数很大的时候效率还是很低下的。talk is cheep,show me the code,少说废话，先上代码吧。\n测试场景一\n当字符串拼接操作次数在1000的级别时，效率差异不是很大的。public class TestClient &#123;/** * @param args */public static void main(String[] args) throws Exception&#123;    // TODO Auto-generated method stub    testString();&#125;private static void testString()throws Exception&#123;            ///1.str+=s的方式。    String str= &quot;&quot;;    String s =&quot;a&quot;;    long start = System.currentTimeMillis();        for(int i=0; i &lt; 1000;i++)&#123;        str+=s;    &#125;        long end = System.currentTimeMillis();    System.out.println(&quot;String+=s耗时：&quot;+(end-start)+&quot;ms&quot;);        ///2.String.concat()方式    long start1 = System.currentTimeMillis();    String str1= &quot;&quot;;    for(int i=0; i &lt; 1000;i++)&#123;        str1.concat(s);    &#125;        long end1 = System.currentTimeMillis();        System.out.println(&quot;String.concat()耗时：&quot;+(end1-start1)+&quot;ms&quot;);    ///3.StringBuffer.append()方式        long start2 = System.currentTimeMillis();    StringBuffer str2= new StringBuffer();    for(int i=0; i &lt; 1000;i++)&#123;        str2.append(s);    &#125;        long end2 = System.currentTimeMillis();    System.out.println(&quot;StringBuffer.append()耗时：&quot;+(end2-start2)+&quot;ms&quot;);        4.StringBuilder.append()方式    long start3 = System.currentTimeMillis();    StringBuilder str3= new StringBuilder();    for(int i=0; i &lt; 1000;i++)&#123;        str3.append(s);    &#125;        long end3 = System.currentTimeMillis();    System.out.println(&quot;StringBuilder.append()耗时：&quot;+(end3-start3) +&quot;ms&quot;);    &#125;\n场景一运行结果String+=s耗时：3msString.concat()耗时：0msStringBuffer.append()耗时：0msStringBuilder.append()耗时：0ms\n测试场景二当操作的次数上升到10000的时候有如何呢?\n\n场景二运行结果String+=s耗时：71msString.concat()耗时：1msStringBuffer.append()耗时：1msStringBuilder.append()耗时：1ms\n测试场景三\n当操作上升到100000的时候有如何呢?String+=s耗时：13250msString.concat()耗时：7msStringBuffer.append()耗时：4msStringBuilder.append()耗时：3ms\n\n结论结果总是那么让人惊艳。很显然StringBuilder和StringBuffer的append()方式效率更高，String的concat()的方法效率也还可以的。那为什么String的+=s的操作方式效率会那么低呢？那是因为这种方式会不停的创建新的String对象，这样会浪费不少内存空间，而且效率也不高。所以我们一般处理少量操作的时候建议用String的concat()方法就可以了。遇到大量拼接操作的时候建议还是用StringBuffer，StringBuilder的append()的方法。\n","categories":["Java"],"tags":["String","StringBuilder","StringBuffer","字符串"]},{"title":"RESTful-WebService初识入门NO.1","url":"http://www.vincentli.top/2016/09/06/restful-webservice-learning-greenhand-note-001/","content":"RESTful WebService是把一切对象方法看做资源，开发RESTful WebService意味着支持在多种媒体类型以及抽象底层的客户端-服务器通信细节，如果没有一个好的工具包可用，会变得不那么容易。为了简化使用JAVA开发RESTful WebService及其客户端，一个轻量级的标准被提出：JAX-RS API。Jersey RESTful WebService框架是一个开源的、产品级别的JAVA框架，支持JAX-RS API并且是一个JAX-RS(JSR 311和 JSR 339)的参考实现。Jersey不仅仅是一个JAX-RS的参考实现，Jersey提供自己的API，其API继承自JAX-RS，提供更多的特性和功能以进一步简化RESTful service和客户端的开发。Jersey2.1版本之前默认HK2作为Ioc容器，后面才增加了Spring的支持。同时默认采用glassfish作为web容器。\n接下里我们 使用 maven来 实践 一个 小 练习。\n检测自己本地的maven版本：sh-3.2# mvn -versionApache Maven 3.3.3 (7994120775791599e205a5524ec3e0dfe41d4a06; 2015-04-22T19:57:37+08:00)Maven home: /Users/lichaoqiang/Maven/Maven3.3.3Java version: 1.7.0_79, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.11.6&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;\n创建第一个restful风格的maven工程。在终端里面执行以下命令：mvn archetype:generate -DarchetypeArtifactId=jersey-quickstart-grizzly2 -DarchetypeGroupId=org.glassfish.jersey.archetypes -DinteractiveMode=false -DgroupId=com.licq.restful -DartifactId=licq-first-service -Dpackage=com.licq -DarchetypeVersion=2.22.1\n得到的结果如下，表示创建成功。[INFO] Using following parameters for creating project from Old (1.x) Archetype: jersey-quickstart-grizzly2:2.22.1[INFO] ----------------------------------------------------------------------------[INFO] Parameter: groupId, Value: com.licq.restful[INFO] Parameter: packageName, Value: com.licq[INFO] Parameter: package, Value: com.licq[INFO] Parameter: artifactId, Value: licq-first-service[INFO] Parameter: basedir, Value: /Users/lichaoqiang/project/restfulService_demo[INFO] Parameter: version, Value: 1.0-SNAPSHOT[INFO] project created from Old (1.x) Archetype in dir: /Users/lichaoqiang/project/restfulService_demo/licq-first-service[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 59.191 s[INFO] Finished at: 2016-09-06T10:11:14+08:00[INFO] Final Memory: 16M/245M[INFO] ------------------------------------------------------------------------\n使用mvn命令来编译测试新建的工程。执行命令如下：得到如下的结果,表示编译通过。------------------------------------------------------- T E S T S-------------------------------------------------------Running com.licq.MyResourceTestSep 06, 2016 10:17:02 AM org.glassfish.grizzly.http.server.NetworkListener start信息: Started listener bound to [localhost:8080]Sep 06, 2016 10:17:02 AM org.glassfish.grizzly.http.server.HttpServer start信息: [HttpServer] Started.Sep 06, 2016 10:17:02 AM org.glassfish.grizzly.http.server.NetworkListener shutdownNow信息: Stopped listener bound to [localhost:8080]Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.154 secResults :Tests run: 1, Failures: 0, Errors: 0, Skipped: 0[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 36.341 s[INFO] Finished at: 2016-09-06T10:17:02+08:00[INFO] Final Memory: 16M/245M\n执行mvn exec:java命令，启动我们的服务，并查看结果。\n\nsh-3.2# mvn exec:java[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building licq-first-service 1.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO][INFO] &gt;&gt;&gt; exec-maven-plugin:1.2.1:java (default-cli) &gt; validate @ licq-first-service &gt;&gt;&gt;[INFO][INFO] &lt;&lt;&lt; exec-maven-plugin:1.2.1:java (default-cli) &lt; validate @ licq-first-service &lt;&lt;&lt;[INFO][INFO] --- exec-maven-plugin:1.2.1:java (default-cli) @ licq-first-service ---Downloading: http://192.168.29.1:8081/nexus/content/groups/public/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jarDownloading: http://192.168.29.1:8081/nexus/content/groups/public/org/codehaus/plexus/plexus-container-default/1.0-alpha-9/plexus-container-default-1.0-alpha-9.jarDownloaded: http://192.168.29.1:8081/nexus/content/groups/public/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar (52 KB at 30.3 KB/sec)Downloaded: http://192.168.29.1:8081/nexus/content/groups/public/org/codehaus/plexus/plexus-container-default/1.0-alpha-9/plexus-container-default-1.0-alpha-9.jar (191 KB at 93.7 KB/sec)Sep 06, 2016 10:18:08 AM org.glassfish.grizzly.http.server.NetworkListener start信息: Started listener bound to [localhost:8080]Sep 06, 2016 10:18:08 AM org.glassfish.grizzly.http.server.HttpServer start信息: [HttpServer] Started.Jersey app started with WADL available at http://localhost:8080/myapp/application.wadlHit enter to stop it...\n\n在浏览器中输入地址：http://localhost:8080/myapp/application.wadl查看wsdl的描述。\n\n在浏览器中输入地址：http://localhost:8080/myapp/myresource查看我们的资源，也就是方法。这个小实践的源码在Github上有备份，可以下载查看，很简单，后面会有更多的详解。\n\n\n","categories":["博客","Restful"],"tags":["restful","webservice"]},{"title":"轻量级极速数据层访问框架mango","url":"http://www.vincentli.top/2016/06/22/mango-jfaster-dao-struct-intraductions/","content":"最近逛论坛发现了一个轻量级极速数据层访问框架－－mango。能够实现分表分库，功能还算比较强大。据官网介绍，mango的中文名是“芒果”，它是一个轻量级极速数据层访问框架。目前已有十多个大型线上项目在使用mango，在某一支付系统中，更是利用mango，承载了每秒12万的支付下单请求。\n下面是mango的一些特性:\n超高性能，响应速度接近直接使用JDBC\n采用接口与注解的形式定义DAO，完美结合db与cache操作\n支持动态sql，可以构造任意复杂的sql语句\n支持多数据源，分表，分库，事务\n内嵌“函数式调用”功能，能将任意复杂的对象，映射到数据库的表中\n高效详细的log统计，方便开发者随时了解自己的系统\n独立jar包，不依赖其它jar包\n提供便捷的spring插件，与spring无缝集成性能相关据官方称，测试下来效率和mybatis,spring-jdbc等不相上下。\n\n代码实践\n1.新建表fruit,user_0,user_1,user_2,user_3SET NAMES utf8;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------  Table structure for `fruit`-- ----------------------------DROP TABLE IF EXISTS `fruit`;CREATE TABLE `fruit` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(20) NOT NULL,  `num` int(11) NOT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;SET FOREIGN_KEY_CHECKS = 1;/*==========分割线============*/CREATE TABLE `user_0` (  `uid` int(11) NOT NULL,  `name` varchar(20) NOT NULL,  PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `user_1` (  `uid` int(11) NOT NULL,  `name` varchar(20) NOT NULL,  PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `user_2` (  `uid` int(11) NOT NULL,  `name` varchar(20) NOT NULL,  PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `user_3` (  `uid` int(11) NOT NULL,  `name` varchar(20) NOT NULL,  PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n2.新建maven工程，并引入依赖。&lt;dependency&gt;     &lt;groupId&gt;junit&lt;/groupId&gt;     &lt;artifactId&gt;junit&lt;/artifactId&gt;     &lt;version&gt;3.8.1&lt;/version&gt;     &lt;scope&gt;test&lt;/scope&gt;   &lt;/dependency&gt;   &lt;dependency&gt;     &lt;groupId&gt;org.jfaster&lt;/groupId&gt;     &lt;artifactId&gt;mango&lt;/artifactId&gt;     &lt;version&gt;1.3.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;mysql&lt;/groupId&gt;     &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;     &lt;version&gt;5.1.18&lt;/version&gt; &lt;/dependency&gt;\n3.新建操作表对应等Dao类和分表相关类。分表通常也被称为散表。 当某张表的数据量很大时，sql执行效率都会变低，这时通常会把大表拆分成多个小表，以提高sql执行效率。mango框架内部提供的8种分表策略:-整数模十分表，支持Integer或int参数类型，实现类为 IntegerModTenTablePartition-长整模十分表，支持Long或long参数类型，实现类为 LongModTenTablePartition-字符串模十分表，支持String参数类型，实现类为 StringModTenTablePartition-模十分表，支持Integer或int或Long或long或String参数类型，实现类为 ModTenTablePartition-整数模百分表，支持Integer或int参数类型，实现类为 IntegerModHundredTablePartition-长整模百分表，支持Long或long参数类型，实现类为 LongModHundredTablePartition-字符串模百分表，支持String参数类型，实现类为 StringModHundredTablePartition-模百分表，支持Integer或int或Long或long或String参数类型，实现类为 ModHundredTablePartition\n\n我们这次使用自定义分表，根据uid取模，可以分为4个分表。分表策略类通过@DB注解中的tablePartition参数传入，tablePartition参数接受任何实现了 TablePartition 接口的类，所以我们可以通过自己实现TablePartition接口，来完成任何自定义分表策略。下面是我们的自定义分表：package com.wdzj.mongo.util;import org.jfaster.mango.partition.TablePartition;/** * 整数模4分表 * @author lichaoqiang * @date 2016-06-22 * */public class ModFourTablePartition implements TablePartition&lt;Integer&gt; &#123;    public String getPartitionedTable(String table, Integer shardParam, int type) &#123;        // TODO Auto-generated method stub        return table + &quot;_&quot; + (shardParam % 4);    &#125;&#125;下面是操作数据库的DAO类，均采用注解。\npackage com.wdzj.mongo.dao;import org.jfaster.mango.annotation.DB;import org.jfaster.mango.annotation.SQL;/** * 表fruit的操作DAO,均使用注解方式来实现 * * */@DBpublic interface FruitDao &#123;     // 插入数据    @SQL(&quot;insert into fruit(name, num) values(:1, :2)&quot;)    public void add(String name, int num);     // 根据name取num的总和    @SQL(&quot;select sum(num) from fruit where name=:1&quot;)    public int getTotalNum(String name);    // 删除数据    @SQL(&quot;delete from fruit where name=:1&quot;)    public int deleteFruit(int id);&#125;//==================================package com.wdzj.mongo.dao;import org.jfaster.mango.annotation.DB;import org.jfaster.mango.annotation.SQL;import org.jfaster.mango.annotation.TableShardBy;import com.wdzj.mongo.model.User;import com.wdzj.mongo.util.ModFourTablePartition;@DB(table = &quot;user&quot;, tablePartition = ModFourTablePartition.class)public interface UserDao &#123;         @SQL(&quot;insert into #table(uid, name) values(:1, :2)&quot;)        public void addUser(@TableShardBy int uid, String name);        @SQL(&quot;select uid, name from #table where uid = :1&quot;)        public User getUser(@TableShardBy int uid);&#125;\n\n4.测试package com.wdzj.mongo.example;import org.jfaster.mango.operator.Mango;import com.wdzj.mongo.dao.FruitDao;import com.wdzj.mongo.util.MangoDBUtils;public class TestFruit &#123;    public static void main(String[] args) &#123;        // TODO Auto-generated method stub        //数据库连接方式一//            String driverClassName = &quot;com.mysql.jdbc.Driver&quot;;//            String url = &quot;jdbc:mysql://192.168.29.1:3306/mongo_demo&quot;;//            String username = &quot;root&quot;; // 这里请使用您自己的用户名//            String password = &quot;root&quot;; // 这里请使用您自己的密码//            DataSource ds = new DriverManagerDataSource(driverClassName, url, username, password);//            Mango mango = Mango.newInstance(ds); // 使用数据源初始化mango        //数据库连接方式二，自己封装好            Mango mango =MangoDBUtils.getMango();            FruitDao dao = mango.create(FruitDao.class);            String name = &quot;pear&quot;;            int num = 3;            dao.add(name, num);            System.out.println(dao.getTotalNum(name));    &#125;&#125;//＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝分表测试package com.wdzj.mongo.example;import org.jfaster.mango.operator.Mango;import com.wdzj.mongo.dao.UserDao;import com.wdzj.mongo.util.MangoDBUtils;/** * 测试分表 * */public class TestUserSplitTable &#123;    public static void main(String[] args) &#123;        // TODO Auto-generated method stub        testAddUser();        System.out.println(&quot;add user  ended................&quot;);        testGetUser();    &#125;    public static void testAddUser()&#123;          Mango mango =MangoDBUtils.getMango();          UserDao dao = mango.create(UserDao.class);          for(int i=0;i&lt;10;i++)&#123;              dao.addUser(i, &quot;张三&quot;+i);          &#125;    &#125;    public static void testGetUser()&#123;          Mango mango =MangoDBUtils.getMango();          UserDao dao = mango.create(UserDao.class);          for(int i=0;i&lt;10;i++)&#123;             System.out.println(dao.getUser(i));          &#125;    &#125;&#125;\n查看相关分表中测试的数据发现插入表是根据取模策略离散的，这个对于大量数据的表业务做分表有很大的参考意义。具体的demo代码可以在github源码上看到。还有很多有意思的功能等着去探索，后面更多实践后，再写点东西吧。\n\n","categories":["博客"],"tags":["分库","分表"]},{"title":"Packet for query is too large(1508792 > 1048576)","url":"http://www.vincentli.top/2016/06/13/PacketTooBigException-Packet-for-query-is-too-large/","content":"昨天在调试一个接口的时候，由于入参的字符串太长了，然后爆了一个问题，具体的日志如下：org.springframework.dao.TransientDataAccessResourceException: \\n###Error updating database.  Cause: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (1508792 &gt; 1048576).You can change this value on the server by setting the max_allowed_packet&#x27; variable.\\n###The error may involve com.wdzj.thirdpartzx.core.dao.OrderDetailMapper.insertSelectiveAndGetId-Inline\\n###The error occurred while setting parameters\\n###SQL: insert into tb_order ( owner_id,  amount, status,  plat_id, endpoint_id,                       sid, adder,  add_time, request_info ) values ( ?, ?, ?, ?, ?, ?, ?,  ?,  ? )\\n###Cause: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (1508792 &gt; 1048576).You can change this value on the server by setting the max_allowed_packet&#x27; variable.\\n; SQL [];Packet for query is too large (1508792 &gt; 1048576).You can change this value on the server by setting the max_allowed_packet&#x27; variable.; nested exception is com.mysql.jdbc.PacketTooBigException:Packet for query is too large (1508792 &gt; 1048576).You can change this value on the server by setting the max_allowed_packet&#x27; variable.,org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:106)看到这个日志的关键词Packet for query is too large(1508792 &gt; 1048576)，看这意思貌似是传给MySQL解析器的包太大了，默认是1M大小，1048576换算下来真多是1M啊，而我们传的参数数据包的大小1508792字节，换算下大概是1.43M，超过了默认的数据包的大小，怎么解决呢？日志中已经给出了You can change this value on the server by setting the max_allowed_packet’ variable，然后我自己大胆的尝试并验证有如下解决方案：查看了下Mysql的配置文件 my.cnf，看到有一行配置max_allowed_packet = 1M ，把它修改为4M或者更多，然后重启了下Mysql服务，然后登录数据库查询了下：show VARIABLES like ‘%max_allowed_packet%’;4194304换算下来就是4M，再次试了下，原来的插入语句可以正常使用。\n","categories":["博客","问题"],"tags":["Mysql"]},{"title":"Spring 4.0.2.RELEASE和xfire1.2.6集成后出现一个奇葩问题","url":"http://www.vincentli.top/2016/04/22/spring4-xfire1-2-6-integration-error-solution/","content":"最近遇到一个奇葩的问题，我们的后台Dubbo服务已经和Spring 4.0.2.RELEASE版本集成，因为需要和一个第三方服务提供方对接，而对方提供的接口是web Service的，而且使用的框架是xfire。我们的技术对接童鞋，按照对方提供的技术文档进行代码编写，在pom.xml中添加了一段依赖导入相关需要的jar包,配置如下：\n &lt;dependency&gt;    &lt;groupId&gt;org.codehaus.xfire&lt;/groupId&gt;    &lt;artifactId&gt;xfire-all&lt;/artifactId&gt;    &lt;version&gt;1.2.6&lt;/version&gt;&lt;/dependency&gt;然后当代码开发已经写得差不多了，在调试的时候就出现一个奇葩问题，老是报一个错org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 96; Document root element “beans”, must match DOCTYPE root “null”.具体的报错信息如下：sh-3.2# sh bin/startDev.shListening for transport dt_socket at address: 9555[com.alibaba.dubbo.common.logger.LoggerFactory] - using logger: com.alibaba.dubbo.common.logger.log4j.Log4jLoggerAdapter   [com.alibaba.dubbo.container.Main] -  [DUBBO] Use container type([spring]) to run dubbo serivce., dubbo version: 2.4.9, current host: 127.0.0.1   [org.springframework.beans.factory.xml.XmlBeanDefinitionReader] - Loading XML bean definitions from URL [file:/Users/lichaoqiang/wdzj/svn_new/projects/credit-thirdpartzx/trunk/target/wdzj-thirdpartzx-1.1.1-SNAPSHOT-pack/thirdpartzx/conf/dubbo/provider.xml]   org.springframework.beans.factory.BeanDefinitionStoreException: Line 5 in XML document from URL [file:/Users/lichaoqiang/wdzj/svn_new/projects/credit-thirdpartzx/trunk/target/wdzj-thirdpartzx-1.1.1-SNAPSHOT-pack/thirdpartzx/conf/dubbo/provider.xml] is invalid; nested exception is org.xml.sax.SAXParseException: Document root element &quot;beans&quot;, must match DOCTYPE root &quot;null&quot;.org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 96; Document root element &quot;beans&quot;, must match DOCTYPE root &quot;null&quot;.    at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)    at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)    at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)    at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)    at org.apache.xerces.impl.dtd.XMLDTDValidator.rootElementSpecified(Unknown Source)    at org.apache.xerces.impl.dtd.XMLDTDValidator.handleStartElement(Unknown Source)    at org.apache.xerces.impl.dtd.XMLDTDValidator.startElement(Unknown Source)    at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown Source)    at org.apache.xerces.impl.XMLDocumentScannerImpl$ContentDispatcher.scanRootElementHook(Unknown Source)    at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)    at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)    at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)    at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)    at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)    at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)    at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:222)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:173)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:148)    at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:126)    at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:142)    at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:113)    at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:81)    at org.springframework.context.support.AbstractRefreshableApplicationContext.refreshBeanFactory(AbstractRefreshableApplicationContext.java:89)    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:269)    at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:87)    at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:72)    at com.alibaba.dubbo.container.spring.SpringContainer.start(SpringContainer.java:50)    at com.alibaba.dubbo.container.Main.main(Main.java:80)经过查证相关资料，发现原来有一个xfire-all导入的一个jar包中依赖了一个1.2.6版本的spring的jar包，而我们的项目采用的Spring的版本就是4.0.2.RELEASE，所以就有冲突。解决办法就是把spring相关的jar包exclusion。具体的办法是修改pom.xml:&lt;dependency&gt;        &lt;groupId&gt;org.codehaus.xfire&lt;/groupId&gt;        &lt;artifactId&gt;xfire-all&lt;/artifactId&gt;        &lt;version&gt;1.2.6&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;xfire-spring&lt;/artifactId&gt;                &lt;groupId&gt;org.codehaus.xfire&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;\n","categories":["博客","问题"],"tags":["Spring","Xfire"]},{"title":"tomcat运行中途自动退出，问题查证","url":"http://www.vincentli.top/2016/04/08/tomcat-run-exit-error/","content":"我们的一个tomcat 7运行应用本来在测试环境运行良好，最近突然应用就自动退出停服，有点奇怪，查看了启动（tailf -n 200 catalina.out）日志获得一段有效的日志信息：ERROR: transport error 202: bind failed: Address already in useERROR: JDWP Transport dt_socket failed to initialize, TRANSPORT_INIT(510)JDWP exit error AGENT_ERROR_TRANSPORT_INIT(197): No transports initialized [../../../src/share/back/debugInit.c:750]FATAL ERROR in native method: JDWP No transports initialized, jvmtiError=AGENT_ERROR_TRANSPORT_INIT(197)  如何解决呢？我们可以从这段日志下手分析。这段日志信息反馈是在tomcat运行时，debug时由于debug端口已经被占用，刚好我们部署该服务器上的还有另外一个tomcat应用在运行。所以，只能修改当前的tomcat的debug接口，具体的修改位置在tomcat的catalina.sh脚本中。如何\b操作如下：找到catalina.sh中如下启动\b\b\b\b\b\b\b 脚本：if [ &quot;$1&quot; = &quot;jpda&quot; ] ; then  if [ -z &quot;$JPDA_TRANSPORT&quot; ]; then    JPDA_TRANSPORT=&quot;dt_socket&quot;  fi  if [ -z &quot;$JPDA_ADDRESS&quot; ]; then    JPDA_ADDRESS=&quot;8000&quot;  fi  if [ -z &quot;$JPDA_SUSPEND&quot; ]; then    JPDA_SUSPEND=&quot;n&quot;  fi  if [ -z &quot;$JPDA_OPTS&quot; ]; then    JPDA_OPTS=&quot;-agentlib:jdwp=transport=$JPDA_TRANSPORT,address=$JPDA_ADDRESS,server=y,suspend=$JPDA_SUSPEND&quot;  fi  CATALINA_OPTS=&quot;$JPDA_OPTS $CATALINA_OPTS&quot;  shiftfi\b\b改一下address\b默认端口号8000\b\b\b，为其他空闲端口号，重启即可。\n","categories":["博客","问题"],"tags":["运维","Tomcat"]},{"title":"jenkins配置一个项目自动部署的步骤实践","url":"http://www.vincentli.top/2016/04/07/jenkins-how-to-make-auto-deploy/","content":"Jenkins是一个开源软件项目，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。Jenkins是基于Java开发的一种持续集成工具，用于监控持续重复的工作，功能包括：\n\n1、持续的软件版本发布/测试项目。\n2、监控外部调用执行的工作。\n\n我们可以用Jenkins来配置一套自动编译发布项目的流程。下面我们以一个简单的例子来说明。主要有以下步骤：\n\n1 新建一个项目credit,选择构建一个Maven项目:\n\n2 进行项目的具体配置\n2.1 进入配置页面\n2.2 可以写项目描述，限定一下项目构建\n2.3 设置代码下载的SVN地址：\n2.4 可以设置每天自动定时发布，构建时是用maven的命令： -Dmaven.test.skip=true clean install package -Denv=dev\n\n\n\n\n3 自定义自动部署的shell脚本   ps:要在shell代码之前添加BUILD_ID=DONTKILLME，这样才不至于中途应用被停止，部署没完成就结束了。 脚本主要的内容包含：备份原来的包，发布新的包，重启相关的应用服务。\nBUILD_ID=DONTKILLMEcd /opt/java/front/apache-tomcat-7.0.67sh bin/shutdown.shsleep 1rm -rf webapps/front.war.bak#备份frontmv webapps/front.war webapps/front.war.bakcp -rf /jenkins/workspace/credit/credit-web/target/front.war webapps/front.warsh bin/startup.shsleep 1echo &quot;front app started......&quot;echo &quot;back app operation......&quot;cd /opt/java/back_tomcat/apache-tomcat-7.0.67sh bin/shutdown.shsleep 1rm -rf webapps/back.war.bak#备份backmv webapps/back.war webapps/back.war.bakcp -rf /jenkins/workspace/credit/credit-manager-web/target/back.war webapps/back.warsh bin/startup.shsleep 1echo &quot;back app started……&quot;\n\n\n\n  Q&amp;A:  Q:一不小心删除了相关job的配置数据后，重新配置相同名的项目的构建部署过程后，发现立即构建会报错：  java.lang.IllegalStateException: cannot create a build with number 5 since that (or higher) is already in use among [204]，那么如何解决呢？  A:可以把相关job的配置文件(/root/.jenkins/jobs/jobName/nextBuildNumber)中的值修改成报错中的值204或者更大的205。  然后重启jenkins的web部署应用tomcat。然后再进行构建即可成功。\n","categories":["博客"],"tags":["部署"]},{"title":"多并发时支付如何保持账户余额的一致性？","url":"http://www.vincentli.top/2016/03/14/dispatch-pay-balance-keep-consistence/","content":"\n&nbsp;&nbsp;不管是电商，还是O2O业务都会涉及到支付，而且多速情况下流量比较大，尤其是在做活动的时候。一般支付系统主要有充值，扣费，提现，转账等功能，那么在有些业务场景下，尤其是多并发的情况下，我们在做扣费业务操作时该怎样去保持账户余额的一致呢？Java开发人员可能第一个想法就是在调用扣减的DAO的方法上加上一个synchronized关键字，这个解决办法在单节点应用部署是也许能生效管用，但是在我们实际的应用场景中，一般都是集群，多节点部署的应用，这个时候该如何解决呢？我们有一张账户表tb_account\n\n\n\nfield\ntype\ndesc\n\n\n\n\nuid\nbigint\n用户id\n\n\nbalance\ndecimal\n余额\n\n\nupdate_time\ndatetime\n表数据更新时间\n\n\n\n扣费之前，我们要先查询一下账户的余额是否足够抵扣，然后再做真正的减扣。大致的过程如下：\n\n\bselect balance from tb_account where uid=100;\n程序判断balance的值是否足够抵扣。\nupdate tb_account set balance = balance - 28.00, update_time = sysdate() where uid=100;通常情况下，这种余额判断\b方法在高并发且不加锁的情况下是非常不可靠的。所以在做扣费操作时要考虑到并发扣费的情况，允许让其并发扣费，但是不应该允许账户余额为负数。转账的话也是一样，相当于先从一个账户扣费，再给另一个账户充值，都必须要在一个事务内完成。可以使用一个存储过程来把这些步骤统一起来。下面的存储过程亲测可用。\n\ncreate procedure proc_account_balance_dec ( in_money decimal(8,2), in_uid bigint, OUT status int )  BEGIN  DECLARE from_account_balance decimal(8,2);  START TRANSACTION;  SELECT balance INTO from_account_balance FROM tb_account      WHERE uid = in_uid FOR UPDATE;  IF from_account_balance&gt;=in_money THEN       UPDATE tb_account SET balance = balance - in_money , update_time = sysdate()          WHERE uid = in_uid;      COMMIT;      SET status=1;  ELSE       ROLLBACK;      SET status=0;  END IF;  END;  \n","categories":["博客","并发"],"tags":["分布式","并发","支付"]},{"title":"Redis分布式锁Java实现","url":"http://www.vincentli.top/2016/03/14/redis-distribute-lock-java/","content":"redis分布式锁可以解决多个应用进程间同步操作的一致性。网上有很多资料并不能完全解决。\n\n1.时间同步问题\n2.在一个进程crash后失效时间后自动释放锁\n3.有些多线程race condition没有考虑到\n\nJava版本的代码参考如下\npackage com.wdzj.jedis.distribution.test;import java.util.Iterator;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicLong;import org.apache.commons.pool2.impl.GenericObjectPoolConfig;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.exceptions.JedisException;/** * Jedis实现分布式锁 * * @author hello * */public class JedisDistributionLock &#123;    private final static long ACCQUIRE_LOCK_TIMEOUT_IN_MS = 10 * 1000;    private final static int EXPIRE_IN_SECOND = 5;//锁失效时间    private final static long WAIT_INTERVAL_IN_MS = 100;    private final JedisPool jedisPool;    private final long acquireLocktimeoutInMS;    private final int expireInSecond;    private final long waitIntervalInMS;    private final ConcurrentMap&lt;String, String&gt; settedKeys;    public JedisDistributionLock(final JedisPool jedisPool,            final long acquireLocktimeout, final int expireInSecond,            final long waitIntervalInMS) &#123;        this.jedisPool = jedisPool;        this.acquireLocktimeoutInMS = acquireLocktimeout;        this.expireInSecond = expireInSecond;        this.waitIntervalInMS = waitIntervalInMS;        this.settedKeys = new ConcurrentHashMap&lt;String, String&gt;();    &#125;    public JedisDistributionLock(final JedisPool jedisPool) &#123;        this(jedisPool, ACCQUIRE_LOCK_TIMEOUT_IN_MS, EXPIRE_IN_SECOND,                WAIT_INTERVAL_IN_MS);    &#125;    public void lock(final String redisKey) throws Exception &#123;        validateRedisKeyName(redisKey);        Jedis resource = null;        try &#123;            resource = jedisPool.getResource();            long timeoutAt = currentTimeMillisFromRedis()                    + acquireLocktimeoutInMS;            boolean flag = false;            while (true) &#123;                String expireAt = String.valueOf(currentTimeMillisFromRedis()                        + expireInSecond * 1000);                long ret = resource.setnx(redisKey, expireAt);                if (ret == 1) &#123;                    settedKeys.put(redisKey, expireAt);                    flag = true;                    break;                &#125; else &#123;                    String oldExpireAt = resource.get(redisKey);                    if (oldExpireAt != null                            &amp;&amp; Long.parseLong(oldExpireAt) &lt; currentTimeMillisFromRedis()) &#123;                        oldExpireAt = resource.getSet(redisKey, expireAt);                        if (Long.parseLong(oldExpireAt) &lt; currentTimeMillisFromRedis()) &#123;                            settedKeys.put(redisKey, expireAt);                            flag = true;                            break;                        &#125; else &#123;                            // loop ...                        &#125;                    &#125; else &#123;                        // loop ...                    &#125;                &#125;                if (acquireLocktimeoutInMS &lt;= 0                        || timeoutAt &lt; currentTimeMillisFromRedis()) &#123;                    break;                &#125;                try &#123;                    TimeUnit.MILLISECONDS.sleep(waitIntervalInMS);                &#125; catch (Exception ignore) &#123;                &#125;            &#125;            if (!flag) &#123;                throw new RuntimeException(&quot;canot acquire lock now ...&quot;);            &#125;        &#125; catch (JedisException je) &#123;            je.printStackTrace();            if (resource != null) &#123;                jedisPool.returnBrokenResource(resource);            &#125;            throw je;        &#125; catch (Exception e) &#123;            e.printStackTrace();            throw e;        &#125; finally &#123;            if (resource != null) &#123;                jedisPool.returnResource(resource);            &#125;        &#125;    &#125;    public boolean unlock(final String name) throws Exception &#123;        validateRedisKeyName(name);        Jedis resource = null;        try &#123;            resource = jedisPool.getResource();            resource.del(name);            settedKeys.remove(name);            return true;        &#125; catch (JedisException je) &#123;            je.printStackTrace();            if (resource != null) &#123;                jedisPool.returnBrokenResource(resource);            &#125;            return false;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125; finally &#123;            if (resource != null) &#123;                jedisPool.returnResource(resource);            &#125;        &#125;    &#125;    public boolean unlockAll() throws Exception &#123;        Jedis resource = null;        try &#123;            resource = jedisPool.getResource();            Iterator&lt;String&gt; iter = settedKeys.keySet().iterator();            while (iter.hasNext()) &#123;                String key = iter.next();                resource.del(key);                settedKeys.remove(key);            &#125;            return true;        &#125; catch (JedisException je) &#123;            je.printStackTrace();            if (resource != null) &#123;                jedisPool.returnBrokenResource(resource);            &#125;            return false;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125; finally &#123;            if (resource != null) &#123;                jedisPool.returnResource(resource);            &#125;        &#125;    &#125;    private void validateRedisKeyName(String name) &#123;        if (name == null || &quot;&quot;.equals(name.trim())) &#123;            throw new IllegalArgumentException(&quot;validateKey fail.&quot;);        &#125;    &#125;    private Long currentTimeMillisFromRedis() throws Exception &#123;        Jedis resource = null;        try &#123;            resource = jedisPool.getResource();            return Long.parseLong(resource.time().get(0)) * 1000;        &#125; catch (JedisException je) &#123;            je.printStackTrace();            if (resource != null) &#123;                jedisPool.returnBrokenResource(resource);            &#125;            throw je;        &#125; catch (Exception e) &#123;            e.printStackTrace();            throw e;        &#125; finally &#123;            if (resource != null) &#123;                jedisPool.returnResource(resource);            &#125;        &#125;    &#125;    public static void main(String[] args) throws Exception &#123;        ExecutorService executorService = Executors.newCachedThreadPool();        GenericObjectPoolConfig config = new GenericObjectPoolConfig();        config.setMaxIdle(200);        config.setMaxTotal(200);        JedisPool pool = new JedisPool(config, &quot;192.168.8.21&quot;, 6379, 3000,                &quot;########&quot;);        final JedisDistributionLock jedisDistributionLock = new JedisDistributionLock(                pool);        final int threadNum = 8;        final CountDownLatch countDownLatch = new CountDownLatch(threadNum);        final int reqsPerThread = 10;        final AtomicLong seq = new AtomicLong(0);        final String key = &quot;qq&quot;;        for (int i = 0; i &lt; threadNum; i++) &#123;            executorService.submit(new Runnable() &#123;                public void run() &#123;                    System.out.println(Thread.currentThread().getId()                            + &quot; start...&quot;);                    try &#123;                        for (int j = 0; j &lt; reqsPerThread; j++) &#123;                            jedisDistributionLock.lock(key);                            System.out.println(seq.incrementAndGet());                            jedisDistributionLock.unlock(key);                        &#125;                    &#125; catch (Exception e) &#123;                        e.printStackTrace();                    &#125; finally &#123;                        countDownLatch.countDown();                    &#125;                &#125;            &#125;);        &#125;        countDownLatch.await();        System.out.println(&quot;----------------------------&gt;&quot; + seq.longValue());        if (threadNum * reqsPerThread == seq.longValue()) &#123;            System.out.println(&quot;-------------ok-----------&quot;);        &#125; else &#123;            System.err.println(&quot;-------------err-----------&quot;);        &#125;    &#125;&#125;\n\n参考资料http://blog.csdn.net/alsocoderalsogeek/article/details/50888468http://www.cnblogs.com/wuhuajun/p/5242644.html\nhttp://www.cnblogs.com/it-cen/p/4984272.html\n","categories":["博客","并发"],"tags":["Java","分布式","多线程","Redis"]},{"title":"HashMap的遍历最优方式","url":"http://www.vincentli.top/2016/02/26/HashMap-best-interator-way/","content":"HashMap的遍历最优方式建议使用entrySet()的方式,因为在数据量比较大的时候，它的效率更高。\n话不多说，请看下面的源代码public static void testEfficiency()&#123;        HashMap hmap = new HashMap();        for(int i=0;i&lt;100;i++)&#123;            hmap.put(&quot;key&quot;+i, i*10);        &#125;        System.out.println(&quot;------遍历方式1：使用entrySet----遍历key和value----------------------&quot;);        long start1 = System.currentTimeMillis();        for (Iterator it = hmap.entrySet().iterator(); it.hasNext();) &#123;            Map.Entry entry = (Map.Entry) it.next();            System.out.println(entry.getKey() + &quot;=&quot; + entry.getValue());        &#125;        long end1 = System.currentTimeMillis();        System.out.println(&quot;方式一，耗时：&quot;+(end1-start1) +&quot;ms&quot;);        System.out.println(&quot;------遍历方式2：使用keySet----遍历key和value----------------------&quot;);        long start2 = System.currentTimeMillis();        for (Iterator it = hmap.keySet().iterator(); it.hasNext();) &#123;            String key=  (String) it.next();            System.out.println(key + &quot;=&quot; + hmap.get(key));        &#125;        long end2 = System.currentTimeMillis();        System.out.println(&quot;方式二，耗时：&quot;+(end2-start2) +&quot;ms&quot;);    &#125;\n执行上面的代码后，会出现下面的结果：key79=790\nkey78=780\nkey38=380\nkey39=390\nkey34=340\nkey35=350\nkey36=360······\nkey28=280\nkey76=760\nkey27=270\nkey75=750\nkey74=740\nkey29=290\n方式一，耗时：1ms\n——遍历方式2：使用keySet—-遍历key和value———————-\nkey79=790\nkey78=780\nkey38=380\nkey39=390\nkey34=340\nkey35=350\n······key71=710\nkey26=260\nkey70=700\nkey25=250\nkey77=770\nkey28=280\nkey76=760\nkey27=270\nkey75=750\nkey74=740\nkey29=290\n方式二，耗时：2ms\n\n所以，从上面的简单的比较，可以得出当我们需要遍历HashMap的时候，使用EntrySet的遍历的方式效率更高，尤其是数据量比较大的时候，效果越明显。同步更新：HashMap的遍历最优方式\n","categories":["博客","Java"],"tags":["HashMap","Java","Map"]}]