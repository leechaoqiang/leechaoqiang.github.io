[{"title":"uName类似首字符小写属性Json序列化接收不到数据问题及解决办法","url":"http://leechaoqiang.github.io/2021/03/01/lowcase-start-word-json-serialize-error/","content":"问题背景最近因为发现有一个表字段被设计成u_name，然后用工具生产的实体的属性字段是uName，就是首字母是小写，第二个字母是大写的这类属性，然后我们关于这个字段的一个接口的请求对象VO中字段也是沿用的uName。然后postman测试提交数据的时候，json请求体中字段属性也是uName。\n我们这个项目是采用SpringBoot 2.1.5.RELEASE的，json序列化的工具是jackson，版本是2.9.8，这可能是jackson对于这类字段属性json序列号支持不太友好的地方。\n解决方案\n采用@JsonProperty注解给uName属性字段定义json字段别名./** * 姓名 */@JsonProperty(&quot;uName&quot;)private String uName;\n给请求VO实体添加@JsonAutoDetect注解@Data@JsonAutoDetect(fieldVisibility=JsonAutoDetect.Visibility.ANY, getterVisibility=JsonAutoDetect.Visibility.NONE)public class UserVO &#123;    /**     - 姓名     */     private String uName;&#125;\n\n\n注解说明@JsonAutoDetect该注解的作用是配置自动识别的类型：\n有以下四个属性：\n\ngetterVisibility：定义getter方法的识别范围。\nisGetterVisibility：定义is-getter方法的识别范围(boolean类型的getter，很少用)。\nsetterVisibility：定义setter方法的识别范围。\ncreatorVisibility：定义构造器识别范围。\nfieldVisibility：定义属性识别范围。识别范围是一个枚举，包括：\nVisibility.ANY：表示从 private 到 public 修饰，都可识别。\nVisibility.NON_PRIVATE：表示除 private 修饰不可识别，其他都识别。\nVisibility.PROTECTED_AND_PUBLIC：protected 和 public都识别。\nVisibility.PUBLIC_ONLY：仅 public 可见。\nVisibility.NONE：所有皆不可见。\nVisibility.DEFAULT：缺省，所有被 public 修饰的属性、 getter 和所有 setter皆可见。\n\n","categories":["SpringBoot","Java"],"tags":["Java","SpringBoot","Json","jackson"]},{"title":"手机摄影之城市一角（一）","url":"http://leechaoqiang.github.io/2020/09/16/photo/","content":"\n","categories":["摄影"],"tags":["美图欣赏"]},{"title":"JVM高性能本地缓存Caffeine使用案例","url":"http://leechaoqiang.github.io/2020/09/01/jvm-local-cache-case-caffeine/","content":"Background对于服务消费，响应时间（RT）的长短是衡量一个系统高效处理业务的重要指标，缓存就是必不可少的优化工具，在一个高并发的场景中往往占有着非常重要的角色，所以开发人员需要根据不同的应用场景来选择不同的缓存框架，比如分布式缓存redis，或者内存缓存GuavaCache。\n我们团队有一个调用比较频繁的服务，之前是和别的团队共用的Redis缓存服务，前不久突然得到消息，维护该redis团队要收回使用权，而我们服务使用也比较简单，只是用来做一个接口调用鉴权，从redis中拿出所有授权方的appKey，然后校验调用方的appKey是否合法。所以我第一想法是采用jvm本地缓存，因为这个调用方不会很多，而且数据是比较静态的，变化不会很频繁，放在jvm本地内存中，也不会占用很大空间，而且也不用担心多个部署实例缓存不一致的问题，经过调用有很多比较优秀的本地缓存比如GuavaCache，Caffeine等。我最后采用了Caffeine。    \nWhat is Caffeine？内存缓存与Map之间的本质区别就是能自动的回收存储的元素，而GuavaCache是一款非常优秀的内存缓存框架，很好的提供了读写和自动失效的功能。而今天要介绍的内存缓存Caffeine，在设计上参考了GuavaCache的经验，也进行了大量的改进优化，除了之前提到的GuavaCache的优点，还可以支持自动刷新，失效后自动加载等优点。以下数据图片均来源于Caffeine GitHub，首先是读写性能的比较：\n8个线程同时从缓存中读取 8个线程同时从缓存中写入  6个线程读取，2个线程写入 从上面的测试结果图，我们可以看出caffeine在读写方面明显优与其他框架，在缓存命中率上Caffeine也不同于Guava，采用了更为优秀的Window TinyLfu算法，该算法是在LRU的基础上改进的版本。\nFeature填充策略\n1、手动填充\n  Caffeine.newBuilder()方法只是Caffeine类的一个空的构造函数，类属性的实例化是在build方法中进行的，put方法就是手动填充缓存。newBuilder方法后面还能跟很多配置方法，比如\nCache&lt;String, Map&lt;String, String&gt;&gt; cache = Caffeine.newBuilder().maximumSize(5000).expireAfterWrite(172800L, TimeUnit.MILLISECONDS).build();Map&lt;String, String&gt; value = Maps.newHashMap();cache.put(&quot;key&quot;, value)\n\n\n我们也可以使用 get 方法获取值，该方法将一个参数为 key 的 Function 作为参数传入。如果缓存中不存在该 key，则该函数将用于提供默认值，该值在计算后插入缓存中。Caffeine类是Caffeine的基础类，里面提供了很多配置方法和参数：maximumSize：设置缓存最大条目数，超过条目则触发回收。 maximumWeight：设置缓存最大权重，设置权重是通过weigher方法， 需要注意的是权重也是限制缓存大小的参数，并不会影响缓存淘汰策略，也不能和maximumSize方法一起使用。 weakKeys：将key设置为弱引用，在GC时可以直接淘汰weakValues：将value设置为弱引用，在GC时可以直接淘汰softValues：将value设置为软引用，在内存溢出前可以直接淘汰expireAfterWrite：写入后隔段时间过期expireAfterAccess：访问后隔断时间过期refreshAfterWrite：写入后隔断时间刷新removalListener：缓存淘汰监听器，配置监听器后，每个条目淘汰时都会调用该监听器writer：writer监听器其实提供了两个监听，一个是缓存写入或更新是的write，一个是缓存淘汰时的delete，每个条目淘汰时都会调用该监听器手动填充表示任何数据都需要手动put到cache中，没有任何自动加载策略。put方法会覆盖相同key的条目\n\n同步填充\n异步填充异步填充于同步填充大致相似，区别是传入一个执行器进行异步执行，并且返回一个CompletableFuture对象，可以通过CompletableFuture.get来获取数据并设置超时时间。\n\n回收策略条目的自动淘汰回收是map于cache最大的区别，Caffeine同样包含了3中缓存回收机制，分别是基于大小，基于时间，基于引用类型。\n\n基于大小\n基于时间\n基于引用类型自动刷新cache除了会自动淘汰缓存数据，也能进行自动刷新缓存数据。private static Cache&lt;String, String&gt; cache = Caffeine.newBuilder().expireAfterWrite(10000, TimeUnit.MILLISECONDS).refreshAfterWrite(10000, TimeUnit.MILLISECONDS).build();\nrefreshAfterWrite就是设置写入后多就会刷新，expireAfterWrite和refreshAfterWrite的区别是，当缓存过期后，配置了expireAfterWrite，则调用时会阻塞，等待缓存计算完成，返回新的值并进行缓存，refreshAfterWrite则是返回一个旧值，并异步计算新值并缓存。\n\nCaffeine的使用案例代码/** * @author vincent.li * @Description ConfigCache本地缓存类 * @since 2020/9/01 */@Component@Slf4jpublic class ConfigCache &#123;    /**     * 自己实现的一个查询配置表数据的服务     */    @Autowired    private ConfigService configService;    private static Lock lock = new ReentrantLock();    /**     * key过期时间     * 全量刷新没有用invalidateAll（为了时并发线程可以获取到缓存旧值），对于数据库中已删除的key，需要靠过期来使其失效     *     */    private static final long EXPIRE_TIME = 172800L;    /**     * 上一次字典全量刷新的时间     */    private static long lastRefreshTime = 0L;    /**     * 全量字典数据刷新时间间隔，需小于单个key过期时间，否则刷新字典时，并发线程可能遇到key过期的情况     */    private static final long REFRESH_INTERVAL = 86400L;    private static Cache&lt;String, Map&lt;String, String&gt;&gt; configTypeCache = Caffeine.newBuilder().maximumSize(5000).expireAfterWrite(EXPIRE_TIME, TimeUnit.MILLISECONDS).build();    private static Cache&lt;String, String&gt; cache = Caffeine.newBuilder().expireAfterWrite(10000, TimeUnit.MILLISECONDS).refreshAfterWrite(10000, TimeUnit.MILLISECONDS).build();    /**     * 加载全量字典数据到缓存     */    @PostConstruct    public void reload() &#123;        try &#123;            log.info(&quot;start reload ConfigCache cache&quot;);            //获取全量字典数据            Map&lt;String, Map&lt;String, String&gt;&gt; configMap = configService.selectConfigItemMap();            configTypeCache.putAll(configMap);            lastRefreshTime = System.currentTimeMillis();            log.info(&quot;finish reload ConfigCache cache&quot;);        &#125; catch (Exception e) &#123;            log.warn(&quot;加载OrderPrintConfig失败&quot;, e);        &#125;    &#125;    /**     * 根据type获取configMap&lt;key,value&gt;，会判断是否需要全量刷新缓存     * @param type 类型     * @return Map&lt;String, String&gt;     */    public static Map&lt;String, String&gt; getByType(String type) &#123;        if (StringUtils.isEmpty(type)) &#123;            return Maps.newHashMap();        &#125;        try &#123;            if (System.currentTimeMillis() - lastRefreshTime &gt; REFRESH_INTERVAL) &#123;                if (lock.tryLock()) &#123;                    try &#123;                        if (System.currentTimeMillis() - lastRefreshTime &gt; REFRESH_INTERVAL) &#123;                            ApplicationContext ctx = SpringBeanUtil.getContext();                            if (Objects.nonNull(ctx) &amp;&amp; Objects.nonNull(ctx.getBean(OrderPrintConfigCache.class))) &#123;            ConfigCache configCache = ctx.getBean(ConfigCache.class);                                configCache.reload();                            &#125;                            return configTypeCache.getIfPresent(type);                        &#125;                    &#125; catch (Exception e) &#123;                        log.info(&quot;configTypeCache数据更新异常&quot;, e);                    &#125; finally &#123;                        lock.unlock();                    &#125;                &#125; else &#123;                    //获取锁失败，表明另一线程正在更新全量字典，直接从缓存中拿旧值                    return configTypeCache.getIfPresent(type);                &#125;            &#125;            return configService.get(type, ConfigCache::loadDictByType);        &#125; catch (Exception e) &#123;            log.info(&quot;configTypeCache缓存未命中&quot;, e);            return Maps.newHashMap();        &#125;    &#125;    private static Map&lt;String, String&gt; loadDictByType(String type) &#123;        ApplicationContext ctx = SpringBeanUtil.getContext();        if (Objects.nonNull(ctx) &amp;&amp;  Objects.nonNull(ctx.getBean(ConfigCache.class))) &#123;            ConfigCache dictCache = ctx.getBean(ConfigCache.class);            return dictCache.loadByKey(type);        &#125;        return Maps.newHashMap();    &#125;    private Map&lt;String, String&gt; loadByKey(String type) &#123;       return ConfigService.selectConfigItemMap(type);    &#125;&#125;","categories":["缓存"],"tags":["缓存,JVM,caffeine,redis"]},{"title":"减少重复劳动,使用Mysql存储过程批量创建表","url":"http://leechaoqiang.github.io/2020/08/25/mysql-procedure-batch-create-table-pratise/","content":"背景相信很多公司发展到一定规模，数据量达到千万级甚至亿级别的时候，开始考虑分库分表，最近我们团队一个同事接到别的团队交接过来的一个应用服务，每天的数据增量在1千万，由于时间紧迫，存储数据在Mysql中，经过短暂调研我们采用了分库分表的中间件Apache ShardingSphere的分库分表组件ShardingSphere-JDBC,这不是本文的重点，重点是我们做分库分表时，需要一次性创建几十甚至上百张分表，如果Ctrl+C和Ctrl+V也是极其累的，同事问我有木有简单的方法，减少重复劳动，我第一个想法就是用Mysql的存储过程或者函数批量创建表，解放生产力。\nMysql批量创建分表的过程\n下面我以简化版的order表来举例说明操作过程\n准备一个基本表orderCREATE TABLE `order` (  `order_id` bigint(20) NOT NULL COMMENT &#x27;住建ID&#x27;,  `order_no` varchar(20) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;订单号&#x27;,  `is_deleted` tinyint(2) NOT NULL DEFAULT &#x27;0&#x27; COMMENT &#x27;是否逻辑删除(0-否,1-是)&#x27;,  `create_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#x27;创建时间&#x27;,  `update_time` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#x27;更新时间&#x27;,  `remarks` varchar(255) NOT NULL DEFAULT &#x27;&#x27; COMMENT &#x27;备注&#x27;,  PRIMARY KEY (`order_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&#x27;订单表&#x27;;\n\n创建一个批量创建order分表的存储过程CREATE DEFINER=`root`@`%` PROCEDURE `batch_create_table_order`()begindeclare i int default 0;declare tab_name varchar(200) default &#x27;&#x27;;while i &lt; 20 do        set tab_name = concat(&#x27;create table  order_&#x27;,i, &#x27; as select * from         `order` where 1=2;&#x27;);        SET @SQL = CONCAT(tab_name);            PREPARE stmt FROM @SQL ;    EXECUTE stmt;    DEALLOCATE PREPARE stmt;        set i = i + 1;end while;end\n执行存储过程\n执行SQL命令call batch_create_table_order();\n执行结果和耗时：从执行的结果和耗时来看，不到1s就创建出了20张分表，如果是100张分表执行也只有1到2s,比起传统的Ctrl+C,Ctrl+V效率提升真是开心到飞起，多余的时间去刷刷虎扑，看看球，真香。\n\n","categories":["博客","Mysql"],"tags":["Mysql","存储过程"]},{"title":"Tomcat高危安全漏洞影响SpringBoot和SpringCloud多个版本及解决方案","url":"http://leechaoqiang.github.io/2020/07/06/tomcat-unsafe-hole-solution/","content":"事件背景2020是庚子年，是不平凡的一年，据2020年6月25日Apache官方安全团队通过邮件公开报告显示，Tomcat版本8.5.0 至 8.5.55，9.0.0.M1 至 9.0.35，10.0.0-M1 至10.0.0-M5爆出了一个高危漏洞， 主要涉及HTTP/2拒绝服务漏洞的细节及解决方案。    漏洞细节如下图所示：\n\n漏洞名称：Apache Tomcat HTTP/2 拒绝服务漏洞\n漏洞编号：CVE-2020-11996\n严重程度: 重要\n软件提供商: Apache 软件基金会\n受影响的版本：Apache Tomcat 10.0.0-M1 ~ 10.0.0-M5Apache Tomcat 9.0.0.M1 ~ 9.0.35Apache Tomcat 8.5.0 ~ 8.5.55\n漏洞描述：一个特别制作的 HTTP/2 请求序列，在短短数秒内能导致 CPU 满负载率，如果有足够数量多的此类请求连接（HTTP/2）并发放在服务器上，服务器可能会失去响应。如果条件允许，可以通过升级到Tomcat新版本来解决漏洞。下面为受影响版本对应的安全版本：Apache Tomcat 10.0.0-M6+Apache Tomcat 9.0.36+Apache Tomcat 8.5.56+\nSpringCloud/SpringBoot框架影响\n\nApache Tomcat HTTP/2 拒绝服务漏洞给SpringCloud /SpringBoot框架带来了一定的影响。下面是所有受影响的版本列表，大家可以查看并对照下自己的代码，看看是否受到影响。\nSpring Cloud Edgware / Spring Boot 1.5.xSpring Cloud [Edgware.RELEASE - Edgware.SR6] 版本受到影响。\nSpring Boot [1.5.0.RELEASE - 1.5.22.RELEASE] 版本受到影响。\nSpring Cloud Finchley / Spring Boot 2.0.xSpring Cloud [Finchley.RELEASE - Finchley.SR4] 版本受到影响。\nSpring Boot [2.0.0.RELEASE - 2.0.9.RELEASE] 版本受到影响。\nSpring Cloud Greenwich / Spring Boot 2.1.xSpring Cloud [Greenwich.RELEASE - Greenwich.SR6] 版本受到影响。\nSpring Boot [2.1.0.RELEASE - 2.1.14.RELEASE] 版本受到影响。\nSpring Boot [2.1.15.RELEASE] 版本已修复。\nSpring Cloud Hoxton / Spring Boot 2.2.xSpring Cloud [Hoxton.RELEASE - Hoxton.SR6] 版本受到影响。\nSpring Boot [2.2.0.RELEASE - 2.2.7.RELEASE] 版本受到影响。\nSpring Boot [2.2.8.RELEASE] 版本已修复。\nSpring Boot 2.3.xSpring Boot [2.3.0.RELEASE] 版本受到影响。\nSpring Boot [2.3.1.RELEASE] 版本已修复。\n解决方案为了解决上述漏洞，我和我们团队的小伙伴摸索出两种升级方案：\n\n直接升级Spring Boot版本。\n手动升级Tomcat版本。\n\n升级 Spring Cloud Edgware / Spring Boot 1.5.x\nEdgware无法通过升级Spring Boot版本解决问题。\n\n&lt;properties&gt;    &lt;tomcat.version&gt;8.5.56&lt;/tomcat.version&gt;&lt;/properties&gt;\n升级SpringCloud Finchley / SpringBoot 2.0.x\nFinchley无法通过升级Spring Boot版本解决问题。\n\n&lt;properties&gt;    &lt;tomcat.version&gt;8.5.56&lt;/tomcat.version&gt;&lt;/properties&gt;\n升级SpringCloud Greenwich / SpringBoot 2.1.x\n升级Spring Boot\n\n&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.1.15.RELEASE&lt;/version&gt;&lt;/parent&gt;\n\n升级Tomcat\n\n&lt;properties&gt;    &lt;tomcat.version&gt;9.0.37&lt;/tomcat.version&gt;&lt;/properties&gt;\n升级Spring Cloud Hoxton / Spring Boot 2.2.x\n升级SpringBoot\n\n&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.2.8.RELEASE&lt;/version&gt;&lt;/parent&gt;\n\n升级Tomcat\n\n&lt;properties&gt;    &lt;tomcat.version&gt;9.0.37&lt;/tomcat.version&gt;&lt;/properties&gt;\n升级Spring Boot 2.3.x\n升级SpringBoot\n\n&lt;parent&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;    &lt;version&gt;2.3.1.RELEASE&lt;/version&gt;&lt;/parent&gt;\n\n升级Tomcat\n\n&lt;properties&gt;    &lt;tomcat.version&gt;9.0.37&lt;/tomcat.version&gt;&lt;/properties&gt;\n后记我们有个现有的服务SpringBoot的版本是2.1.10.RELEAS,SpringCloud的版本是Greenwich.SR3,还集成了很多其他微服务组件，我们考虑到升级SpringBoot版本带来的兼容风险，我们采取了直接升级Tomcat版本的方式，建议由同样担忧的小伙伴也可以采取类似方案。\n","categories":["Tomcat","SpringBoot","SpringCloud"],"tags":["SpringBoot","Tomcat","SpringCloud","安全漏洞"]},{"title":"Kafka开启JMX监控操作实践","url":"http://leechaoqiang.github.io/2020/06/04/kafka-jmx-monitor-open/","content":"前段时间，我们团队使用的kafka集群压力比较大，需要接入监控，而运维给搭建kafka集群的时候没有开启JMX监控,于是我调用了3种开启方式，并本地进行了开启验证，方便后续接入kafka eagle监控平台。\n一、开启JMX的方式方式1：修改bin/kafka-run-class.sh脚本,在开始运行的最上方加入JMX_PORT=9999(可以自行指定一个没有占用的端口)。# Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.#open jmx monitorJMX_PORT=9999if [ $# -lt 1 ];\n方式2：修改bin/kafka-server-start.sh脚本，在开始运行的最上方加入如下代码:if [ &quot;x$JMX_PORT&quot; = &quot;x&quot;]; then    export JMX_PORT=&quot;9999&quot;fi\n方式3：在运行启动命令前 加上系统预留的JMX_PORT.JMX_PORT=9999 bin/kafka-server-start.sh -daemon config/server.properties\n我们采用了方式2，先用命令停止服务。修改启动脚本后，重新启动kafka服务，然后进行验证。\n二、验证JMX是否开启的方式Kafka的每个监控指标都是以JMX MBEAN的形式定义的，MBEAN是一个被管理的资源实例。我们可以使用Jconsole （Java Monitoring and Management Console），一种基于JMX的可视化监视、管理工具。\n方式1：通过jmx的9999端口访问观察MBean及metric数据\n1.1 启动jconsole。\n1.2 在远程连接输入service:jmx:rmi:///jndi/rmi://127.0.0.1:9999/jmxrmi 或者 127.0.0.1:9999（127.0.0.1 可以换成kafka服务器所在的ip),然后点击连接，可以查看Kafka的各种监控指标，都是以 kafka.xxx:type=xxx,xxx=xxx 打头MBean。方式2：使用Kafka默认提供的一个工具JmxTool，用于实时查看JMX监控指标。\n2.1 打开终端进入到Kafka安装目录下，输入命令bin/kafka-run-class.sh kafka.tools.JmxTool便可以得到JmxTool工具的帮助信息。比如我们要监控入站速率，可以输入以下命令，BytesInPerSec的值每5秒会打印在控制台上。bin/kafka-run-class.sh kafka.tools.JmxTool --object-name kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec --jmx-url service:jmx:rmi:///jndi/rmi://ip:9999/jmxrmi --date-format &quot;YYYY-MM-dd HH:mm:ss&quot; --attributes FifteenMinuteRate --reporting-interval 5000\n\n\n","categories":["缓存","博客","消息队列","kafka"],"tags":["Java","kafka","消息队列","MQ","jmx","监控"]},{"title":"Zookeeper从入门到精通（一）","url":"http://leechaoqiang.github.io/2020/04/17/zookeeper-from-start-to-deep-known-one/","content":"Zookeeper 概念Zookeeper是一个分布式协调服务，可用于服务发现，分布式锁，分布式领导选举，配置管理等。Zookeeper 提供了一个类似于 Linux 文件系统的树形结构（可认为是轻量级的内存文件系统，但只适合存少量信息，完全不适合存储大量文件或者大文件），同时提供了对于每个节点的监控与通知机制。\nZookeeper 角色Zookeeper 集群是一个基于主从复制的高可用集群，每个服务器承担如下三种角色中的一种.\nLeader\n一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader，它会发起并维护与各 Follwer及 Observer 间的心跳。\n所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。只要有超过半数节点（不包括 observeer 节点）写入成功，该写请求就会被提交（类 2PC 协议）。 Follower\n一个 Zookeeper 集群可能同时存在多个 Follower，它会响应 Leader 的心跳，\nFollower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，\n并且负责在 Leader 处理写请求时对请求进行投票。Observer角色与 Follower 类似，但是无投票权。Zookeeper 需保证高可用和强一致性，为了支持更多的客\n户端，需要增加更多 Server；Server 增多，投票阶段延迟增大，影响性能；引入 Observer，Observer 不参与投票； Observers 接受客户端的连接，并将写请求转发给 leader 节点； 加入更多 Observer 节点，提高伸缩性，同时不影响吞吐率。\n\n\nZAB 协议事务编号 Zxid（事务请求计数器+ epoch）在 ZAB ( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议） 协议的事务编号 Zxid设计中，Zxid 是一个 64 位的数字，其中低 32 位是一个简单的单调递增的计数器，针对客户端每一个事务请求，计数器加 1；而高 32 位则代表 Leader 周期 epoch 的编号，每个当选产生一个新的 Leader 服务器，就会从这个 Leader 服务器上取出其本地日志中最大事务的 ZXID，并从中读取epoch 值，然后加 1，以此作为新的 epoch，并将低 32 位从 0 开始计数。Zxid（Transaction id）类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal（提议）ID。为了保证顺序性，该 zkid 必须单调递增。\nepochepoch：可以理解为当前集群所处的年代或者周期，每个 leader 就像皇帝，都有自己的年号，所以每次改朝换代，leader 变更之后，都会在前一个年代的基础上加 1。这样就算旧的 leader 崩溃恢复之后，也没有人听他的了，因为 follower 只听从当前年代的 leader 的命令。\nZab 协议有两种模式-恢复模式（选主）、广播模式（同步）Zab 协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab 就进入了恢复模式，当领导者被选举出来，且大多数 Server 完成了和 leader 的状态同步以后，恢复模式就结束了。状态同步保证了 leader 和 Server 具有相同的系统状态。\nZAB 协议 4 阶段\n  Leader election（选举阶段-选出准 Leader）\nLeader election（选举阶段）：节点在一开始都处于选举阶段，只要有一个节点得到超半数节点的票数，它就可以当选准 leader。只有到达 广播阶段（broadcast） 准 leader 才会成为真正的 leader。这一阶段的目的是就是为了选出一个准 leader，然后进入下一个阶段。\n\n Discovery（发现阶段-接受提议、生成 epoch、接受 epoch）\n\n\nDiscovery（发现阶段）：在这个阶段，followers 跟准 leader 进行通信，同步 followers最近接收的事务提议。这个一阶段的主要目的是发现当前大多数节点接收的最新提议，并且准 leader 生成新的 epoch，让 followers 接受，更新它们的 accepted Epoch。一个 follower 只会连接一个 leader，如果有一个节点 f 认为另一个 follower p 是 leader，f在尝试连接 p 时会被拒绝，f 被拒绝之后，就会进入重新选举阶段。\n\n Synchronization（同步阶段-同步 follower 副本）\n\nSynchronization（同步阶段）：同步阶段主要是利用 leader 前一阶段获得的最新提议历史，同步集群中所有的副本。只有当 大多数节点都同步完成，准 leader 才会成为真正的 leader。follower 只会接收 zxid 比自己的 lastZxid 大的提议。\n\n Broadcast（广播阶段-leader 消息广播）\n\nBroadcast（广播阶段）：到了这个阶段，Zookeeper 集群才能正式对外提供事务服务，并且 leader 可以进行消息广播。同时如果有新的节点加入，还需要对新节点进行同步。ZAB 提交事务并不像 2PC 一样需要全部 follower 都 ACK，只需要得到超过半数的节点的 ACK 就可以了。\n\n ZAB 协议 JAVA 实现（FLE-发现阶段和同步合并为 Recovery Phase（恢复阶段）\n\n协议的 Java 版本实现跟上面的定义有些不同，选举阶段使用的是 Fast Leader Election（FLE），它包含了 选举的发现职责。因为 FLE 会选举拥有最新提议历史的节点作为 leader，这样就省去了发现最新提议的步骤。实际的实现将 发现阶段 和 同步合并为 Recovery Phase（恢复阶段）。所以，ZAB 的实现只有三个阶段：Fast Leader Election；Recovery Phase；Broadcast Phase。\n投票机制每个 sever 首先给自己投票，然后用自己的选票和其他 sever 选票对比，权重大的胜出，使用权重较大的更新自身选票箱。具体选举过程如下：\n\n每个 Server 启动以后都询问其它的 Server 它要投票给谁。对于其他 server 的询问，server 每次根据自己的状态都回复自己推荐的 leader 的 id 和上一次处理事务的 zxid（系统启动时每个 server 都会推荐自己）\n\n收到所有 Server 回复以后，就计算出 zxid 最大的哪个 Server，并将这个 Server 相关信息设置成下一次要投票的 Server。\n\n\n\n计算这过程中获得票数最多的的 sever 为获胜者，如果获胜者的票数超过半数，则改server 被选为 leader。否则，继续这个过程，直到 leader 被选举出来\n\nleader 就会开始等待 server 连接\n\nFollower 连接 leader，将最大的 zxid 发送给 leader\n\nLeader 根据 follower 的 zxid 确定同步点，至此选举阶段完成。\n\n选举阶段完成 Leader 同步后通知 follower 已经成为 uptodate 状态\n\nFollower 收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了\n\n\n投票过程举例：目前有 5 台服务器，每台服务器均没有数据，它们的编号分别是 1,2,3,4,5,按编号依次启动，它们的选择举过程如下。\n\n服务器 1 启动，给自己投票，然后发投票信息，由于其它机器还没有启动所以它收不到反馈信息，服务器 1 的状态一直属于 Looking。\n\n服务器 2 启动，给自己投票，同时与之前启动的服务器 1 交换结果，由于服务器 2 的编号大所以服务器 2 胜出，但此时投票数没有大于半数，所以两个服务器的状态依然是LOOKING。\n\n服务器 3 启动，给自己投票，同时与之前启动的服务器 1,2 交换信息，由于服务器 3 的编号最大所以服务器 3 胜出，此时投票数正好大于半数，所以服务器 3 成为领导者，服务器1,2 成为小弟。\n\n服务器 4 启动，给自己投票，同时与之前启动的服务器 1,2,3 交换信息，尽管服务器 4 的编号大，但之前服务器 3 已经胜出，所以服务器 4 只能成为小弟。\n\n服务器 5 启动，后面的逻辑同服务器 4 成为小弟。\n\n\n小结本篇幅，我们一起熟悉了zookeeper的基本概念，以及它的一些基本角色，以及ZAB协议和投票机制，后续我们再来讨论一下Zookeeper相关的工作原理和Znode。\n","categories":["Zookeeper"],"tags":["分布式","Zookeeper","微服务"]},{"title":"Mysql好的使用规范","url":"http://leechaoqiang.github.io/2019/11/28/mysql-good-using-rule/","content":"(一)建表规约1.【强制】表达是与否概念的字段，必须使用 is_xxx的方式命名，数据类型是 unsigned tinyint（ 1表示是，0表示否），此规则同样适用于 odps建表。说明：任何字段如果为非负数，必须是 unsigned。个人备注：Open Data Processing Service， 简称ODPS；是由阿里云自主研发，提供针对TB/PB级数据、实时性要求不高的分布式处理能力，应用于数据分析、挖掘、商业智能等领域；阿里巴巴的离线数据业务都运行在ODPS上；。2.【强制】表名、字段名必须使用小写字母或数字；禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑。正例：getter_admin，task_config，level3_name反例：GetterAdmin，taskConfig，level_3name3.【强制】表名不使用复数名词。说明：表名应该仅仅表示表里面的实体内容，不应该表示实体数量，对应于 DO类名也是单数形式，符合表达习惯。4.【强制】禁用保留字，如 desc、range、match、delayed等，请参考 MySQL官方保留字。5.【强制】唯一索引名为 uk字段名；普通索引名则为 idx字段名。说明：uk 即 unique key；idx_ 即 index的简称。6.【强制】小数类型为 decimal，禁止使用 float和 double。说明：float和 double在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal的范围，建议将数据拆成整数和小数分开存储。7.【强制】如果存储的字符串长度几乎相等，使用 char定长字符串类型。8.【强制】varchar是可变长字符串，不预先分配存储空间，长度不要超过 5000，如果存储长度大于此值，定义字段类型为 text，独立出来一张表，用主键来对应，避免影响其它字段索引效率。9.【强制】表必备三字段：id, gmt_create, gmt_modified。说明：其中 id必为主键，类型为 unsigned bigint、单表时自增、步长为 1。gmt_create,gmt_modified的类型均为 datetime类型。10.【推荐】表的命名最好是加上“业务名称表的作用”。正例：tiger_task / tiger_reader / mpp_config11.【推荐】库名与应用名称尽量一致。12.【推荐】如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释。13.【推荐】字段允许适当冗余，以提高性能，但是必须考虑数据同步的情况。冗余字段应遵循：1）不是频繁修改的字段。2）不是 varchar超长字段，更不能是 text字段。正例：商品类目名称使用频率高，字段长度短，名称基本一成不变，可在相关联的表中冗余存储类目名称，避免关联查询。14.【推荐】单表行数超过 500万行或者单表容量超过 2GB，才推荐进行分库分表。说明：如果预计三年后的数据量根本达不到这个级别，请不要在创建表时就分库分表。15.【参考】合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度。正例：人的年龄用 unsigned tinyint（表示范围 0-255，人的寿命不会超过 255岁）；海龟就必须是 smallint，但如果是太阳的年龄，就必须是 int；如果是所有恒星的年龄都加起来，那么就必须使用 bigint。\n(二)索引规约1.【强制】业务上具有唯一特性的字段，即使是组合字段，也必须建成唯一索引。说明：不要以为唯一索引影响了 insert速度，这个速度损耗可以忽略，但提高查找速度是明显的；另外，即使在应用层做了非常完善的校验和控制，只要没有唯一索引，根据墨菲定律，必然有脏数据产生。2.【强制】 超过三个表禁止 join。需要 join的字段，数据类型保持绝对一致；多表关联查询时，保证被关联的字段需要有索引。说明：即使双表 join也要注意表索引、SQL性能。3.【强制】在 varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度。说明：索引的长度与区分度是一对矛盾体，一般对字符串类型数据，长度为 20的索引，区分度会高达 90%以上，可以使用 count(distinct left(列名, 索引长度))/count(*)的区分度来确定。4.【强制】页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决。说明：索引文件具有 B-Tree的最左前缀匹配特性，如果左边的值未确定，那么无法使用此索引。5.【推荐】如果有 order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现 file_sort的情况，影响查询性能。正例：where a=? and b=? order by c; 索引：a_b_c反例：索引中有范围查找，那么索引有序性无法利用，如：WHERE a&gt;10 ORDER BY b; 索引a_b无法排序。6.【推荐】利用覆盖索引来进行查询操作，来避免回表操作。说明：如果一本书需要知道第 11章是什么标题，会翻开第 11章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索引的作用。正例：能够建立索引的种类：主键索引、唯一索引、普通索引，而覆盖索引是一种查询的一种效果，用 explain的结果，extra列会出现：using index。7.【推荐】利用延迟关联或者子查询优化超多分页场景。说明：MySQL并不是跳过 offset行，而是取 offset+N行，然后返回放弃前offset行，返回N行，那当 offset特别大的时候，效率就非常的低下，要么控制返回的总页数，要么对超过特定阈值的页数进行 SQL改写。正例：先快速定位需要获取的 id段，然后再关联：\nSELECT    a.*FROM    表1 a,    (        SELECT            id        FROM            表1        WHERE            条件        LIMIT 100000,        20    ) bWHERE    a.id = b.id\n8.【推荐】SQL性能优化的目标：至少要达到 range 级别，要求是 ref级别，如果可以是 consts最好。说明：1）consts 单表中最多只有一个匹配行（主键或者唯一索引），在优化阶段即可读取到数据。2）ref 指的是使用普通的索引（normal index）。3）range 对索引进行范围检索。反例：explain表的结果，type=index，索引物理文件全扫描，速度非常慢，这个 index级别比较 range还低，与全表扫描是小巫见大巫。9.【推荐】建组合索引的时候，区分度最高的在最左边。正例：如果 where a=? and b=? ，a列的几乎接近于唯一值，那么只需要单建 idx_a索引即可。说明：存在非等号和等号混合判断条件时，在建索引时，请把等号条件的列前置。如：where a&gt;?and b=? 那么即使 a的区分度更高，也必须把 b放在索引的最前列。10.【参考】创建索引时避免有如下极端误解：1）误认为一个查询就需要建一个索引。2）误认为索引会消耗空间、严重拖慢更新和新增速度。3）误认为唯一索引一律需要在应用层通过“先查后插”方式解决。\n(三)SQL规约1.【强制】不要使用 count(列名)或 count(常量)来替代 count()，count()就是 SQL92定义的标准统计行数的语法，跟数据库无关，跟 NULL和非 NULL无关。说明：count(*)会统计值为 NULL的行，而 count(列名)不会统计此列为 NULL值的行。2.【强制】count(distinct col) 计算该列除 NULL之外的不重复数量。注意 count(distinct col1, col2) 如果其中一列全为 NULL，那么即使另一列有不同的值，也返回为 0。3.【强制】当某一列的值全是 NULL时，count(col)的返回结果为 0，但 sum(col)的返回结果为NULL，因此使用 sum()时需注意 NPE问题。正例：可以使用如下方式来避免 sum的 NPE问题：\nSELECTIF (ISNULL(SUM(g)), 0, SUM(g))FROM    TABLE;\n4.【强制】使用 ISNULL()来判断是否为 NULL值。注意：NULL与任何值的直接比较都为 NULL。说明：1） NULL&lt;&gt;NULL的返回结果是 NULL，而不是 false。2） NULL=NULL的返回结果是 NULL，而不是 true。3） NULL&lt;&gt;1的返回结果是 NULL，而不是 true。5.【强制】 在代码中写分页查询逻辑时，若 count为 0应直接返回，避免执行后面的分页语句。6.【强制】不得使用外键与级联，一切外键概念必须在应用层解决。说明：（概念解释）学生表中的 student_id是主键，那么成绩表中的 student_id则为外键。如果更新学生表中的 student_id，同时触发成绩表中的 student_id更新，则为级联更新。外键与级联更新适用于单机低并发，不适合分布式、高并发集群；级联更新是强阻塞，存在数据库更新风暴的风险；外键影响数据库的插入速度。7.【强制】禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。8.【强制】数据订正时，删除和修改记录时，要先 select，避免出现误删除，确认无误才能执行更新语句。9.【推荐】in操作能避免则避免，若实在避免不了，需要仔细评估 in后边的集合元素数量，控制在 1000个之内。10.【参考】如果有全球化需要，所有的字符存储与表示，均以 utf-8编码，那么字符计数方法注意：说明：SELECT LENGTH(“轻松工作”)； 返回为 12SELECT CHARACTER_LENGTH(“轻松工作”)； 返回为 4如果要使用表情，那么使用 utfmb4来进行存储，注意它与 utf-8编码的区别。11.【参考】TRUNCATETABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但 TRUNCATE无事务且不触发 trigger，有可能造成事故，故不建议在开发代码中使用此语句。说明：TRUNCATE TABLE 在功能上与不带 WHERE 子句的 DELETE 语句相同。\n(四)ORM规约1.【强制】在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明。说明：1）增加查询分析器解析成本。2）增减字段容易与 resultMap配置不一致。2.【强制】POJO类的 boolean属性不能加 is，而数据库字段必须加 is_，要求在 resultMap中进行字段与属性之间的映射。说明：参见定义 POJO类以及数据库字段定义规定，在 sql.xml增加映射，是必须的。3.【强制】不要用 resultClass当返回参数，即使所有类属性名与数据库字段一一对应，也需要定义；反过来，每一个表也必然有一个与之对应。说明：配置映射关系，使字段与 DO类解耦，方便维护。4.【强制】xml配置中参数注意使用：#{}，#param# 不要使用${} 此种方式容易出现 SQL注入。5.【强制】iBATIS自带的 queryForList(String statementName,int start,int size)不推荐使用。说明：其实现方式是在数据库取到statementName对应的SQL语句的所有记录，再通过subList取 start,size的子集合，线上因为这个原因曾经出现过 OOM。正例：在 sqlmap.xml中引入 #start#, #size#\nMap&lt;String, Object&gt; map = new HashMap&lt;String, Object&gt;();map.put(&quot;start&quot;, start);map.put(&quot;size&quot;, size);\n6.【强制】不允许直接拿 HashMap与 Hashtable作为查询结果集的输出。7.【强制】更新数据表记录时，必须同时更新记录对应的 gmt_modified字段值为当前时间。8.【推荐】不要写一个大而全的数据更新接口，传入为 POJO类，不管是不是自己的目标更新字段，都进行\nUPDATE TABLESET  c1 = value1, c2 = value2, c3 = value3;\n这是不对的。执行 SQL时，尽量不要更新无改动的字段，一是易出错；二是效率低；三是 binlog增加存储。9.【参考】@Transactional事务不要滥用。事务会影响数据库的 QPS，另外使用事务的地方需要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。10.【参考】&lt; isEqual&gt;中的compareValue是与属性值对比的常量，一般是数字，表示相等时带上此条件；&lt; isNotEmpty&gt;表示不为空且不为 null时执行；&lt; isNotNull&gt;表示不为 null值时执行。\n","categories":["博客","Mysql"],"tags":["Mysql","数据库"]},{"title":"Kafka简析以及SpringBoot整合Kafka应用实践","url":"http://leechaoqiang.github.io/2019/09/04/springcloud-app-kafka/","content":"一、Kafka介绍\nKafka创建背景Kafka 是一个消息系统，原本开发自 LinkedIn，用作 LinkedIn 的活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。现在它已被多家不同类型的公司 作为多种类型的数据管道和消息系统使用。\n活动流数据是几乎所有站点在对其网站使用情况做报表时都要用到的数据中最常规的部分。活动数据包括页面访问量（Page View）、被查看内容方面的信息以及搜索情况等内容。这种数据通常的处理方式是先把各种活动以日志的形式写入某种文件，然后周期性地对这些文件进行统计分析。运营数据指的是服务器的性能数据（CPU、IO 使用率、请求时间、服务日志等等数据)。运营数据的统计方法种类繁多。近年来，活动和运营数据处理已经成为了网站软件产品特性中一个至关重要的组成部分，这就需要一套稍微更加复杂的基础设施对其提供支持。\nKafka简介Kafka是一种分布式的，基于发布/订阅的消息系统。 \n主要设计目标如下：\n\n以时间复杂度为 O(1)的方式提供消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。\n高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒 100K 条以上消息的传输。\n支持 Kafka Server 间的消息分区，及分布式消费，同时保证每个 Partition 内的消息顺序传输。\n同时支持离线数据处理和实时数据处理。\nScale out：支持在线水平扩展。\n\nKafka基础概念专业名称解释\nBroker一台kafka服务器就是一个broker。一个集群由多个broker组成。一个broker可以容纳多个topic。\nProducer消息生产者，就是向kafka broker发消息的客户端。\nConsumer消息消费者，向kafka broker取消息的客户端。\nTopic每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）\nConsumer Group每个Consumer属于一个特定的Consumer Group，可为每个Consumer指定group name，若不指定group name则属于默认的分组。\nPartition一个庞大大的topic可以分布到多个broker上，一个topic可以分为多个partition，每个partition是一个有序的队列。partition中的每条消息都会被分配一个有序的id。kafka只保证按一个partition中的顺序将消息发给consumer，不保证一个topic的整体的顺序。Partition是物理上的概念，方便在集群中扩展，提高并发。\n\n消息功能\n点对点模式\n\n点对点模型通常是一个基于拉取或者轮询的消息传递模型，消费者主动拉取数据，消息收到后从队列移除消息，这种模型不是将消息推送到客户端，而是从队列中请求消息。特点是发送到队列的消息被一个且只有一个消费者接收处理，即使有多个消费者监听队列也是如此。\n\n发布订阅模式\n\n发布订阅模型则是一个基于推送的消息传送模型，消息产生后，推送给所有订阅者。发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息，即使当前订阅者不可用，处于离线状态。\nKafka如何保证可靠性当我们讨论可靠性的时候，我们总会提到保证*这个词语。可靠性保证是基础，我们基于这些基础之上构建我们的应用。比如关系型数据库的可靠性保证是ACID，也就是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）和持久性（Durability）。\nKafka 中的可靠性保证有如下四点：\n\n对于一个分区来说，它的消息是有序的。如果一个生产者向一个分区先写入消息A，然后写入消息B，那么消费者会先读取消息A再读取消息B。\n当消息写入所有in-sync状态的副本后，消息才会认为已提交（committed）。这里的写入有可能只是写入到文件系统的缓存，不一定刷新到磁盘。生产者可以等待不同时机的确认，比如等待分区主副本写入即返回，后者等待所有in-sync状态副本写入才返回。\n一旦消息已提交，那么只要有一个副本存活，数据不会丢失。\n消费者只能读取到已提交的消息。\n\n使用这些基础保证，我们构建一个可靠的系统，这时候需要考虑一个问题：究竟我们的应用需要多大程度的可靠性？可靠性不是无偿的，它与系统可用性、吞吐量、延迟和硬件价格息息相关，得此失彼。因此，我们往往需要做权衡，一味的追求可靠性并不实际。\nQuick Start下载安装Kafka,解压安装包\n从官网下载Kafka的安装包。#1.1 浏览器打开链接 https://www.apache.org/dyn/closer.cgi?path=/kafka/2.6.0/kafka_2.13-2.6.0.tgz#1.2 命令下载 wget https://mirrors.tuna.tsinghua.edu.cn/apache/kafka/2.6.0/kafka_2.13-2.6.0.tgz  tar -xzf kafka_2.13-2.6.0.tgz cd kafka_2.13-2.6.0\n修改配置,启动服务\n\n\n2.1 修改配置\nvim config/server.properties\n把参数修改成如下图：\n\n2.2 启动服务\n# Start the ZooKeeper service# Note: Soon, ZooKeeper will no longer be required by Apache Kafka.$ bin/zookeeper-server-start.sh -daemon config/zookeeper.properties# Start the Kafka broker service$ bin/kafka-server-start.sh -daemon config/server.properties\n\n\n生产消息\nMaven依赖配置&lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;     &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;     &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--spring-kafka--&gt; &lt;dependency&gt;     &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;     &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;     &lt;artifactId&gt;gson&lt;/artifactId&gt; &lt;/dependency&gt;\n生产消息application.properties配置spring.application.name=springboot-kafka-app-providerserver.port=8081# ============== kafka ==================# 指定kafka 代理地址，可以多个spring.kafka.bootstrap-servers=127.0.0.1:9092# =============== provider  =======================spring.kafka.producer.retries=0# 每次批量发送消息的数量spring.kafka.producer.batch-size=16384spring.kafka.producer.buffer-memory=33554432# 指定消息key和消息体的编解码方式spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializerspring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer\n具体生产消息核心代码KafkaProducer/** * kafka消息生产 */@Component@Slf4jpublic class KafkaProducer &#123;    @Resource    private KafkaTemplate&lt;String, String&gt; kafkaTemplate;    private Gson gson = new GsonBuilder().create();    AtomicLong atomicLong = new AtomicLong(0L);    public void send() &#123;        String msg = &quot;中国崛起:&quot;+atomicLong.incrementAndGet();        send(msg);    &#125;    public void send(final String msg) &#123;        Message message = new Message();        message.setId(System.currentTimeMillis());        message.setMsg(msg);        message.setSendTime(new Date());        log.info(&quot;+++++++++++++++++++++send  message = &#123;&#125;&quot;, gson.toJson(message));        kafkaTemplate.send(KafkaTopicConstant.testTopicName, message.getId().toString() , gson.toJson(message));    &#125;\n具体生产消息核心代码MessageController/** * 消息发送controller * @author vincent.li */@RestController@Slf4jpublic class MessageController &#123;    @Autowired    KafkaProducer kafkaProducer;    @GetMapping(value = &quot;/send&quot;)    public String send(String msg)&#123;        try &#123;            kafkaProducer.send(msg);        &#125; catch (Exception e) &#123;            log.error(e.getMessage(), e);            return &quot;failure&quot;;        &#125;        return &quot;success&quot;;    &#125;&#125;\n生产消息服务启动类SpringBootKafkaProducerApplication/*** kafka消息生产服务SpringBoot 启动类* @author vincent.li*/@SpringBootApplication(scanBasePackages = &#123;&quot;com.vincent.app.kafka.producer&quot;&#125;)public class SpringBootKafkaProducerApplication &#123;  public static void main(String[] args) &#123;      ConfigurableApplicationContext context = SpringApplication.run(SpringBootKafkaProducerApplication.class, args);      System.out.println(&quot;O(∩_∩)O哈哈~    【TEST-KAFKA-APP-PRODUCER】启动成功      O(∩_∩)O哈哈~&quot;);      KafkaProducer sender = context.getBean(KafkaProducer.class);      for (int i = 0; i &lt; 1000; i++) &#123;          sender.send();          try &#123;              Thread.sleep(2000);          &#125; catch (InterruptedException e) &#123;              e.printStackTrace();          &#125;      &#125;  &#125;&#125;\n消费消息\nMaven配置&lt;dependency&gt;          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;          &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;          &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;          &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;          &lt;scope&gt;test&lt;/scope&gt;      &lt;/dependency&gt;      &lt;!--spring-kafka--&gt;      &lt;dependency&gt;          &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;          &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;      &lt;/dependency&gt;      &lt;dependency&gt;          &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;          &lt;artifactId&gt;gson&lt;/artifactId&gt;      &lt;/dependency&gt;\n消费消息application.properties配置spring.application.name=springboot-kafka-app-consumerserver.port=8082# ============== kafka ==================# 指定kafka 代理地址，可以多个spring.kafka.bootstrap-servers=127.0.0.1:9092#=============== consumer  =======================# 指定默认消费者group idspring.kafka.consumer.group-id=test-demo-consumer-groupspring.kafka.consumer.auto-offset-reset=earliestspring.kafka.consumer.enable-auto-commit=truespring.kafka.consumer.auto-commit-interval=2000# 指定消息key和消息体的编解码方式spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializerspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer\n消费消息核心代码/*** kafka消息消费* @author vincent.li*/@Component@Slf4jpublic class KafkaConsumer &#123;  @KafkaListener(topics = &#123;KafkaConsumerTopicConstant.testTopicName&#125;)  public void listen(ConsumerRecord&lt;?, ?&gt; record) &#123;      Optional&lt;?&gt; kafkaMessage = Optional.ofNullable(record.value());      if (kafkaMessage.isPresent()) &#123;          Object message = kafkaMessage.get();          log.info(KafkaConsumerTopicConstant.testTopicName+&quot;----------------- record==&gt;&#123;&#125;&quot;, record);          log.info(KafkaConsumerTopicConstant.testTopicName+&quot;------------------ message==&gt;&#123;&#125;&quot; , message);      &#125;  &#125;&#125;\n消费消息启动服务类SpringBootKafkaConsumerApplication/** * kafka消息消费服务SpringBoot 启动类 * @author vincent.li */@SpringBootApplication(scanBasePackages = &#123;&quot;com.vincent.app.kafka.consumer&quot;&#125;)public class SpringBootKafkaConsumerApplication &#123;    public static void main(String[] args) &#123;        SpringApplication.run(SpringBootKafkaConsumerApplication.class, args);        System.out.println(&quot;O(∩_∩)O哈哈~    【TEST-KAFKA-APP-CONSUMER】启动成功      O(∩_∩)O哈哈~&quot;);    &#125;&#125;\n运行结果\n通过controller方法生产消息\n生产消息服务控制台打印日志\n消费消息服务控制台打印日志\n\n完整demo代码地址Github地址: https://github.com/leechaoqiang/springcloud-app-parentGitee地址：https://gitee.com/chaoqianglee/springcloud-app-parent\n参考资料\n\n官方文档\nKafka 设计解析（一）：Kafka 背景及架构介绍\nKafka技术内幕——图文详解Kafka源码设计与实现\n\n","categories":["博客","消息队列","kafka"],"tags":["Java","kafka","消息队列","MQ","zookeeper"]},{"title":"使用Folk/Join框架实现多核并行计算学习笔记","url":"http://leechaoqiang.github.io/2019/08/12/fork-join-pool-study-note/","content":"背景最近温习《Java虚拟机精讲》的时候，里面有提到使用Folk/Join框架实现多核并行计算，似乎有点陌生又有点熟悉，原来真的好久没用了，根据书上的相关资料，自Java7开始新增在java.util.concurrent包下面新增了基于细粒度的多核并行计算Folk/Join框架。它的主要思想就是讲一个大任务分割成若干小任务，最终汇总每个小任务的结果得到这个大任务的结果。这种思想和开源基金会Apache提供的Hadoop里面MapReduce很像（input –&gt; split –&gt; map –&gt; reduce –&gt; output）\n主要有两步：\n第一、任务切分（Folk）\n第二、结果合并 (Join)\n\n使用说明自JDK1.7开始，java.util.concurrent包下提供了ForkJoinPool来支持将一个任务拆分成多个“小任务”并行计算，再把多个“小任务”的结果合并成总的计算结果。多线程ForkJoinPool运用了Fork/Join原理，使用“分而治之”的思想，将大任务分拆成小任务分配给多个线程执行，最后合并得到最终结果，加快运算。它的模型大致是这样的：线程池中的每个线程都有自己的工作队列（这一点和ThreadPoolExecutor不同，ThreadPoolExecutor是所有线程共用一个工作队列。ForkJoinPool是ExecutorService的实现类，因此是一种特殊的线程池。\n使用方法：创建了ForkJoinPool实例之后，就可以调用ForkJoinPool的submit(ForkJoinTask task) 或invoke(ForkJoinTask task)方法来执行指定任务了。\n其中ForkJoinTask代表一个可以并行、合并的任务。ForkJoinTask是一个抽象类，它还有两个抽象子类：RecusiveAction和RecusiveTask。其中RecusiveTask代表有返回值的任务，而RecusiveAction代表没有返回值的任务。\n代码DEMO\nDemo 1.使用ForkJoinPool完成一个任务的分段执行\n简单的打印0-500的数值。用多线程实现并行执行实现\npackage com.vincent.demo.folkjoin;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.RecursiveAction;import java.util.concurrent.TimeUnit;/** * @Desc 使用ForkJoinPool完成一个任务的分段执行 * 简单的打印0-500的数值。用多线程实现并行执行 * @author   vincent.li * @version   1.0 * @since    JDK 1.7 * @see */public class ForkJoinPoolAction &#123;    public static void main(String[] args) throws Exception &#123;        PrintTask task = new PrintTask(0, 500);        //创建实例，并执行分割任务        ForkJoinPool forkJoinPool = new ForkJoinPool();        forkJoinPool.submit(task);        //线程阻塞，等待所有任务完成        forkJoinPool.awaitTermination(2, TimeUnit.SECONDS);        forkJoinPool.shutdown();    &#125;&#125;/** * @Desc: 继承RecursiveAction来实现“可分解”的任务。 * * @author vincent.li * @version 1.0 * @since JDK 1.7 */class PrintTask extends RecursiveAction &#123;    //最多只能打印50个数    private static final int THRESHOLD = 50;    private int start;    private int end;    public PrintTask(int start, int end) &#123;        super();        this.start = start;        this.end = end;    &#125;    @Override    protected void compute() &#123;        if(end - start &lt; THRESHOLD)&#123;            for(int i = start; i &lt; end; i++)&#123;                System.out.println(Thread.currentThread().getName()+&quot;打印i值&gt;&gt;&gt;&quot;+i);            &#125;        &#125;else &#123;            int middle = (start + end) / 2;            PrintTask left = new PrintTask(start, middle);            PrintTask right = new PrintTask(middle, end);            //并行执行两个“小任务”            left.fork();            right.fork();        &#125;    &#125;&#125;\n\n执行结果如下：··················ForkJoinPool-1-worker-6打印i值&gt;&gt;&gt;282ForkJoinPool-1-worker-2打印i值&gt;&gt;&gt;219ForkJoinPool-1-worker-3打印i值&gt;&gt;&gt;343ForkJoinPool-1-worker-4打印i值&gt;&gt;&gt;97ForkJoinPool-1-worker-0打印i值&gt;&gt;&gt;31ForkJoinPool-1-worker-4打印i值&gt;&gt;&gt;98ForkJoinPool-1-worker-3打印i值&gt;&gt;&gt;344ForkJoinPool-1-worker-2打印i值&gt;&gt;&gt;220ForkJoinPool-1-worker-6打印i值&gt;&gt;&gt;283ForkJoinPool-1-worker-7打印i值&gt;&gt;&gt;2ForkJoinPool-1-worker-5打印i值&gt;&gt;&gt;408··················\n\n\n\n我的Macbook是2.2 GHz Intel Core i7,是8核的，由线程名称可以知道，8个CPU都参与了执行，其实我们ForkJoinPool默认会开启和CPU核数一样的线程数。\n\n\nDemo 2.对一个长度为100000000的数组的元素进行累加求和package com.vincent.demo.folkjoin;import java.util.Random;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.Future;import java.util.concurrent.RecursiveTask;/** * @Desc 对一个长度为100000000的数组的元素进行累加求和 * @author   vincent.li * @version   1.0 * @since    JDK 1.7 * @see */public class ForJoinPollTask &#123;    public static void main(String[] args) throws Exception &#123;        long[] arr = new long[100000000];        Random random = new Random();        long total =0L;        int len = arr.length;        //初始化10000000个数组元素        for(int i=0; i&lt;len; i++)&#123;            int temp = random.nextInt(50);            arr[i]=Long.valueOf(temp).longValue() ;        &#125;        System.out.println(&quot;数组初始化完成。。。&quot;);        long start = System.currentTimeMillis();        for(int i=0; i&lt;len; i++)&#123;            //对数组元素赋值，并将数组元素的值添加到sum总和中            total += arr[i];        &#125;        long timeCost = System.currentTimeMillis() - start;        System.out.println(&quot;for循环累加求和结果：&quot; + total + &quot;,耗时：&quot; + timeCost + &quot; ms&quot;);        start = System.currentTimeMillis();        SumTask task = new SumTask(arr, 0, len);//        创建一个通用池，这个是jdk1.8提供的功能        ForkJoinPool pool = ForkJoinPool.commonPool();        Future&lt;Long&gt; future = pool.submit(task); //提交分解的SumTask 任务        timeCost = System.currentTimeMillis() - start;        System.out.println(&quot;多线程执行求和结果：&quot;+future.get()+ &quot;,耗时：&quot; + timeCost + &quot; ms&quot;);        pool.shutdown(); //关闭线程池    &#125;&#125;/** * @Desc: 继承抽象类RecursiveTask，通过返回的结果，来实现数组的多线程分段累累加 *  RecursiveTask 具有返回值 * * @author vincent.li * @version 1.0 * @since JDK 1.7 */class SumTask extends RecursiveTask&lt;Long&gt; &#123;    private static final int THRESHOLD = 50; //每个小任务 最多只累加50个数    private long arry[];    private int start;    private int end;    /**     * Creates a new instance of SumTask.     * 累加从start到end的arry数组     * @param arry     * @param start     * @param end     */    public SumTask(long[] arry, int start, int end) &#123;        super();        this.arry = arry;        this.start = start;        this.end = end;    &#125;    @Override    protected Long compute() &#123;        long sum = 0L;        //当end与start之间的差小于threshold时，开始进行实际的累加        if(end - start &lt; THRESHOLD)&#123;            for(int i = start; i &lt; end; i++)&#123;                sum += arry[i];            &#125;            return sum;        &#125; else &#123;            //当end与start之间的差大于threshold，即要累加的数超过50个时候，将大任务分解成小任务            int middle = (start+ end)/2;            SumTask left = new SumTask(arry, start, middle);            SumTask right = new SumTask(arry, middle, end);            //并行执行两个 小任务            left.fork();            right.fork();            //把两个小任务累加的结果合并起来            return left.join()+right.join();        &#125;    &#125;&#125;\n执行结果如下：数组初始化完成。。。for循环累加求和结果：2450102493,耗时：86 ms多线程执行求和结果：2450102493,耗时：3 ms\n我们这次是针对长度1亿的数组的所有元素求和，很明显看出多核并行计算执行效率缴传统for循环累加高了20多将近30倍，如果我们采用这个多核并行计算框架来处理海量数据，那效率必须杠杠的。\n\n分析自JDK1.7开始，Java中引入了可以多核并行计算一种新的线程池：ForkJoinPool。它同ThreadPoolExecutor一样，也实现了Executor和ExecutorService接口。它使用了一个无限队列来保存需要执行的任务，而线程的数量则是通过构造函数传入，如果没有向构造函数中传入希望的线程数量，那么当前计算机可用的CPU数量会被设置为线程数量作为默认值。ForkJoinPool主要用来使用 分治算法(Divide-and-Conquer Algorithm)来解决问题。典型的应用比如快速排序算法。\n他们区别在于，ForkJoinPool可以使用相对少的线程来处理大量的任务，对于有限资源可以充分使用。\n比如要对1000万个数据进行排序，那么会将这个任务分割成两个500万的排序任务和一个针对这两组500万数据的合并任务。以此类推，对于500万的数据也会做出同样的分割处理，到最后会设置一个阈值来规定当数据规模到多少时，停止这样的分割处理。比如，当元素的数量小于10时，会停止分割，转而使用插入排序对它们进行排序。\n那么到最后，所有的任务加起来会有大概2000000+个。问题的关键在于，对于一个任务而言，只有当它所有的子任务完成之后，它才能够被执行。\n所以当使用ThreadPoolExecutor时，使用分治法会存在问题，因为ThreadPoolExecutor中的线程无法像任务队列中再添加一个任务并且在等待该任务完成之后再继续执行。而使用ForkJoinPool时，就能够让其中的线程创建新的任务，并挂起当前的任务，此时线程就能够从队列中选择子任务执行。\n 以上程序的关键方法是fork()和join()方法。在ForkJoinPool使用的线程中，会使用一个内部队列来对需要执行的任务以及子任务进行操作来保证它们的执行顺序。\n那么使用ThreadPoolExecutor或者ForkJoinPool，会有什么性能的差异呢？\n首先，使用ForkJoinPool能够使用数量有限的线程来完成非常多的具有父子关系的任务，比如使用4个线程来完成超过200万个任务。但是，使用ThreadPoolExecutor时，是不可能完成的，因为ThreadPoolExecutor中的Thread无法选择优先执行子任务，需要完成200万个具有父子关系的任务时，也需要200万个线程，显然这是不可行的。\nNotice: ForkJoinPool在执行过程中，会创建大量的子任务，这会导致GC进行垃圾回收，这里可能带来一些系统卡顿的风险。\n","categories":["博客","Java"],"tags":["Java","多线程","ForkJoinPool"]},{"title":"RabbitMQ分析全解之快速开始实现一个demo","url":"http://leechaoqiang.github.io/2019/08/10/rabbitmq-quitstart-practise/","content":"RabbitMQ的安装、Web管理、命令行控制基础操作主要包括：安装服务器，查看Web管理页面，使用控制行操作相关内容。\n安装服务器安装ErlangRabbitMQ主要依赖Erlang，因此必须先安装erlang。\nerlang主要有三个方式来安装。具体内容参考： http://www.rabbitmq.com/install-rpm.html这里选择第二种进行安装。\n\n安装erlang-solution的配置信息wget http://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpm\n运行yum，安装erlang.rpm表sudo yum install erlang``` 3. 测试，运行 erl命令#### 安装RabbitMQ1. 我们这里选择手动下载rabbitmq安装包，当然也可以选择rpm和yum进行安装。\nwget https://www.rabbitmq.com/releases/rabbitmq-server/v3.6.15/rabbitmq-server-mac-standalone-3.6.15.tar.xz2. 启动服务和检查服务是否正常启动\n./sbin/rabbitmq-plugins enable rabbitmq_management\n\n./sbin/rabbitmq-server -detached  #这是后台服务运行\n./sbin/rabbitmqctl status  #监测服务状态3. 查看Web管理平台界面  浏览器打开http://localhost:15672/  用户名和密码 是 guest／guest4. 新增用户admin并设置状态administrator./sbin/rabbitmqctl add_user admin 123456\n./sbin/rabbitmqctl set_user_tags admin administrator\n[rabbitmq官方参考资料：https://www.rabbitmq.com/management.html#configuration](https://www.rabbitmq.com/management.html#configuration)### 采用广播模式Fanout实现一个发送接收消息的demo#### 生产消息* Maven依赖配置```xml     &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;           &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;           &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;           &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;           &lt;scope&gt;test&lt;/scope&gt;       &lt;/dependency&gt;      &lt;!-- rabbitmq 依赖 --&gt;       &lt;dependency&gt;           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;           &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;       &lt;/dependency&gt;       &lt;dependency&gt;           &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;           &lt;artifactId&gt;gson&lt;/artifactId&gt;       &lt;/dependency&gt;\n\n生产消息配置spring.application.name=springboot-rabbitmq-app-providerserver.port=8084#rabbitmq相关配置spring.rabbitmq.host = 127.0.0.1spring.rabbitmq.port = 5672spring.rabbitmq.username = adminspring.rabbitmq.password = 123456# 自定义配置应用于消息生产#交换器名称rabbitmq.config.exchange = mc.Ex.demo.test#自定义队列名称rabbitmq.producer.queue.name =mc.queue.demo.test\n生产消息Rabbitmq配置/** * @author vincent.li * @Description Rabbitmq配置 * @since 2019/8/10 */@Componentpublic class RabbitmqConfig &#123;    @Value(&quot;$&#123;rabbitmq.config.exchange&#125;&quot;)    private String fanoutExchangeName;    @Value(&quot;$&#123;rabbitmq.producer.queue.name&#125;&quot;)    private String producerQueueName;    @Bean    public FanoutExchange fanoutExchange() &#123;        return new FanoutExchange(fanoutExchangeName, true, false);    &#125;    @Bean(name = &quot;basicQueue&quot;)    public Queue basicQueue() &#123;        return new Queue(producerQueueName, true);    &#125;    @Bean    public Binding basicBinding() &#123;        return BindingBuilder.bind(basicQueue()).to(fanoutExchange());    &#125;&#125;\n生产消息方法/** * @author vincent.li * @Description Rabbitmq消息生产控制器 * @since 2019/8/9 */@Slf4j@RestController@RequestMapping(value = &quot;rabbitmq&quot;)public class RabbitmqProduceController &#123;    @Autowired    private RabbitTemplate rabbitTemplate;    @Value(&quot;$&#123;rabbitmq.config.exchange&#125;&quot;)    private String fanoutExchangeName;    /**     * 发送消息     * @param msg     * @return     */    @GetMapping(&quot;/message/send&quot;)    public BaseResponse sendMessage(@RequestParam String msg)&#123;        if (StringUtils.isEmpty(msg)) &#123;            return BaseResponse.fail(&quot;请输入有效参数&quot;);        &#125;        try &#123;            log.info(&quot;待发送的消息： &#123;&#125; &quot;, msg);            rabbitTemplate.setMessageConverter(new Jackson2JsonMessageConverter());            rabbitTemplate.setExchange(fanoutExchangeName);            Message message = Message.builder()                    .id(System.currentTimeMillis())                    .msg(msg)                    .sendTime(new Date())                    .build();            rabbitTemplate.convertAndSend(message);        &#125;catch (Exception e)&#123;            log.error(&quot;发送消息发生异常： &quot;, e.fillInStackTrace());            return BaseResponse.fail(&quot;发送消息发生异常&quot;);        &#125;        return BaseResponse.success();    &#125;&#125;\n\n\n接收消息\nMaven依赖配置\n&lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;      &lt;scope&gt;test&lt;/scope&gt;  &lt;/dependency&gt;  &lt;!-- rabbitmq 依赖 --&gt;  &lt;dependency&gt;      &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;      &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;      &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;      &lt;artifactId&gt;gson&lt;/artifactId&gt;  &lt;/dependency&gt;\n\n接收消息配置\nspring.application.name=springboot-rabbitmq-app-consumerserver.port=8083spring.rabbitmq.host = 127.0.0.1spring.rabbitmq.port = 5672spring.rabbitmq.username = adminspring.rabbitmq.password = 123456# 自定义配置应用于消息消费#交换器名称rabbitmq.config.exchange = mc.Ex.demo.test#自定义队列名称rabbitmq.consumer.queue.name =mc.queue.demo.test.consumerabbitmq.consumer.2.queue.name = mc.queue.demo.test.consume2\n\n接收消息consumer-1\n/** * @author vincent.li * @Description rabbitmq广播模式消费 * @since 2019/8/9 */@Component@RabbitListener(bindings = @QueueBinding(        value = @Queue(value = &quot;$&#123;rabbitmq.consumer.queue.name&#125;&quot;, durable = &quot;true&quot;, autoDelete = &quot;false&quot;),        exchange = @Exchange(value = &quot;$&#123;rabbitmq.config.exchange&#125;&quot;, type = ExchangeTypes.FANOUT)))public class RabbitmqFanoutConsumer &#123;    /**     * 设置监听方法     *     * @param message     * @RabbitHandler 声明监听方法是下面的 isDefault属性是默认false接受的完整对象，true接受body体     */    @RabbitHandler(isDefault = true)    public void process(byte[] message) &#123;        System.out.println(&quot;Fanout-1 Receiver : &quot; + new String(message));    &#125;&#125;\n接收消息consumer-2/** * @author vincent.li * @Description rabbitmq广播模式消费 * @since 2019/8/9 */@Component@RabbitListener(bindings = @QueueBinding(        value = @Queue(value = &quot;$&#123;rabbitmq.consumer.2.queue.name&#125;&quot;, durable = &quot;true&quot;, autoDelete = &quot;false&quot;),        exchange = @Exchange(value = &quot;$&#123;rabbitmq.config.exchange&#125;&quot;, type = ExchangeTypes.FANOUT)))public class RabbitmqFanoutConsumer2 &#123;    /**     * 设置监听方法     *     * @param message     * @RabbitHandler 声明监听方法是下面的 isDefault属性是默认false接受的完整对象，true接受body体     */    @RabbitHandler(isDefault = true)    public void process(byte[] message) &#123;        System.out.println(&quot;Fanout-2 Receiver : &quot; + new String(message));    &#125;&#125;\n\n\n运行结果\n发送消息：\n\n\n\n\n接受消息：\n\n\n具体完整代码可以移步github:springcloud-app-rabbitmq\n","categories":["RabbitMQ","博客","消息队列"],"tags":["Java","消息队列","MQ","RabbitMQ"]},{"title":"RabbitMQ分析全解之RabbitMQ介绍","url":"http://leechaoqiang.github.io/2019/08/01/rabbitmq-complete-analysis/","content":"RabbitMQ介绍什么是RabbitMQ？RabbitMQ是一套开源（MPL）的消息队列服务软件，是由 LShift 提供的一个 Advanced Message Queuing Protocol (AMQP，高级消息队列协议) 的开源实现，由以高性能、健壮以及可伸缩性出名的 Erlang 写成。最初起源于金融系统，用于在分布式系统中存储转发消息，在易用性、扩展性、高可用性等方面表现不俗。\nRabbitMQ主要是为了实现系统之间的双向解耦而实现的。当生产者大量产生数据时，消费者无法快速消费，那么需要一个中间层。保存这个数据。例如一个日志系统，很容易使用RabbitMQ简化工作量，一个Consumer可以进行消息的正常处理，另一个Consumer负责对消息进行日志记录，只要在程序中指定两个Consumer所监听的queue以相同的方式绑定到同一exchange即可，剩下的消息分发工作由RabbitMQ完成。\n单向解耦“Producer”--           |           |-----&gt;&quot;RabbitMQ Clusters&quot; ---&gt; “Consumer”&quot;Producer&quot;--\n双向解耦（如：RPC）“Producer1”--&gt;           |           |&lt;-----&gt;&quot;RabbitMQ Clusters&quot; &lt;---&gt; “Consumer2&amp;Producer2”&quot;Consumer1&quot;&lt;--\nRabbitMQ的使用基础使用RabbitMQ server需要： \n\nErLang语言包； \nRabbitMQ安装包；\n\n基础概念交换机（exchange）：\n接收消息，转发消息到绑定的队列。四种类型：direct, topic, headers and fanout\n\n\ndirect：转发消息到routigKey指定的队列\ntopic：按规则转发消息（最灵活）\nheaders：（这个还没有接触到）\nfanout：转发消息到所有绑定队列（广播模式）\n\n\n如果交换机上(Exchange）和（Queue）是多对多的关系。\n\ntopic类型交换器通过模式匹配分析消息的routing-key属性。它将routing-key和binding-key的字符串切分成单词。这些单词之间用点隔开。\n支持表达式：   *.foo.bar  # 只要包含foo.bar就可以匹配相关信息。这个是topic，性能最慢   demo   # 这个是direct,性能最好。\n\n因为交换器是在RabbitMQ是一个实际存在的实体，不能被改变。只能删除之后，重新创建。\n\n交换器的属性：\n\n\n\n持久性：如果启用，交换器将会在server重启前都有效。（对应Duration属性，持久化）\n自动删除：如果启用，那么交换器将会在其绑定的队列都被删除掉之后自动删除掉自身。（创建时候设置，如果不设置不会自动删除）。\n惰性：如果没有声明交换器，那么在执行到使用的时候会导致异常，并不会主动声明。（不会自动创建）队列（queue）：\n\n\n队列是RabbitMQ内部对象，存储消息。相同属性的queue可以重复定义。\n\n临时队列。channel.queueDeclare()，有时不需要指定队列的名字，并希望断开连接时删除队列。\n\n\n队列的属性：\n\n持久性：如果启用，队列将会在server重启前都有效。\n自动删除：如果启用，那么队列将会在所有的消费者停止使用之后自动删除掉自身。\n惰性：如果没有声明队列，那么在执行到使用的时候会导致异常，并不会主动声明。\n排他性：如果启用，队列只能被声明它的消费者使用。\n消息传递：\n\n消息在队列中保存，以轮询的方式将消息发送给监听消息队列的消费者，可以动态的增加消费者以提高消息的处理能力。为了实现负载均衡，可以在消费者端通知RabbitMQ，一个消息处理完之后才会接受下一个消息。 channel.basic_qos(prefetch_count=1) 注意：效率非常低，不能使用客户端缓存。消息有14个属性，最常用的几种：\n\ndeliveryMode：持久化属性\n\n\ncontentType：编码\nreplyTo：指定一个回调队列\ncorrelationId：消息id在client代码中，send方法时候，可以设置mandatory和immediate。设置mandatory:发送到交换器并且还未投递到队列（没有绑定器存在）得到通知。设置immediate：没有消费者能够立即处理的时候得到通知。这些投递保障机制，保证了消息可靠性。\n\n在client代码中，send方法时候persistent属性为true。数据就会被保存到队列中，但是必须Exchange,Queue,Client三者都设置为存储状态。\nRabbitMQ特性高可用性（HA）\n消息ACK，通知RabbitMQ消息已被处理，可以从内存删除。如果消费者因宕机或链接失败等原因没有发送ACK（不同于ActiveMQ，在RabbitMQ里，消息没有过期的概念），则RabbitMQ会将消息重新发送给其他监听在队列的下一个消费者。channel.basicConsume(queuename, noAck=false, consumer);\n消息和队列的持久化。定义队列时可以指定队列的持久化属性（问：持久化队列如何删除？） channel.queueDeclare(queuename, durable=true, false, false, null); 发送消息时可以指定消息持久化属性：这样，即使RabbitMQ服务器重启，也不会丢失队列和消息。channel.basicPublish(exchangeName, routingKey,MessageProperties.PERSISTENT_TEXT_PLAIN,message.getBytes());\npublisher confirms 提供批量确认消息的方法。\nmaster/slave机制，配合Mirrored Queue。Mirrored Queue通过policy和rabbitmqctl设置可以实现。具体可以参考Rabbitmq官方文档。在Mirrored Queue下，无论Producer和Consumer连接那个RabbitMq服务器，都跟连接同一个RabbitMQ上，消费和生产数据会被同步。注意：Mirrored Queue会严重的消耗性能，性能会下降到原来的1/5。当一个slave重新加入mirrored-queue时，如果queue是durable的，则会被清空。通过命令行或管理插件可以查看哪个slave是同步的：rabbitmqctl list_queues name slave_pids synchronised_slave_pids\n\n\n集群（cluster）\n不支持跨网段，因为RabbitMQ底层是Erlang，会导致脑裂（Slave Node感觉Master Node死掉了，主Master Node觉得Slave2 Node死掉了，结果数据无法复制，系统逻辑出现问题）（如需支持，需要shovel或federation插件）\n可以随意的动态增加或减少、启动或停止节点，允许节点故障。（但是数据同步会造成Queue服务暂停，所有的Producer和Consumer都被终止）\n集群分为RAM节点和DISK节点，一个集群最好至少有一个DISK节点保存集群的状态。\n集群的配置可以通过命令行，也可以通过配置文件，命令行优先。\n\n参考资料\n透彻rabbitmq\n\n","categories":["RabbitMQ","博客","消息队列"],"tags":["Java","消息队列","MQ","RabbitMQ"]},{"title":"秒杀系统扣减库存的常见几种设计","url":"http://leechaoqiang.github.io/2019/07/29/seconds-kill-when-reduce-sku-stock-design/","content":"背景我以前参与做过一个社交电商平台，其中就有秒杀场景，现在我从事的互联网酒店行业也有类似的秒杀场景，所以准备写一点关于秒杀相关的文字，就当总结记录一下吧。秒杀最主要的一个业务部门和我们技术部门需要注意一点，就是要防止超卖，而这个是电商行业经常会出现的现象。没有接触过秒杀的童鞋，可能会觉得，库存 200 件就卖 200 件，在数据库里减到 0 不就好了啊，这有什么好麻烦的？是的，理论上是这样，但是具体到业务场景中，“减库存”就不是这么简单了。例如，我们平常在淘宝或者京东上购物都是这样，看到喜欢的商品然后下单，但并不是每个下单请求你都最后付款了。你说系统是用户下单了就算这个商品卖出去了，还是等到用户真正付款了才算卖出了呢？这是个值得我们一起探讨问题！我们可以先根据减库存是发生在下单阶段还是付款阶段，把减库存做一下划分。\n扣减库存主要有哪几种方式呢在正常的电商平台购物场景中，用户的实际购买过程一般分为两步：下单 和 付款。你想买一台佳能单反相机，在商品页面点了“立即购买”按钮，核对信息之后点击“提交订单”，这一步称为下单操作。下单之后，你只有真正完成付款操作才能算真正购买，也就是俗话说的“落袋为安”。那如果你是架构师，你会在哪个环节完成减库存的操作呢？总结来说，减库存操作一般有如下几个方式：\n\n下单减库存，即当买家下单后，在商品的总库存中减去买家购买数量。下单减库存是最简单的减库存方式，也是控制最精确的一种，下单时直接通过数据库的事务机制控制商品库存，这样一定不会出现超卖的情况。但是你要知道，有些人下完单可能并不会付款。\n付款减库存，即买家下单后，并不立即减库存，而是等到有用户付款后才真正减库存，否则库存一直保留给其他买家。但因为付款时才减库存，如果并发比较高，有可能出现买家下单后付不了款的情况，因为可能商品已经被其他人买走了。\n预扣库存，这种方式相对复杂一些，买家下单后，库存为其保留一定的时间（如30分钟,早期12306的票就是下单后保留30分钟的支付时间，现在好像是15分钟），超过这个时间，库存将会自动释放，释放后其他买家就可以继续购买。在买家付款前，系统会校验该订单的库存是否还有保留：如果没有保留，则再次尝试预扣；如果库存不足（也就是预扣失败）则不允许继续付款；如果预扣成功，则完成付款并实际地减去库存。\n\n以上这几种减库存的方式也会存在一些问题，下面我们一起来看下。\n减库存可能存在的问题由于购物过程中存在两步或者多步的操作，因此在不同的操作步骤中减库存，就会存在一些可能被恶意买家利用的漏洞，例如发生恶意下单的情况。假如我们采用“下单减库存”的方式，即用户下单后就减去库存，正常情况下，买家下单后付款的概率会很高，所以不会有太大问题。但是有一种场景例外，就是当卖家参加某个活动时，此时活动的有效时间是商品的黄金售卖时间，如果有竞争对手通过恶意下单的方式将该卖家的商品全部下单，让这款商品的库存减为零，那么这款商品就不能正常售卖了。要知道，这些恶意下单的人是不会真正付款的，这正是“下单减库存”方式的不足之处。既然“下单减库存”可能导致恶意下单，从而影响卖家的商品销售，那么有没有办法解决呢？你可能会想，采用“付款减库存”的方式是不是就可以了？的确可以。但是，“付款减库存”又会导致另外一个问题：库存超卖。假如有 200 件商品，就可能出现 500 人下单成功的情况，因为下单时不会减库存，所以也就可能出现下单成功数远远超过真正库存数的情况，这尤其会发生在做活动的热门商品上。这样一来，就会导致很多买家下单成功但是付不了款，买家的购物体验自然比较差。可以看到，不管是“下单减库存”还是“付款减库存”，都会导致商品库存不能完全和实际售卖情况对应起来的情况，看来要把商品准确地卖出去还真是不容易啊！那么，既然“下单减库存”和“付款减库存”都有缺点，我们能否把两者相结合，将两次操作进行前后关联起来，下单时先预扣，在规定时间内不付款再释放库存，即采用“预扣库存”这种方式呢？这种方案确实可以在一定程度上缓解上面的问题。但是否就彻底解决了呢？其实没有！针对恶意下单这种情况，虽然把有效的付款时间设置为 15 分钟，但是恶意买家完全可以在 15 分钟后再次下单，或者采用一次下单很多件的方式把库存减完。针对这种情况，解决办法还是要结合安全和反作弊的措施来制止。例如，给经常下单不付款的买家进行识别打标（可以在被打标的买家下单时不减库存）、给某些类目设置最大购买件数（例如，参加活动的商品一人最多只能买2件），以及对重复下单不付款的操作进行次数限制等。针对 “库存超卖” 这种情况，在 15 分钟时间内下单的数量仍然有可能超过库存数量，遇到这种情况我们只能区别对待：对普通的商品下单数量超过库存数量的情况，可以通过补货来解决；但是有些卖家完全不允许库存为负数的情况，那只能在买家付款时提示库存不足。大型秒杀中如何减库存？目前来看，业务系统中最常见的就是预扣库存方案，像你在买火车票、买电影票时，下单后一般都有个“有效付款时间”，超过这个时间订单自动释放，这都是典型的预扣库存方案。而具体到秒杀这个场景，应该采用哪种方案比较好呢？由于参加秒杀的商品，一般都是“抢到就是赚到”，所以成功下单后却不付款的情况比较少，再加上卖家对秒杀商品的库存有严格限制，所以秒杀商品采用“下单减库存”更加合理。另外，理论上由于 “下单减库存”比 “预扣库存”以及涉及第三方支付的“付款减库存”在逻辑上更为简单，所以性能上更占优势。“下单减库存”在数据一致性上，主要就是保证大并发请求时库存数据不能为负数，也就是要保证数据库中的库存字段值不能为负数，一般我们有多种 解决方案：\n\n一种是在应用程序中通过事务来判断，即保证减后库存不能为负数，否则就回滚；\n另一种办法是直接设置数据库的字段数据为无符号整数，这样减后库存字段值小于零时会直接执行 SQL 语句来报错；\n再有一种就是使用 CASE WHEN 判断语句，例如这样的 SQL 语句：\nUPDATE goods SET stock = CASE WHEN stock &gt;= ? THEN stock- ? ELSE stock END  \n秒杀减库存的极致优化在交易环节中，“库存”是个关键数据，也是个热点数据，因为交易的各个环节中都可能涉及对库存的查询。但是，我在前面介绍分层过滤时提到过，秒杀中并不需要对库存有精确的一致性读，把库存数据放到缓存（Cache）中，可以大大提升读性能。解决大并发读问题，可以采用 LocalCache（即在秒杀系统的单机上缓存商品相关的数据）和对数据进行分层过滤的方式，但是像减库存这种大并发写无论如何还是避免不了，这也是秒杀场景下最为核心的一个技术难题。因此，这里我想专门来说一下秒杀场景下减库存的极致优化思路，包括如何在缓存中减库存以及如何在数据库中减库存。秒杀商品和普通商品的减库存还是有些差异的，例如商品数量比较少，交易时间段也比较短，因此这里有一个大胆的假设，即能否把秒杀商品减库存直接放到缓存系统中实现，也就是直接在缓存中减库存或者在一个带有持久化功能的缓存系统（如 Redis）中完成呢？如果你的秒杀商品的减库存逻辑非常单一，比如没有复杂的 SKU库存和总库存这种联动关系的话，我觉得完全可以。但是如果有比较复杂的减库存逻辑，或者需要使用事务，你还是必须在数据库中完成减库存。由于MySQL存储数据的特点，同一数据在数据库里肯定是一行存储（MySQL），因此会有大量线程来竞争 InnoDB 行锁，而并发度越高时等待线程会越多，TPS（Transaction Per Second，即每秒处理的消息数）会下降，RT（Request Time,即响应时间）会上升，数据库的吞吐量就会严重受影响。这就可能引发一个问题，就是单个热点商品会影响整个数据库的性能， 导致 0.01% 的商品影响 99.99% 的商品的售卖，这是我们不愿意看到的情况。一个解决思路是遵循前面介绍的原则进行隔离，把热点商品放到单独的热点库中。但是这无疑会带来维护上的麻烦，比如要做热点数据的动态迁移以及单独的数据库等。而分离热点商品到单独的数据库还是没有解决并发锁的问题，我们应该怎么办呢？要解决并发锁的问题，有两种办法：\n\n应用层做排队。按照商品维度设置队列顺序执行，这样能减少同一台机器对数据库同一行记录进行操作的并发度，同时也能控制单个商品占用数据库连接的数量，防止热点商品占用太多的数据库连接。\n\n数据库层做排队。应用层只能做到单机的排队，但是应用机器数本身很多，这种排队方式控制并发的能力仍然有限，所以如果能在数据库层做全局排队是最理想的。阿里的数据库团队开发了针对这种 MySQL 的 InnoDB 层上的补丁程序（patch），可以在数据库层上对单行记录做到并发排队。\n\n你可能有疑问了，排队和锁竞争不都是要等待吗，有啥区别？如果熟悉 MySQL 的话，你会知道 InnoDB 内部的死锁检测，以及 MySQL Server 和 InnoDB 的切换会比较消耗性能，据说淘宝的MySQL 核心团队还做了很多其他方面的优化，如 COMMIT_ON_SUCCESS 和 ROLLBACK_ON_FAIL 的补丁程序，配合在 SQL 里面加提示（hint），在事务里不需要等待应用层提交（COMMIT），而在数据执行完最后一条 SQL 后，直接根据 TARGET_AFFECT_ROW 的结果进行提交或回滚，可以减少网络等待时间（平均约 0.7ms）。据说目前阿里MySQL团队已经将包含这些补丁程序的 MySQL 开源。另外，数据更新问题除了前面介绍的热点隔离和排队处理之外，还有些场景（如对商品的 last_updated_time 字段的）更新会非常频繁，在某些场景下这些多条 SQL 是可以合并的，一定时间内只要执行最后一条 SQL 就行了，以便减少对数据库的更新操作。\nSUMMARY围绕商品减库存的场景，本文介绍了减库存的三种实现方案，以及分别存在的问题和可能的缓解办法。当然减库存还有很多细节问题，例如预扣的库存超时后如何进行库存回补，再比如目前都是第三方支付，如何在付款时保证减库存和成功付款时的状态一致性，都是值得我们去探讨和研究的。\n\n本文参考很多网络上的材料，如有侵权，请联系vincentlee99@126.com删除。\n\n","categories":["博客","Java","分布式"],"tags":["分布式","秒杀","电商","扣减库存","超卖","淘宝","京东","12306"]},{"title":"Docker容器化部署SpringBoot应用实践","url":"http://leechaoqiang.github.io/2019/06/19/docker-java-app-practise/","content":"一、Background\nSpring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can &quot;just run&quot;.\n用SpringBoot开发构建基于Spring的SpringBoot Apps应用服务是超级简单，但是多个实例同时部署到虚机，需要先上传包然后使用类似java -Dserver.port=8080 -jar app.jar命令启动。现在docker容器化技术已经发展很成熟，采用docker容器化部署SpringBoot Apps也是so easy.\n二、构建基于SpringBoot的Java应用容器化Docker部署1. 项目结构\n2. 基于SpringBoot的Java应用构建准备\npom.xml\n\n&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;    &lt;parent&gt;        &lt;artifactId&gt;springcloud-app-docker&lt;/artifactId&gt;        &lt;groupId&gt;com.licq&lt;/groupId&gt;        &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;    &lt;/parent&gt;    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;    &lt;artifactId&gt;springcloud-app-docker-java-helloworld&lt;/artifactId&gt;    &lt;name&gt;springcloud-app-docker-java-helloworld&lt;/name&gt;    &lt;packaging&gt;jar&lt;/packaging&gt;    &lt;description&gt;docker-java应用helloworld&lt;/description&gt;    &lt;properties&gt;        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;        &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;        &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;        &lt;java.version&gt;1.8&lt;/java.version&gt;    &lt;/properties&gt;    &lt;dependencies&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;        &lt;/dependency&gt;        &lt;dependency&gt;            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;            &lt;scope&gt;test&lt;/scope&gt;        &lt;/dependency&gt;    &lt;/dependencies&gt;    &lt;build&gt;        &lt;finalName&gt;$&#123;project.artifactId&#125;&lt;/finalName&gt;        &lt;pluginManagement&gt;            &lt;plugins&gt;                &lt;plugin&gt;                    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;                    &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;                    &lt;configuration&gt;                    &lt;skip&gt;true&lt;/skip&gt;                    &lt;/configuration&gt;                &lt;/plugin&gt;            &lt;/plugins&gt;        &lt;/pluginManagement&gt;        &lt;plugins&gt;            &lt;plugin&gt;                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;                &lt;configuration&gt;                    &lt;source&gt;8&lt;/source&gt;                    &lt;target&gt;8&lt;/target&gt;                &lt;/configuration&gt;            &lt;/plugin&gt;        &lt;/plugins&gt;    &lt;/build&gt;&lt;/project&gt;\n\n创建一个Api测试HelloController\npackage com.vincent.springcloud.app.docker.controller;import com.alibaba.fastjson.JSONObject;import org.springframework.beans.factory.annotation.Value;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.bind.annotation.RestController;/** * @author vincent.li * @Description docker-app-hello-world * @since 2019/6/29 */@RestControllerpublic class HelloController &#123;    @Value(&quot;$&#123;server.port&#125;&quot;)    private String serverPort;    @Value(&quot;$&#123;spring.application.name&#125;&quot;)    private String applicationName;    @ResponseBody    @GetMapping(&quot;/hello/&#123;name&#125;&quot;)    public JSONObject hello(@PathVariable(&quot;name&quot;) String name)&#123;        return new JSONObject()                .fluentPut(&quot;hello&quot;, name)                .fluentPut(&quot;application&quot;, applicationName)                .fluentPut(&quot;port&quot;, serverPort);    &#125;&#125;\n\nSpringBoot应用启动类\n\n\npackage com.vincent.springcloud.app.docker;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import java.util.TimeZone;/** * @author vincent.li * @Description api提供服务 * @since 2019/6/29 */@SpringBootApplication(scanBasePackages = &#123;&quot;com.vincent.springcloud.app.docker&quot;&#125;)public class SpringCloudAppDockerApplication &#123;    public static void main(String[] args) &#123;        TimeZone.setDefault(TimeZone.getTimeZone(&quot;Asia/Shanghai&quot;));        SpringApplication.run(SpringCloudAppDockerApplication.class, args);        System.out.println(&quot;(#^.^#)   【SpringCloud-docker-app-hello-world】启动成功      (#^.^#)&quot;);    &#125;&#125;\n3. SpringBoot应用打包成jarmvn clean install -DskipTests\n4. 编写Dockerfile#从公共仓库下载java:8到本地容器FROM java:8#申明作者可以不写MAINTAINER vincent.li vincentlee99@126.com#WORKDIR：工作目录，类似于cd命令#把maven打包好的jar拷贝到容器中并命名为app.jarCOPY target/springcloud-app-docker-java-helloworld.jar app.jar#ENV：设置环境变量ENV LANG C.UTF-8#配置容器，使其可执行化。配合CMD可省去&quot;application&quot;，只使用参数。ENTRYPOINT [&quot;java&quot;, &quot;-jar&quot;, &quot;/app.jar&quot;]#EXPOSE：指定于外界交互的端口EXPOSE 8080#VOLUME：用于指定持久化目录\n5. 构建Docker镜像在Dockerfile文件所在的目录执行以下docker命令构建镜像\ndocker build -t demo-helloworld .\n镜像构建完成后可以采用以下docker命令查看我们自己构建的镜像\ndocker image ls\n\n6. 使用镜像启动容器执行如下docker命令可以启动镜像\ndocker run -d -p 8099:8080 demo-helloworld\n启动命令中-d是以后台守护进程的方式执行，-p映射宿主机和容器内部执行应用服务的端口，上面的命令是把宿主机的8099端口映射到容器的8080端口，通过这些配置，我们就把docker容器的8080端口对应的服务提供给外面访问了。\n三、验证容器化部署应用\n我可以通过docker命令查看容器进程,可以查看到我们demo-helloworld镜像的容器在运行,以及相关端口映射信息。\n\ndocker ps\n命令执行结果如下图：\n\n\n也可以通过执行下面的docker命令进入容器内部查看应用的jar包位置。docker exec -it 3156c04e6d6c /bin/bash其中3156c04e6d6c为对应的容器id.命令执行结果如下图：\n\n\n通过http请求调用验证我们的应用是否能正常提供服务，在宿主上的浏览器上打开链接 http://localhost:8099/hello/docker，可以看到如下返回就说明服务正常了。&#123;    &quot;application&quot;:&quot;springcloud-docker-app-hello-world&quot;,    &quot;port&quot;:&quot;8080&quot;,    &quot;hello&quot;:&quot;docker&quot;&#125;\n也可以使用curl http://localhost:8099/hello/docker命令验证。\nOne More Thing我们如果想在同一台虚机上采用容器化部署多个应用怎么做了呢？很简单，只需要执行以下类似命令多条就可以实现，很方便。\ndocker run -d -p 8081:8080 demo-helloworlddocker run -d -p 8082:8080 demo-helloworlddocker run -d -p 8083:8080 demo-helloworld\n当然实际情况我们不可能是只有一台虚机，是多台虚机资源来部署，重复一条一条去执行命令肯定是不行的，这个可以结合jenkins,gitlab等工具，这个后面就涉及到CI/CD以及使用k8s来管理虚机资源和docker容器化服务治理和编排，后面有时间的时候再写一篇关于k8s可落地实践的文章。\n","categories":["Docker","SpringBoot"],"tags":["Java","Docker","容器化","SpringBoot"]},{"title":"TensorFlow初探（一）","url":"http://leechaoqiang.github.io/2018/11/25/tensorflow-open-practise/","content":"TensorFlow由谷歌人工智能团队谷歌大脑（Google Brain）开发和维护，拥有包括TensorFlow Hub、TensorFlow Lite、TensorFlow Research Cloud在内的多个项目以及各类应用程序接口（Application Programming Interface, API）,是一个适合所有人学习的开源的机器学习框架。\n今天刚参加了谷歌开发者大会，了解到了\b目前TensorFlow用于很多科学实验，解决了很多社会问题，\b感触很深。所以决定更多了解下\bTensorFlow。\n\b环境准备\n具备 Python 基础\n具备数学基础（如线性代数、微积分）\n对机器学习/深度学习的概念（如CNN、RNN、强化学习）稍有了解\n配置好 Python 和 TensorFlow 环境，配置好适合的 Python IDE（如PyCharm），环境配置方法请参考 https://tf.wiki/zh/installation.html （中文）或 https://tf.wiki/en/installation.html （英文）\n\n查看python和tensorflow的版本号：\n用命令python -V 或者python3 -V查看版本号：lichaoqiang@lichaoqiangs-MacBook-Pro ~/project/python  python3 -V              Python 3.5.2\n\b查看tensoflow的版本号,可以用如下脚本\n#!/usr/local/bin/python3import tensorflow as tfprint(tf.__version__)\n运行tensorflow-version.py脚本可以查看： lichaoqiang@lichaoqiangs-MacBook-Pro  ~/project/python  python3 tensorflow-version.py1.11.0\n\n\n用TensorFlow解决实际问题案例\n具体问题描述\n  某公司有四个工厂，分布在不同地区，同时三种产品，产量（单位；t）， 试用矩阵统计这些数据。工厂/产品    P1    P2    P3 甲        5    2    4 乙        3    8    2 丙        6    0    4 丁        0    1    6 其中四行分别表示甲乙丙丁四个工厂的生产情况，三列分布表示三种产品P1，P2，P3的产量。 再设矩阵 2   4 1   3 3   2 其中第一列表示三种产品的单件利润，第二列表示三种产品的单件体积。\n\n用python实现使用tensorflow来计算,新建脚本tensorflow-demo05.py，代码如下:\n\n\n#!/usr/local/bin/python3import tensorflow as tftf.enable_eager_execution()a = tf.constant([[5,2,4], [3, 8,2],[6,0,4],[0,1,6]])b = tf.constant([[2,4],[1,3],[3,2]])c = tf.matmul(a, b)print(c)\n\n执行python脚本得到结果(venv)  ✘ lichaoqiang@lichaoqiangs-MacBook-Pro  ~/project/python  python3 tensorflow-demo05.py 2018-11-25 22:02:52.718706: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMAtf.Tensor([[24 34] [20 40] [24 32] [19 15]], shape=(4, 2), dtype=int32)\n很简单的几行代码可以轻松计算出了四个工厂的利润（结果第一列）和这四个工厂产品需要的存储空间（结果第二列）。通过这个简单的例子可以看出，\bTensorflow的很多计算模型很实用，而且也很容易上手，后面空了\b，我再试一试其他功能。\n\n","categories":["tensorflow"],"tags":["tensorflow","强化学习","python","深度增强学习"]},{"title":"Mybatis常见面试题","url":"http://leechaoqiang.github.io/2018/09/04/mybatis-common-interview-question/","content":"Mybatis是我们常用的ORM框架，经常用，但是对于 Mybatis 的技术架构和重要组成部分，以及基本运行原理，很多人了解的不多，我在网上见到了很多常考的面试题，整理了下相关答案（有些是自己想的，有些是网上搜索的），答案有不合理或者错误的请指正提出。\n废话不多说，直接上Mybatis常考面试题，康康我们能答出来几道。\n1、#{}和${}的区别是什么？\n可能很多人只用过#{}，而很少用${}，有过分库分表经验的童鞋可能用过${}。\n\n答：\n\n$&#123;&#125;是 Properties 文件中的变量占位符，它可以用于标签属性值和 sql 内部，属于静态文本替换，比如${driver}会被静态替换为com.mysql.jdbc.Driver。\n#&#123;&#125;是 sql 的参数占位符，Mybatis 会将 sql 中的#&#123;&#125;替换为?号，在 sql 执行前会使用 PreparedStatement 的参数设置方法，按序给 sql 的?号占位符设置参数值，比如 ps.setInt(0, parameterValue)，#&#123;item.name&#125; 的取值方式为使用反射从参数对象中获取 item 对象的 name 属性值，相当于 param.getItem().getName()。\n\n2、Xml 映射文件中，除了常见的 select|insert|updae|delete 标签之外，还有哪些标签？\n据说来自京东面试管的考题\n\n答：还有很多其他的标签，&lt;resultMap&gt;、&lt;parameterMap&gt;、&lt;sql&gt;、&lt;include&gt;、&lt;selectKey&gt;，加上动态 sql 的 9 个标签，trim|where|set|foreach|if|choose|when|otherwise|bind等，其中为 sql 片段标签，通过&lt;include&gt;标签引入 sql 片段，&lt;selectKey&gt;为不支持自增的主键生成策略标签。\n3、最佳实践中，通常一个 Xml 映射文件，都会写一个 Dao 接口与之对应，请问，这个 Dao 接口的工作原理是什么？Dao 接口里的方法，参数不同时，方法能重载吗？\n据说来自京东面试管的考题\n\n答：Dao 接口，就是人们常说的 Mapper接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中MappedStatement的 id 值，接口方法内的参数，就是传递给 sql 的参数。Mapper接口是没有实现类的，当调用接口方法时，接口全限名+方法名拼接字符串作为 key 值，可唯一定位一个MappedStatement，举例：com.mybatis3.mappers.StudentDao.findStudentById，可以唯一找到 namespace 为com.mybatis3.mappers.StudentDao下面id = findStudentById的MappedStatement。在 Mybatis 中，每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签，都会被解析为一个MappedStatement对象。\nDao 接口里的方法，是不能重载的，因为是全限名+方法名的保存和寻找策略。\nDao 接口的工作原理是 JDK 动态代理，Mybatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行MappedStatement所代表的 sql，然后将 sql 执行结果返回。\n4、Mybatis 是如何进行分页的？分页插件的原理是什么？答：Mybatis使用RowBounds对象进行分页，它是针对ResultSet结果集执行的内存分页，而非物理分页，可以在sql内直接书写带有物理分页的参数来完成物理分页功能，也可以使用分页插件来完成物理分页。\n分页插件的基本原理是使用Mybatis提供的插件接口，实现自定义插件，在插件的拦截方法内拦截待执行的 sql，然后重写sql，根据dialect方言，添加对应的物理分页语句和物理分页参数。\n举例：select \\* from student，拦截 sql 后重写为：select t.* from （select \\* from student）t limit 0，10\n5、Mybatis执行批量插入，可以返回数据库主键列表吗？答：可以，JDBC都可以，Mybatis当然也可以。\n6、简述 Mybatis 的插件运行原理，以及如何编写一个插件。答：Mybatis仅可以编写针对 ParameterHandler、ResultSetHandler、StatementHandler、Executor 这 4 种接口的插件，Mybatis 使用 JDK 的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能，每当执行这 4 种接口对象的方法时，就会进入拦截方法，具体就是 InvocationHandler 的 invoke()方法，当然，只会拦截那些你指定需要拦截的方法。\n实现 Mybatis 的 Interceptor 接口并复写intercept()方法，然后在给插件编写注解，指定要拦截哪一个接口的哪些方法即可，记住，别忘了在配置文件中配置你编写的插件。\n7、Mybatis 是如何将 sql 执行结果封装为目标对象并返回的？都有哪些映射形式？答：第一种是使用&lt;resultMap&gt;标签，逐一定义列名和对象属性名之间的映射关系。第二种是使用 sql 列的别名功能，将列别名书写为对象属性名，比如 T_NAME AS NAME，对象属性名一般是 name，小写，但是列名不区分大小写，Mybatis 会忽略列名大小写，智能找到与之对应对象属性名，你甚至可以写成 T_NAME AS NaMe，Mybatis 一样可以正常工作。\n有了列名与属性名的映射关系后，Mybatis 通过反射创建对象，同时使用反射给对象的属性逐一赋值并返回，那些找不到映射关系的属性，是无法完成赋值的。\n8、Mybatis 动态 sql 是做什么的？都有哪些动态 sql？能简述一下动态 sql 的执行原理不？答：Mybatis 动态 sql 可以让我们在 Xml 映射文件内，以标签的形式编写动态 sql，完成逻辑判断和动态拼接 sql 的功能，Mybatis 提供了 9 种动态 sql 标签 trim|where|set|foreach|if|choose|when|otherwise|bind。\n其执行原理为，使用 OGNL 从 sql 参数对象中计算表达式的值，根据表达式的值动态拼接 sql，以此来完成动态 sql 的功能。\n9、Mybatis 能执行一对一、一对多的关联查询吗？都有哪些实现方式，以及它们之间的区别。答：能，Mybatis 不仅可以执行一对一、一对多的关联查询，还可以执行多对一，多对多的关联查询，多对一查询，其实就是一对一查询，只需要把 selectOne()修改为 selectList()即可；多对多查询，其实就是一对多查询，只需要把 selectOne()修改为 selectList()即可。\n关联对象查询，有两种实现方式，一种是单独发送一个 sql 去查询关联对象，赋给主对象，然后返回主对象。另一种是使用嵌套查询，嵌套查询的含义为使用 join 查询，一部分列是 A 对象的属性值，另外一部分列是关联对象 B 的属性值，好处是只发一个 sql 查询，就可以把主对象和其关联对象查出来。\n那么问题来了，join 查询出来 100 条记录，如何确定主对象是 5 个，而不是 100 个？其去重复的原理是&lt;resultMap&gt;标签内的&lt;id&gt;子标签，指定了唯一确定一条记录的 id 列，Mybatis 根据列值来完成 100 条记录的去重复功能，&lt;id&gt;可以有多个，代表了联合主键的语意。\n同样主对象的关联对象，也是根据这个原理去重复的，尽管一般情况下，只有主对象会有重复记录，关联对象一般不会重复。\n举例：下面 join 查询出来 6 条记录，一、二列是 Teacher 对象列，第三列为 Student 对象列，Mybatis 去重复处理后，结果为 1 个老师 6 个学生，而不是 6 个老师 6 个学生。\n|t_id|t_name|s_id| 1 | teacher | 38 || 1 | teacher | 39 || 1 | teacher | 40 || 1 | teacher | 41 || 1 | teacher | 42 || 1 | teacher | 43 |\n10、Mybatis 是否支持延迟加载？如果支持，它的实现原理是什么？答：Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载，association 指的就是一对一，collection 指的就是一对多查询。在 Mybatis 配置文件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。\n它的原理是，使用CGLIB 创建目标对象的代理对象，当调用目标方法时，进入拦截器方法，比如调用 a.getB().getName()，拦截器 invoke()方法发现 a.getB()是 null 值，那么就会单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上来，然后调用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName()方法的调用。这就是延迟加载的基本原理。\n当然了，不光是 Mybatis，几乎所有的包括 Hibernate，支持延迟加载的原理都是一样的。\n11、Mybatis 的 Xml 映射文件中，不同的 Xml 映射文件，id 是否可以重复？答：不同的 Xml 映射文件，如果配置了 namespace，那么 id 可以重复；如果没有配置 namespace，那么 id 不能重复；毕竟 namespace 不是必须的，只是最佳实践而已。\n原因就是 namespace+id 是作为 Map&lt;String, MappedStatement&gt;的 key 使用的，如果没有 namespace，就剩下 id，那么，id 重复会导致数据互相覆盖。有了 namespace，自然 id 就可以重复，namespace 不同，namespace+id 自然也就不同。\n12、Mybatis 中如何执行批处理？答：使用 BatchExecutor 完成批处理。\n13、Mybatis 都有哪些 Executor 执行器？它们之间的区别是什么？答：Mybatis 有三种基本的 Executor 执行器，SimpleExecutor、ReuseExecutor、BatchExecutor。\n SimpleExecutor：每执行一次 update 或 select，就开启一个 Statement 对象，用完立刻关闭 Statement 对象。\n ReuseExecutor：执行 update 或 select，以 sql 作为 key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象，而是放置于 Map内，供下一次使用。简言之，就是重复使用 Statement 对象。\n BatchExecutor：执行 update（没有 select，JDBC 批处理不支持 select），将所有 sql 都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个 Statement 对象，每个 Statement 对象都是 addBatch()完毕后，等待逐一执行 executeBatch()批处理。与 JDBC 批处理相同。\n作用范围：Executor 的这些特点，都严格限制在 SqlSession 生命周期范围内。\n14、Mybatis 中如何指定使用哪一种 Executor 执行器？答：在 Mybatis 配置文件中，可以指定默认的 ExecutorType 执行器类型，也可以手动给 DefaultSqlSessionFactory 的创建 SqlSession 的方法传递 ExecutorType 类型参数。\n15、为什么说 Mybatis 是半自动 ORM 映射工具？它与全自动的区别在哪里？答：Hibernate 属于全自动 ORM 映射工具，使用 Hibernate 查询关联对象或者关联集合对象时，可以根据对象关系模型直接获取，所以它是全自动的。而 Mybatis 在查询关联对象或关联集合对象时，需要手动编写 sql 来完成，所以，称之为半自动 ORM 映射工具。\n16、简述 Mybatis 的 Xml 映射文件和 Mybatis 内部数据结构之间的映射关系？答：Mybatis 将所有 Xml 配置信息都封装到 All-In-One 重量级对象 Configuration 内部。在 Xml 映射文件中，&lt;parameterMap&gt;标签会被解析为 ParameterMap 对象，其每个子元素会被解析为 ParameterMapping 对象。&lt;resultMap&gt;标签会被解析为 ResultMap 对象，其每个子元素会被解析为 ResultMapping 对象。每一个&lt;select&gt;、&lt;insert&gt;、&lt;update&gt;、&lt;delete&gt;标签均会被解析为 MappedStatement 对象，标签内的 sql 会被解析为 BoundSql 对象。\n17、Mybatis 是否可以映射 Enum 枚举类？答：Mybatis 可以映射枚举类，不单可以映射枚举类，Mybatis 可以映射任何对象到表的一列上。映射方式为自定义一个 TypeHandler，实现 TypeHandler 的 setParameter()和 getResult()接口方法。TypeHandler 有两个作用，一是完成从 javaType 至 jdbcType 的转换，二是完成 jdbcType 至 javaType 的转换，体现为 setParameter()和 getResult()两个方法，分别代表设置 sql 问号占位符参数和获取列查询结果。\n18、Mybatis 映射文件中，如果 A 标签通过 include 引用了 B 标签的内容，请问，B 标签能否定义在 A 标签的后面，还是说必须定义在 A 标签的前面？答：虽然 Mybatis 解析 Xml 映射文件是按照顺序解析的，但是，被引用的 B 标签依然可以定义在任何地方，Mybatis 都可以正确识别。\n原理是，Mybatis 解析 A 标签，发现 A 标签引用了 B 标签，但是 B 标签尚未解析到，尚不存在，此时，Mybatis 会将 A 标签标记为未解析状态，然后继续解析余下的标签，包含 B 标签，待所有标签解析完毕，Mybatis 会重新解析那些被标记为未解析的标签，此时再解析 A 标签时，B 标签已经存在，A 标签也就可以正常解析完成了。\n孙子曰：兵者，国之大事，死生之地，存亡之道，不可不察也。\n","categories":["mybatis","博客"],"tags":["Mybatis","数据库中间件","ORM"]},{"title":"三个线程顺序打印ABC字符串10遍的三种实现方案","url":"http://leechaoqiang.github.io/2017/01/12/three-print-abc-char-ten-times-solutions/","content":"What之前同事遇到过这样一个面试题，大概是用三个线程顺序打印ABC字符串，打印10遍。请给出至少一种解决方案。\nWhy面试官为什么出这个问题呢？我想大概主要是想考验一下面试者多线程的熟悉度，理解和运用。\nHow\n我想了一会儿，给出大概3种实现方案。一种使用synchronized关键字来做锁，另外两种不使用锁机制，大同小异的实现。Talk is cheap,show me your code!!!\n\n实现一，使用synchronized关键字来做锁。import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;/** * 三个线程顺序打印字符串ABC，打印10遍 * 写法一 * */public class ThreadTest &#123;    private boolean flagA =true;    private boolean flagB =false;    private boolean flagC =false;    private Object objA = new Object();    private Object objB = new Object();    private Object objC = new Object();    private void printA() throws InterruptedException&#123;        for(int i=0;i&lt;10;i++)&#123;            synchronized(objA)&#123;                synchronized(objB)&#123;                    while(flagA)&#123;                        System.out.println(&quot;A&quot;);                        flagA=false;                        flagB=true;                        objB.notify();                    &#125;                &#125;                objA.wait();            &#125;               &#125;    &#125;    private void printB() throws InterruptedException&#123;        for(int i=0;i&lt;10;i++)&#123;            synchronized(objB)&#123;                synchronized(objC)&#123;                    while(flagB)&#123;                        System.out.println(&quot;B&quot;);                        flagB=false;                        flagC=true;                        objC.notify();                    &#125;                &#125;                objB.wait();            &#125;               &#125;    &#125;        private void printC() throws InterruptedException&#123;        for(int i=0;i&lt;10;i++)&#123;            synchronized(objC)&#123;                synchronized(objA)&#123;                    while(flagC)&#123;                        System.out.println(&quot;C&quot;);                        flagA=true;                        flagC=false;                        objA.notify();                    &#125;                &#125;                objC.wait();            &#125;               &#125;    &#125;    public static void main(String[] args) throws InterruptedException &#123;        final ThreadTest ThreadTest =new ThreadTest();                Runnable ra = new Runnable()&#123;            public void run()&#123;                try &#123;                    ThreadTest.printA();                &#125; catch (InterruptedException e) &#123;                    // TODO Auto-generated catch block                    e.printStackTrace();                &#125;            &#125;        &#125;;        Runnable rb = new Runnable()&#123;            public void run()&#123;                try &#123;                    ThreadTest.printB();                &#125; catch (InterruptedException e) &#123;                    // TODO Auto-generated catch block                    e.printStackTrace();                &#125;            &#125;        &#125;;        Runnable rc = new Runnable()&#123;            public void run()&#123;                try &#123;                    ThreadTest.printC();                &#125; catch (InterruptedException e) &#123;                    // TODO Auto-generated catch block                    e.printStackTrace();                &#125;            &#125;        &#125;;        new Thread(ra).start();        Thread.sleep(300);         new Thread(rb).start();        Thread.sleep(300);        new Thread(rc).start();                &#125;    &#125;\n\n\n\n\n实现二import java.util.concurrent.atomic.AtomicInteger;/** * 三个线程顺序打印字符串ABC，打印10遍 * 写法二 * @author lichaoqiang * */public class ThreadTest2 implements Runnable&#123;            static Thread[] threads = new Thread[3];    static int len = 3;    static final AtomicInteger ai = new AtomicInteger(1);    String val=&quot;&quot;;        public ThreadTest2(String val)&#123;        this.val = val;    &#125;        public void run() &#123;        while(true)&#123;            if(ai.get()&lt;= 30)&#123;                                if(&quot;A&quot;.equals(val))&#123;                                        if(ai.get()%len == 1)&#123;                        // TODO Auto-generated method stub                        System.out.println(Thread.currentThread().getName()+val);                        ai.getAndIncrement();                    &#125;                 &#125;                if(&quot;B&quot;.equals(val))&#123;                    if(ai.get()%len == 2)&#123;                        // TODO Auto-generated method stub                        System.out.println(Thread.currentThread().getName()+val);                        ai.getAndIncrement();                    &#125;                &#125;                if(&quot;C&quot;.equals(val))&#123;                    if(ai.get()%len == 0)&#123;                        // TODO Auto-generated method stub                        System.out.println(Thread.currentThread().getName()+val);                        ai.getAndIncrement();                    &#125;                &#125;            &#125;else&#123;                break;            &#125;                    &#125;        //          &#125;        public static void main(String[] args) throws InterruptedException &#123;        // TODO Auto-generated method stub                        threads[0] = new Thread(new ThreadTest2(&quot;A&quot;));                threads[1] = new Thread(new ThreadTest2(&quot;B&quot;));                threads[2] = new Thread(new ThreadTest2(&quot;C&quot;));                threads[0].start();        threads[1].start();        threads[2].start();    &#125;&#125;\n实现三package com.licq.thread;import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;/** * 三个线程顺序打印字符串ABC，打印10遍 * 写法三 * */public class ThreadTest3 &#123;    private static int seq = 0;    private static Thread[] threads = new Thread[3];    private static Map&lt;String, String&gt; mapping = new HashMap&lt;String, String&gt;();    public static void main(String[] args) &#123;        mapping.put(&quot;0&quot;, &quot;A&quot;);        mapping.put(&quot;1&quot;, &quot;B&quot;);        mapping.put(&quot;2&quot;, &quot;C&quot;);        for (int i = 0; i &lt; threads.length; i++) &#123;            threads[i] = new Thread(new Runnable() &#123;                                public void run() &#123;                    while (true) &#123;                        if(seq &gt;= 30)&#123;                            break;                        &#125;                        String threadName = Thread.currentThread().getName();                        if (seq % threads.length == Integer                                .parseInt(threadName)) &#123;                            System.out.println(&quot;------------&quot; + mapping.get(threadName) + &quot;-----------&quot;);                            seq = seq + 1;                        &#125; else &#123;                            try &#123;                                TimeUnit.SECONDS.sleep(1);                            &#125; catch (InterruptedException e) &#123;                            &#125;                        &#125;                    &#125;                &#125;            &#125;);            threads[i].setName(String.valueOf(i));            threads[i].start();        &#125;    &#125;&#125;\n\n\nSUMMARY以上三种是比较简单的实现方式，当然还有其他很多实现方式，欢迎有更简单更优雅的实现方式贴在下面一起交流。\n","categories":["博客","thread","多线程"],"tags":["并发","多线程","thread"]},{"title":"Java服务之spi机制简要说明和实践","url":"http://leechaoqiang.github.io/2016/11/10/java-spi-practise-demo-introduction-md/","content":"一、SPI概念&nbsp;&nbsp;这里先说下SPI的一个概念，SPI英文为Service Provider Interface单从字面可以理解为Service提供者接口，正如从SPI的名字去理解SPI就是Service提供者接口；我对SPI的定义：提供给服务提供厂商与扩展框架功能的开发者使用的接口。\n\n&nbsp;&nbsp;当服务的提供者，提供了服务接口的一种实现之后，在jar包的META-INF/services/目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF/services/里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。 很多框架都使用了java的SPI机制，如java.sql.Driver的SPI实现（mysql驱动、oracle驱动等）、common-logging的日志接口实现、dubbo的扩展实现等等框架；基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。jdk提供服务实现查找的一个工具类：java.util.ServiceLoader.\n二、SPI机制的说明：\n1)         在META-INF/services/目录中创建以接口全限定名命名的文件该文件内容为Api具体实现类的全限定名\n\n2)         使用ServiceLoader类动态加载META-INF中的实现类\n\n3)         如SPI的实现类为Jar则需要放在主程序classPath中\n\n4)         Api具体实现类必须有一个不带参数的构造方法\n\n\n三、SPI的一个小demo假设有一个内容搜索系统，分为展示和搜索两个模块。展示和搜索基于接口编程。搜索的实现可能是基于文件系统的搜索，也可能是基于数据库的搜索。实例代码如下Search.java: 搜索接口package com.licq.spi;import java.util.List;public interface Search &#123;     List&lt;Object&gt; search(String keyword);  &#125;下面定义两实现类FileSearch.java:文件系统的搜索实现package com.licq.spi;import java.util.List;public class FileSearch implements Search &#123;    @Override    public List&lt;Object&gt; search(String keyword) &#123;        // TODO Auto-generated method stub        System.out.println(&quot;  FileSearch search.....keywords:&quot;+keyword);        return null;    &#125;&#125;DatabaseSearch.java实现类package com.licq.spi;import java.util.List;public class DatabaseSearch implements Search &#123;    @Override    public List&lt;Object&gt; search(String keyword) &#123;        // TODO Auto-generated method stub        System.out.println(&quot;  databaseSearch  search.....keywords:&quot;+keyword);        return null;    &#125;&#125;Client.java测试类：\npackage com.licq.spi;import java.util.Iterator;import java.util.ServiceLoader;public class Client &#123;    public static void main(String[] args) &#123;        // TODO Auto-generated method stub        ServiceLoader&lt;Search&gt; s = ServiceLoader.load(Search.class);          Iterator&lt;Search&gt; searchs = s.iterator();          while(searchs.hasNext())&#123;            Search sea = searchs.next();            sea.search(&quot;hello world.&quot;);        &#125;    &#125;&#125;最后创建在META-INF/searvices/com.licq.spi.Search文件。当 com.licq.spi.Search文件内容是”com.licq.spi.FileSearch”时，程序输出是：FileSearch search.....keywords:hello world.当com.licq.spi.Search文件内容是”com.licq.spi.DatabaseSearch”时，程序输出是：databaseSearch  search.....keywords:hello world.可以看出Client.java里没有任何和具体实现有关的代码，而是基于spi的机制去查找服务的实现。很多开源框架也是基于这种机制去实现的，具体的完整源码demo可以在Github上去查看。\n","categories":["博客"],"tags":["分布式服务","RPC"]},{"title":"String,StringBuffer,StringBuilder拼接操作的效率比拼","url":"http://leechaoqiang.github.io/2016/10/21/string-stringbuilder-stringbuffer-run-efficiency-compare/","content":"前言 有很多时候，会有大量的字符串的拼接操作，但是我们很多coder，尤其是刚入职场的年轻coder,使用的方式可能就是String str +=s;而且我翻我自己所参与的项目里面的以前很久的代码也有大量的这种写法，但是很少有人知道，这种写法在操作基数很大的时候效率还是很低下的。talk is cheep,show me the code,少说废话，先上代码吧。\n测试场景一\n当字符串拼接操作次数在1000的级别时，效率差异不是很大的。public class TestClient &#123;/** * @param args */public static void main(String[] args) throws Exception&#123;    // TODO Auto-generated method stub    testString();&#125;private static void testString()throws Exception&#123;            ///1.str+=s的方式。    String str= &quot;&quot;;    String s =&quot;a&quot;;    long start = System.currentTimeMillis();        for(int i=0; i &lt; 1000;i++)&#123;        str+=s;    &#125;        long end = System.currentTimeMillis();    System.out.println(&quot;String+=s耗时：&quot;+(end-start)+&quot;ms&quot;);        ///2.String.concat()方式    long start1 = System.currentTimeMillis();    String str1= &quot;&quot;;    for(int i=0; i &lt; 1000;i++)&#123;        str1.concat(s);    &#125;        long end1 = System.currentTimeMillis();        System.out.println(&quot;String.concat()耗时：&quot;+(end1-start1)+&quot;ms&quot;);    ///3.StringBuffer.append()方式        long start2 = System.currentTimeMillis();    StringBuffer str2= new StringBuffer();    for(int i=0; i &lt; 1000;i++)&#123;        str2.append(s);    &#125;        long end2 = System.currentTimeMillis();    System.out.println(&quot;StringBuffer.append()耗时：&quot;+(end2-start2)+&quot;ms&quot;);        4.StringBuilder.append()方式    long start3 = System.currentTimeMillis();    StringBuilder str3= new StringBuilder();    for(int i=0; i &lt; 1000;i++)&#123;        str3.append(s);    &#125;        long end3 = System.currentTimeMillis();    System.out.println(&quot;StringBuilder.append()耗时：&quot;+(end3-start3) +&quot;ms&quot;);    &#125;\n场景一运行结果String+=s耗时：3msString.concat()耗时：0msStringBuffer.append()耗时：0msStringBuilder.append()耗时：0ms\n测试场景二当操作的次数上升到10000的时候有如何呢?\n\n场景二运行结果String+=s耗时：71msString.concat()耗时：1msStringBuffer.append()耗时：1msStringBuilder.append()耗时：1ms\n测试场景三\n当操作上升到100000的时候有如何呢?String+=s耗时：13250msString.concat()耗时：7msStringBuffer.append()耗时：4msStringBuilder.append()耗时：3ms\n\n结论结果总是那么让人惊艳。很显然StringBuilder和StringBuffer的append()方式效率更高，String的concat()的方法效率也还可以的。那为什么String的+=s的操作方式效率会那么低呢？那是因为这种方式会不停的创建新的String对象，这样会浪费不少内存空间，而且效率也不高。所以我们一般处理少量操作的时候建议用String的concat()方法就可以了。遇到大量拼接操作的时候建议还是用StringBuffer，StringBuilder的append()的方法。\n","categories":["Java"],"tags":["String","StringBuilder","StringBuffer","字符串"]},{"title":"RESTful-WebService初识入门NO.1","url":"http://leechaoqiang.github.io/2016/09/06/restful-webservice-learning-greenhand-note-001/","content":"RESTful WebService是把一切对象方法看做资源，开发RESTful WebService意味着支持在多种媒体类型以及抽象底层的客户端-服务器通信细节，如果没有一个好的工具包可用，会变得不那么容易。为了简化使用JAVA开发RESTful WebService及其客户端，一个轻量级的标准被提出：JAX-RS API。Jersey RESTful WebService框架是一个开源的、产品级别的JAVA框架，支持JAX-RS API并且是一个JAX-RS(JSR 311和 JSR 339)的参考实现。Jersey不仅仅是一个JAX-RS的参考实现，Jersey提供自己的API，其API继承自JAX-RS，提供更多的特性和功能以进一步简化RESTful service和客户端的开发。Jersey2.1版本之前默认HK2作为Ioc容器，后面才增加了Spring的支持。同时默认采用glassfish作为web容器。\n接下里我们 使用 maven来 实践 一个 小 练习。\n检测自己本地的maven版本：sh-3.2# mvn -versionApache Maven 3.3.3 (7994120775791599e205a5524ec3e0dfe41d4a06; 2015-04-22T19:57:37+08:00)Maven home: /Users/lichaoqiang/Maven/Maven3.3.3Java version: 1.7.0_79, vendor: Oracle CorporationJava home: /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/jreDefault locale: zh_CN, platform encoding: UTF-8OS name: &quot;mac os x&quot;, version: &quot;10.11.6&quot;, arch: &quot;x86_64&quot;, family: &quot;mac&quot;\n创建第一个restful风格的maven工程。在终端里面执行以下命令：mvn archetype:generate -DarchetypeArtifactId=jersey-quickstart-grizzly2 -DarchetypeGroupId=org.glassfish.jersey.archetypes -DinteractiveMode=false -DgroupId=com.licq.restful -DartifactId=licq-first-service -Dpackage=com.licq -DarchetypeVersion=2.22.1\n得到的结果如下，表示创建成功。[INFO] Using following parameters for creating project from Old (1.x) Archetype: jersey-quickstart-grizzly2:2.22.1[INFO] ----------------------------------------------------------------------------[INFO] Parameter: groupId, Value: com.licq.restful[INFO] Parameter: packageName, Value: com.licq[INFO] Parameter: package, Value: com.licq[INFO] Parameter: artifactId, Value: licq-first-service[INFO] Parameter: basedir, Value: /Users/lichaoqiang/project/restfulService_demo[INFO] Parameter: version, Value: 1.0-SNAPSHOT[INFO] project created from Old (1.x) Archetype in dir: /Users/lichaoqiang/project/restfulService_demo/licq-first-service[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 59.191 s[INFO] Finished at: 2016-09-06T10:11:14+08:00[INFO] Final Memory: 16M/245M[INFO] ------------------------------------------------------------------------\n使用mvn命令来编译测试新建的工程。执行命令如下：得到如下的结果,表示编译通过。------------------------------------------------------- T E S T S-------------------------------------------------------Running com.licq.MyResourceTestSep 06, 2016 10:17:02 AM org.glassfish.grizzly.http.server.NetworkListener start信息: Started listener bound to [localhost:8080]Sep 06, 2016 10:17:02 AM org.glassfish.grizzly.http.server.HttpServer start信息: [HttpServer] Started.Sep 06, 2016 10:17:02 AM org.glassfish.grizzly.http.server.NetworkListener shutdownNow信息: Stopped listener bound to [localhost:8080]Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 1.154 secResults :Tests run: 1, Failures: 0, Errors: 0, Skipped: 0[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 36.341 s[INFO] Finished at: 2016-09-06T10:17:02+08:00[INFO] Final Memory: 16M/245M\n执行mvn exec:java命令，启动我们的服务，并查看结果。\n\nsh-3.2# mvn exec:java[INFO] Scanning for projects...[INFO][INFO] ------------------------------------------------------------------------[INFO] Building licq-first-service 1.0-SNAPSHOT[INFO] ------------------------------------------------------------------------[INFO][INFO] &gt;&gt;&gt; exec-maven-plugin:1.2.1:java (default-cli) &gt; validate @ licq-first-service &gt;&gt;&gt;[INFO][INFO] &lt;&lt;&lt; exec-maven-plugin:1.2.1:java (default-cli) &lt; validate @ licq-first-service &lt;&lt;&lt;[INFO][INFO] --- exec-maven-plugin:1.2.1:java (default-cli) @ licq-first-service ---Downloading: http://192.168.29.1:8081/nexus/content/groups/public/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jarDownloading: http://192.168.29.1:8081/nexus/content/groups/public/org/codehaus/plexus/plexus-container-default/1.0-alpha-9/plexus-container-default-1.0-alpha-9.jarDownloaded: http://192.168.29.1:8081/nexus/content/groups/public/org/apache/commons/commons-exec/1.1/commons-exec-1.1.jar (52 KB at 30.3 KB/sec)Downloaded: http://192.168.29.1:8081/nexus/content/groups/public/org/codehaus/plexus/plexus-container-default/1.0-alpha-9/plexus-container-default-1.0-alpha-9.jar (191 KB at 93.7 KB/sec)Sep 06, 2016 10:18:08 AM org.glassfish.grizzly.http.server.NetworkListener start信息: Started listener bound to [localhost:8080]Sep 06, 2016 10:18:08 AM org.glassfish.grizzly.http.server.HttpServer start信息: [HttpServer] Started.Jersey app started with WADL available at http://localhost:8080/myapp/application.wadlHit enter to stop it...\n\n在浏览器中输入地址：http://localhost:8080/myapp/application.wadl查看wsdl的描述。\n\n在浏览器中输入地址：http://localhost:8080/myapp/myresource查看我们的资源，也就是方法。这个小实践的源码在Github上有备份，可以下载查看，很简单，后面会有更多的详解。\n\n\n","categories":["博客","Restful"],"tags":["restful","webservice"]},{"title":"轻量级极速数据层访问框架mango","url":"http://leechaoqiang.github.io/2016/06/22/mango-jfaster-dao-struct-intraductions/","content":"最近逛论坛发现了一个轻量级极速数据层访问框架－－mango。能够实现分表分库，功能还算比较强大。据官网介绍，mango的中文名是“芒果”，它是一个轻量级极速数据层访问框架。目前已有十多个大型线上项目在使用mango，在某一支付系统中，更是利用mango，承载了每秒12万的支付下单请求。\n下面是mango的一些特性:\n超高性能，响应速度接近直接使用JDBC\n采用接口与注解的形式定义DAO，完美结合db与cache操作\n支持动态sql，可以构造任意复杂的sql语句\n支持多数据源，分表，分库，事务\n内嵌“函数式调用”功能，能将任意复杂的对象，映射到数据库的表中\n高效详细的log统计，方便开发者随时了解自己的系统\n独立jar包，不依赖其它jar包\n提供便捷的spring插件，与spring无缝集成性能相关据官方称，测试下来效率和mybatis,spring-jdbc等不相上下。\n\n代码实践\n1.新建表fruit,user_0,user_1,user_2,user_3SET NAMES utf8;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------  Table structure for `fruit`-- ----------------------------DROP TABLE IF EXISTS `fruit`;CREATE TABLE `fruit` (  `id` int(11) NOT NULL AUTO_INCREMENT,  `name` varchar(20) NOT NULL,  `num` int(11) NOT NULL,  PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;SET FOREIGN_KEY_CHECKS = 1;/*==========分割线============*/CREATE TABLE `user_0` (  `uid` int(11) NOT NULL,  `name` varchar(20) NOT NULL,  PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `user_1` (  `uid` int(11) NOT NULL,  `name` varchar(20) NOT NULL,  PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `user_2` (  `uid` int(11) NOT NULL,  `name` varchar(20) NOT NULL,  PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;CREATE TABLE `user_3` (  `uid` int(11) NOT NULL,  `name` varchar(20) NOT NULL,  PRIMARY KEY (`uid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;\n2.新建maven工程，并引入依赖。&lt;dependency&gt;     &lt;groupId&gt;junit&lt;/groupId&gt;     &lt;artifactId&gt;junit&lt;/artifactId&gt;     &lt;version&gt;3.8.1&lt;/version&gt;     &lt;scope&gt;test&lt;/scope&gt;   &lt;/dependency&gt;   &lt;dependency&gt;     &lt;groupId&gt;org.jfaster&lt;/groupId&gt;     &lt;artifactId&gt;mango&lt;/artifactId&gt;     &lt;version&gt;1.3.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt;     &lt;groupId&gt;mysql&lt;/groupId&gt;     &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;     &lt;version&gt;5.1.18&lt;/version&gt; &lt;/dependency&gt;\n3.新建操作表对应等Dao类和分表相关类。分表通常也被称为散表。 当某张表的数据量很大时，sql执行效率都会变低，这时通常会把大表拆分成多个小表，以提高sql执行效率。mango框架内部提供的8种分表策略:-整数模十分表，支持Integer或int参数类型，实现类为 IntegerModTenTablePartition-长整模十分表，支持Long或long参数类型，实现类为 LongModTenTablePartition-字符串模十分表，支持String参数类型，实现类为 StringModTenTablePartition-模十分表，支持Integer或int或Long或long或String参数类型，实现类为 ModTenTablePartition-整数模百分表，支持Integer或int参数类型，实现类为 IntegerModHundredTablePartition-长整模百分表，支持Long或long参数类型，实现类为 LongModHundredTablePartition-字符串模百分表，支持String参数类型，实现类为 StringModHundredTablePartition-模百分表，支持Integer或int或Long或long或String参数类型，实现类为 ModHundredTablePartition\n\n我们这次使用自定义分表，根据uid取模，可以分为4个分表。分表策略类通过@DB注解中的tablePartition参数传入，tablePartition参数接受任何实现了 TablePartition 接口的类，所以我们可以通过自己实现TablePartition接口，来完成任何自定义分表策略。下面是我们的自定义分表：package com.wdzj.mongo.util;import org.jfaster.mango.partition.TablePartition;/** * 整数模4分表 * @author lichaoqiang * @date 2016-06-22 * */public class ModFourTablePartition implements TablePartition&lt;Integer&gt; &#123;    public String getPartitionedTable(String table, Integer shardParam, int type) &#123;        // TODO Auto-generated method stub        return table + &quot;_&quot; + (shardParam % 4);    &#125;&#125;下面是操作数据库的DAO类，均采用注解。\npackage com.wdzj.mongo.dao;import org.jfaster.mango.annotation.DB;import org.jfaster.mango.annotation.SQL;/** * 表fruit的操作DAO,均使用注解方式来实现 * * */@DBpublic interface FruitDao &#123;     // 插入数据    @SQL(&quot;insert into fruit(name, num) values(:1, :2)&quot;)    public void add(String name, int num);     // 根据name取num的总和    @SQL(&quot;select sum(num) from fruit where name=:1&quot;)    public int getTotalNum(String name);    // 删除数据    @SQL(&quot;delete from fruit where name=:1&quot;)    public int deleteFruit(int id);&#125;//==================================package com.wdzj.mongo.dao;import org.jfaster.mango.annotation.DB;import org.jfaster.mango.annotation.SQL;import org.jfaster.mango.annotation.TableShardBy;import com.wdzj.mongo.model.User;import com.wdzj.mongo.util.ModFourTablePartition;@DB(table = &quot;user&quot;, tablePartition = ModFourTablePartition.class)public interface UserDao &#123;         @SQL(&quot;insert into #table(uid, name) values(:1, :2)&quot;)        public void addUser(@TableShardBy int uid, String name);        @SQL(&quot;select uid, name from #table where uid = :1&quot;)        public User getUser(@TableShardBy int uid);&#125;\n\n4.测试package com.wdzj.mongo.example;import org.jfaster.mango.operator.Mango;import com.wdzj.mongo.dao.FruitDao;import com.wdzj.mongo.util.MangoDBUtils;public class TestFruit &#123;    public static void main(String[] args) &#123;        // TODO Auto-generated method stub        //数据库连接方式一//            String driverClassName = &quot;com.mysql.jdbc.Driver&quot;;//            String url = &quot;jdbc:mysql://192.168.29.1:3306/mongo_demo&quot;;//            String username = &quot;root&quot;; // 这里请使用您自己的用户名//            String password = &quot;root&quot;; // 这里请使用您自己的密码//            DataSource ds = new DriverManagerDataSource(driverClassName, url, username, password);//            Mango mango = Mango.newInstance(ds); // 使用数据源初始化mango        //数据库连接方式二，自己封装好            Mango mango =MangoDBUtils.getMango();            FruitDao dao = mango.create(FruitDao.class);            String name = &quot;pear&quot;;            int num = 3;            dao.add(name, num);            System.out.println(dao.getTotalNum(name));    &#125;&#125;//＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝分表测试package com.wdzj.mongo.example;import org.jfaster.mango.operator.Mango;import com.wdzj.mongo.dao.UserDao;import com.wdzj.mongo.util.MangoDBUtils;/** * 测试分表 * */public class TestUserSplitTable &#123;    public static void main(String[] args) &#123;        // TODO Auto-generated method stub        testAddUser();        System.out.println(&quot;add user  ended................&quot;);        testGetUser();    &#125;    public static void testAddUser()&#123;          Mango mango =MangoDBUtils.getMango();          UserDao dao = mango.create(UserDao.class);          for(int i=0;i&lt;10;i++)&#123;              dao.addUser(i, &quot;张三&quot;+i);          &#125;    &#125;    public static void testGetUser()&#123;          Mango mango =MangoDBUtils.getMango();          UserDao dao = mango.create(UserDao.class);          for(int i=0;i&lt;10;i++)&#123;             System.out.println(dao.getUser(i));          &#125;    &#125;&#125;\n查看相关分表中测试的数据发现插入表是根据取模策略离散的，这个对于大量数据的表业务做分表有很大的参考意义。具体的demo代码可以在github源码上看到。还有很多有意思的功能等着去探索，后面更多实践后，再写点东西吧。\n\n","categories":["博客"],"tags":["分库","分表"]},{"title":"Packet for query is too large(1508792 > 1048576)","url":"http://leechaoqiang.github.io/2016/06/13/PacketTooBigException-Packet-for-query-is-too-large/","content":"昨天在调试一个接口的时候，由于入参的字符串太长了，然后爆了一个问题，具体的日志如下：org.springframework.dao.TransientDataAccessResourceException: \\n###Error updating database.  Cause: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (1508792 &gt; 1048576).You can change this value on the server by setting the max_allowed_packet&#x27; variable.\\n###The error may involve com.wdzj.thirdpartzx.core.dao.OrderDetailMapper.insertSelectiveAndGetId-Inline\\n###The error occurred while setting parameters\\n###SQL: insert into tb_order ( owner_id,  amount, status,  plat_id, endpoint_id,                       sid, adder,  add_time, request_info ) values ( ?, ?, ?, ?, ?, ?, ?,  ?,  ? )\\n###Cause: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (1508792 &gt; 1048576).You can change this value on the server by setting the max_allowed_packet&#x27; variable.\\n; SQL [];Packet for query is too large (1508792 &gt; 1048576).You can change this value on the server by setting the max_allowed_packet&#x27; variable.; nested exception is com.mysql.jdbc.PacketTooBigException:Packet for query is too large (1508792 &gt; 1048576).You can change this value on the server by setting the max_allowed_packet&#x27; variable.,org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:106)看到这个日志的关键词Packet for query is too large(1508792 &gt; 1048576)，看这意思貌似是传给MySQL解析器的包太大了，默认是1M大小，1048576换算下来真多是1M啊，而我们传的参数数据包的大小1508792字节，换算下大概是1.43M，超过了默认的数据包的大小，怎么解决呢？日志中已经给出了You can change this value on the server by setting the max_allowed_packet’ variable，然后我自己大胆的尝试并验证有如下解决方案：查看了下Mysql的配置文件 my.cnf，看到有一行配置max_allowed_packet = 1M ，把它修改为4M或者更多，然后重启了下Mysql服务，然后登录数据库查询了下：show VARIABLES like ‘%max_allowed_packet%’;4194304换算下来就是4M，再次试了下，原来的插入语句可以正常使用。\n","categories":["博客","问题"],"tags":["Mysql"]},{"title":"Spring 4.0.2.RELEASE和xfire1.2.6集成后出现一个奇葩问题","url":"http://leechaoqiang.github.io/2016/04/22/spring4-xfire1-2-6-integration-error-solution/","content":"最近遇到一个奇葩的问题，我们的后台Dubbo服务已经和Spring 4.0.2.RELEASE版本集成，因为需要和一个第三方服务提供方对接，而对方提供的接口是web Service的，而且使用的框架是xfire。我们的技术对接童鞋，按照对方提供的技术文档进行代码编写，在pom.xml中添加了一段依赖导入相关需要的jar包,配置如下：\n &lt;dependency&gt;    &lt;groupId&gt;org.codehaus.xfire&lt;/groupId&gt;    &lt;artifactId&gt;xfire-all&lt;/artifactId&gt;    &lt;version&gt;1.2.6&lt;/version&gt;&lt;/dependency&gt;然后当代码开发已经写得差不多了，在调试的时候就出现一个奇葩问题，老是报一个错org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 96; Document root element “beans”, must match DOCTYPE root “null”.具体的报错信息如下：sh-3.2# sh bin/startDev.shListening for transport dt_socket at address: 9555[com.alibaba.dubbo.common.logger.LoggerFactory] - using logger: com.alibaba.dubbo.common.logger.log4j.Log4jLoggerAdapter   [com.alibaba.dubbo.container.Main] -  [DUBBO] Use container type([spring]) to run dubbo serivce., dubbo version: 2.4.9, current host: 127.0.0.1   [org.springframework.beans.factory.xml.XmlBeanDefinitionReader] - Loading XML bean definitions from URL [file:/Users/lichaoqiang/wdzj/svn_new/projects/credit-thirdpartzx/trunk/target/wdzj-thirdpartzx-1.1.1-SNAPSHOT-pack/thirdpartzx/conf/dubbo/provider.xml]   org.springframework.beans.factory.BeanDefinitionStoreException: Line 5 in XML document from URL [file:/Users/lichaoqiang/wdzj/svn_new/projects/credit-thirdpartzx/trunk/target/wdzj-thirdpartzx-1.1.1-SNAPSHOT-pack/thirdpartzx/conf/dubbo/provider.xml] is invalid; nested exception is org.xml.sax.SAXParseException: Document root element &quot;beans&quot;, must match DOCTYPE root &quot;null&quot;.org.xml.sax.SAXParseException; lineNumber: 5; columnNumber: 96; Document root element &quot;beans&quot;, must match DOCTYPE root &quot;null&quot;.    at org.apache.xerces.util.ErrorHandlerWrapper.createSAXParseException(Unknown Source)    at org.apache.xerces.util.ErrorHandlerWrapper.error(Unknown Source)    at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)    at org.apache.xerces.impl.XMLErrorReporter.reportError(Unknown Source)    at org.apache.xerces.impl.dtd.XMLDTDValidator.rootElementSpecified(Unknown Source)    at org.apache.xerces.impl.dtd.XMLDTDValidator.handleStartElement(Unknown Source)    at org.apache.xerces.impl.dtd.XMLDTDValidator.startElement(Unknown Source)    at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanStartElement(Unknown Source)    at org.apache.xerces.impl.XMLDocumentScannerImpl$ContentDispatcher.scanRootElementHook(Unknown Source)    at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)    at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)    at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)    at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)    at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)    at org.apache.xerces.parsers.DOMParser.parse(Unknown Source)    at org.apache.xerces.jaxp.DocumentBuilderImpl.parse(Unknown Source)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:222)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:173)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:148)    at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:126)    at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:142)    at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:113)    at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:81)    at org.springframework.context.support.AbstractRefreshableApplicationContext.refreshBeanFactory(AbstractRefreshableApplicationContext.java:89)    at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:269)    at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:87)    at org.springframework.context.support.ClassPathXmlApplicationContext.&lt;init&gt;(ClassPathXmlApplicationContext.java:72)    at com.alibaba.dubbo.container.spring.SpringContainer.start(SpringContainer.java:50)    at com.alibaba.dubbo.container.Main.main(Main.java:80)经过查证相关资料，发现原来有一个xfire-all导入的一个jar包中依赖了一个1.2.6版本的spring的jar包，而我们的项目采用的Spring的版本就是4.0.2.RELEASE，所以就有冲突。解决办法就是把spring相关的jar包exclusion。具体的办法是修改pom.xml:&lt;dependency&gt;        &lt;groupId&gt;org.codehaus.xfire&lt;/groupId&gt;        &lt;artifactId&gt;xfire-all&lt;/artifactId&gt;        &lt;version&gt;1.2.6&lt;/version&gt;        &lt;exclusions&gt;            &lt;exclusion&gt;                &lt;artifactId&gt;xfire-spring&lt;/artifactId&gt;                &lt;groupId&gt;org.codehaus.xfire&lt;/groupId&gt;            &lt;/exclusion&gt;        &lt;/exclusions&gt;    &lt;/dependency&gt;\n","categories":["博客","问题"],"tags":["Spring","Xfire"]},{"title":"tomcat运行中途自动退出，问题查证","url":"http://leechaoqiang.github.io/2016/04/08/tomcat-run-exit-error/","content":"我们的一个tomcat 7运行应用本来在测试环境运行良好，最近突然应用就自动退出停服，有点奇怪，查看了启动（tailf -n 200 catalina.out）日志获得一段有效的日志信息：ERROR: transport error 202: bind failed: Address already in useERROR: JDWP Transport dt_socket failed to initialize, TRANSPORT_INIT(510)JDWP exit error AGENT_ERROR_TRANSPORT_INIT(197): No transports initialized [../../../src/share/back/debugInit.c:750]FATAL ERROR in native method: JDWP No transports initialized, jvmtiError=AGENT_ERROR_TRANSPORT_INIT(197)  如何解决呢？我们可以从这段日志下手分析。这段日志信息反馈是在tomcat运行时，debug时由于debug端口已经被占用，刚好我们部署该服务器上的还有另外一个tomcat应用在运行。所以，只能修改当前的tomcat的debug接口，具体的修改位置在tomcat的catalina.sh脚本中。如何\b操作如下：找到catalina.sh中如下启动\b\b\b\b\b\b\b 脚本：if [ &quot;$1&quot; = &quot;jpda&quot; ] ; then  if [ -z &quot;$JPDA_TRANSPORT&quot; ]; then    JPDA_TRANSPORT=&quot;dt_socket&quot;  fi  if [ -z &quot;$JPDA_ADDRESS&quot; ]; then    JPDA_ADDRESS=&quot;8000&quot;  fi  if [ -z &quot;$JPDA_SUSPEND&quot; ]; then    JPDA_SUSPEND=&quot;n&quot;  fi  if [ -z &quot;$JPDA_OPTS&quot; ]; then    JPDA_OPTS=&quot;-agentlib:jdwp=transport=$JPDA_TRANSPORT,address=$JPDA_ADDRESS,server=y,suspend=$JPDA_SUSPEND&quot;  fi  CATALINA_OPTS=&quot;$JPDA_OPTS $CATALINA_OPTS&quot;  shiftfi\b\b改一下address\b默认端口号8000\b\b\b，为其他空闲端口号，重启即可。\n","categories":["博客","问题"],"tags":["运维","Tomcat"]},{"title":"jenkins配置一个项目自动部署的步骤实践","url":"http://leechaoqiang.github.io/2016/04/07/jenkins-how-to-make-auto-deploy/","content":"Jenkins是一个开源软件项目，旨在提供一个开放易用的软件平台，使软件的持续集成变成可能。Jenkins是基于Java开发的一种持续集成工具，用于监控持续重复的工作，功能包括：\n\n1、持续的软件版本发布/测试项目。\n2、监控外部调用执行的工作。\n\n我们可以用Jenkins来配置一套自动编译发布项目的流程。下面我们以一个简单的例子来说明。主要有以下步骤：\n\n1 新建一个项目credit,选择构建一个Maven项目:\n\n2 进行项目的具体配置\n2.1 进入配置页面\n2.2 可以写项目描述，限定一下项目构建\n2.3 设置代码下载的SVN地址：\n2.4 可以设置每天自动定时发布，构建时是用maven的命令： -Dmaven.test.skip=true clean install package -Denv=dev\n\n\n\n\n3 自定义自动部署的shell脚本   ps:要在shell代码之前添加BUILD_ID=DONTKILLME，这样才不至于中途应用被停止，部署没完成就结束了。 脚本主要的内容包含：备份原来的包，发布新的包，重启相关的应用服务。\nBUILD_ID=DONTKILLMEcd /opt/java/front/apache-tomcat-7.0.67sh bin/shutdown.shsleep 1rm -rf webapps/front.war.bak#备份frontmv webapps/front.war webapps/front.war.bakcp -rf /jenkins/workspace/credit/credit-web/target/front.war webapps/front.warsh bin/startup.shsleep 1echo &quot;front app started......&quot;echo &quot;back app operation......&quot;cd /opt/java/back_tomcat/apache-tomcat-7.0.67sh bin/shutdown.shsleep 1rm -rf webapps/back.war.bak#备份backmv webapps/back.war webapps/back.war.bakcp -rf /jenkins/workspace/credit/credit-manager-web/target/back.war webapps/back.warsh bin/startup.shsleep 1echo &quot;back app started……&quot;\n\n\n\n  Q&amp;A:  Q:一不小心删除了相关job的配置数据后，重新配置相同名的项目的构建部署过程后，发现立即构建会报错：  java.lang.IllegalStateException: cannot create a build with number 5 since that (or higher) is already in use among [204]，那么如何解决呢？  A:可以把相关job的配置文件(/root/.jenkins/jobs/jobName/nextBuildNumber)中的值修改成报错中的值204或者更大的205。  然后重启jenkins的web部署应用tomcat。然后再进行构建即可成功。\n","categories":["博客"],"tags":["部署"]},{"title":"多并发时支付如何保持账户余额的一致性？","url":"http://leechaoqiang.github.io/2016/03/14/dispatch-pay-balance-keep-consistence/","content":"\n&nbsp;&nbsp;不管是电商，还是O2O业务都会涉及到支付，而且多速情况下流量比较大，尤其是在做活动的时候。一般支付系统主要有充值，扣费，提现，转账等功能，那么在有些业务场景下，尤其是多并发的情况下，我们在做扣费业务操作时该怎样去保持账户余额的一致呢？Java开发人员可能第一个想法就是在调用扣减的DAO的方法上加上一个synchronized关键字，这个解决办法在单节点应用部署是也许能生效管用，但是在我们实际的应用场景中，一般都是集群，多节点部署的应用，这个时候该如何解决呢？我们有一张账户表tb_account\n\n\n\nfield\ntype\ndesc\n\n\n\n\nuid\nbigint\n用户id\n\n\nbalance\ndecimal\n余额\n\n\nupdate_time\ndatetime\n表数据更新时间\n\n\n\n扣费之前，我们要先查询一下账户的余额是否足够抵扣，然后再做真正的减扣。大致的过程如下：\n\n\bselect balance from tb_account where uid=100;\n程序判断balance的值是否足够抵扣。\nupdate tb_account set balance = balance - 28.00, update_time = sysdate() where uid=100;通常情况下，这种余额判断\b方法在高并发且不加锁的情况下是非常不可靠的。所以在做扣费操作时要考虑到并发扣费的情况，允许让其并发扣费，但是不应该允许账户余额为负数。转账的话也是一样，相当于先从一个账户扣费，再给另一个账户充值，都必须要在一个事务内完成。可以使用一个存储过程来把这些步骤统一起来。下面的存储过程亲测可用。\n\ncreate procedure proc_account_balance_dec ( in_money decimal(8,2), in_uid bigint, OUT status int )  BEGIN  DECLARE from_account_balance decimal(8,2);  START TRANSACTION;  SELECT balance INTO from_account_balance FROM tb_account      WHERE uid = in_uid FOR UPDATE;  IF from_account_balance&gt;=in_money THEN       UPDATE tb_account SET balance = balance - in_money , update_time = sysdate()          WHERE uid = in_uid;      COMMIT;      SET status=1;  ELSE       ROLLBACK;      SET status=0;  END IF;  END;  \n","categories":["博客","并发"],"tags":["分布式","并发","支付"]},{"title":"Redis分布式锁Java实现","url":"http://leechaoqiang.github.io/2016/03/14/redis-distribute-lock-java/","content":"redis分布式锁可以解决多个应用进程间同步操作的一致性。网上有很多资料并不能完全解决。\n\n1.时间同步问题\n2.在一个进程crash后失效时间后自动释放锁\n3.有些多线程race condition没有考虑到\n\nJava版本的代码参考如下\npackage com.wdzj.jedis.distribution.test;import java.util.Iterator;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.concurrent.atomic.AtomicLong;import org.apache.commons.pool2.impl.GenericObjectPoolConfig;import redis.clients.jedis.Jedis;import redis.clients.jedis.JedisPool;import redis.clients.jedis.exceptions.JedisException;/** * Jedis实现分布式锁 * * @author hello * */public class JedisDistributionLock &#123;    private final static long ACCQUIRE_LOCK_TIMEOUT_IN_MS = 10 * 1000;    private final static int EXPIRE_IN_SECOND = 5;//锁失效时间    private final static long WAIT_INTERVAL_IN_MS = 100;    private final JedisPool jedisPool;    private final long acquireLocktimeoutInMS;    private final int expireInSecond;    private final long waitIntervalInMS;    private final ConcurrentMap&lt;String, String&gt; settedKeys;    public JedisDistributionLock(final JedisPool jedisPool,            final long acquireLocktimeout, final int expireInSecond,            final long waitIntervalInMS) &#123;        this.jedisPool = jedisPool;        this.acquireLocktimeoutInMS = acquireLocktimeout;        this.expireInSecond = expireInSecond;        this.waitIntervalInMS = waitIntervalInMS;        this.settedKeys = new ConcurrentHashMap&lt;String, String&gt;();    &#125;    public JedisDistributionLock(final JedisPool jedisPool) &#123;        this(jedisPool, ACCQUIRE_LOCK_TIMEOUT_IN_MS, EXPIRE_IN_SECOND,                WAIT_INTERVAL_IN_MS);    &#125;    public void lock(final String redisKey) throws Exception &#123;        validateRedisKeyName(redisKey);        Jedis resource = null;        try &#123;            resource = jedisPool.getResource();            long timeoutAt = currentTimeMillisFromRedis()                    + acquireLocktimeoutInMS;            boolean flag = false;            while (true) &#123;                String expireAt = String.valueOf(currentTimeMillisFromRedis()                        + expireInSecond * 1000);                long ret = resource.setnx(redisKey, expireAt);                if (ret == 1) &#123;                    settedKeys.put(redisKey, expireAt);                    flag = true;                    break;                &#125; else &#123;                    String oldExpireAt = resource.get(redisKey);                    if (oldExpireAt != null                            &amp;&amp; Long.parseLong(oldExpireAt) &lt; currentTimeMillisFromRedis()) &#123;                        oldExpireAt = resource.getSet(redisKey, expireAt);                        if (Long.parseLong(oldExpireAt) &lt; currentTimeMillisFromRedis()) &#123;                            settedKeys.put(redisKey, expireAt);                            flag = true;                            break;                        &#125; else &#123;                            // loop ...                        &#125;                    &#125; else &#123;                        // loop ...                    &#125;                &#125;                if (acquireLocktimeoutInMS &lt;= 0                        || timeoutAt &lt; currentTimeMillisFromRedis()) &#123;                    break;                &#125;                try &#123;                    TimeUnit.MILLISECONDS.sleep(waitIntervalInMS);                &#125; catch (Exception ignore) &#123;                &#125;            &#125;            if (!flag) &#123;                throw new RuntimeException(&quot;canot acquire lock now ...&quot;);            &#125;        &#125; catch (JedisException je) &#123;            je.printStackTrace();            if (resource != null) &#123;                jedisPool.returnBrokenResource(resource);            &#125;            throw je;        &#125; catch (Exception e) &#123;            e.printStackTrace();            throw e;        &#125; finally &#123;            if (resource != null) &#123;                jedisPool.returnResource(resource);            &#125;        &#125;    &#125;    public boolean unlock(final String name) throws Exception &#123;        validateRedisKeyName(name);        Jedis resource = null;        try &#123;            resource = jedisPool.getResource();            resource.del(name);            settedKeys.remove(name);            return true;        &#125; catch (JedisException je) &#123;            je.printStackTrace();            if (resource != null) &#123;                jedisPool.returnBrokenResource(resource);            &#125;            return false;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125; finally &#123;            if (resource != null) &#123;                jedisPool.returnResource(resource);            &#125;        &#125;    &#125;    public boolean unlockAll() throws Exception &#123;        Jedis resource = null;        try &#123;            resource = jedisPool.getResource();            Iterator&lt;String&gt; iter = settedKeys.keySet().iterator();            while (iter.hasNext()) &#123;                String key = iter.next();                resource.del(key);                settedKeys.remove(key);            &#125;            return true;        &#125; catch (JedisException je) &#123;            je.printStackTrace();            if (resource != null) &#123;                jedisPool.returnBrokenResource(resource);            &#125;            return false;        &#125; catch (Exception e) &#123;            e.printStackTrace();            return false;        &#125; finally &#123;            if (resource != null) &#123;                jedisPool.returnResource(resource);            &#125;        &#125;    &#125;    private void validateRedisKeyName(String name) &#123;        if (name == null || &quot;&quot;.equals(name.trim())) &#123;            throw new IllegalArgumentException(&quot;validateKey fail.&quot;);        &#125;    &#125;    private Long currentTimeMillisFromRedis() throws Exception &#123;        Jedis resource = null;        try &#123;            resource = jedisPool.getResource();            return Long.parseLong(resource.time().get(0)) * 1000;        &#125; catch (JedisException je) &#123;            je.printStackTrace();            if (resource != null) &#123;                jedisPool.returnBrokenResource(resource);            &#125;            throw je;        &#125; catch (Exception e) &#123;            e.printStackTrace();            throw e;        &#125; finally &#123;            if (resource != null) &#123;                jedisPool.returnResource(resource);            &#125;        &#125;    &#125;    public static void main(String[] args) throws Exception &#123;        ExecutorService executorService = Executors.newCachedThreadPool();        GenericObjectPoolConfig config = new GenericObjectPoolConfig();        config.setMaxIdle(200);        config.setMaxTotal(200);        JedisPool pool = new JedisPool(config, &quot;192.168.8.21&quot;, 6379, 3000,                &quot;########&quot;);        final JedisDistributionLock jedisDistributionLock = new JedisDistributionLock(                pool);        final int threadNum = 8;        final CountDownLatch countDownLatch = new CountDownLatch(threadNum);        final int reqsPerThread = 10;        final AtomicLong seq = new AtomicLong(0);        final String key = &quot;qq&quot;;        for (int i = 0; i &lt; threadNum; i++) &#123;            executorService.submit(new Runnable() &#123;                public void run() &#123;                    System.out.println(Thread.currentThread().getId()                            + &quot; start...&quot;);                    try &#123;                        for (int j = 0; j &lt; reqsPerThread; j++) &#123;                            jedisDistributionLock.lock(key);                            System.out.println(seq.incrementAndGet());                            jedisDistributionLock.unlock(key);                        &#125;                    &#125; catch (Exception e) &#123;                        e.printStackTrace();                    &#125; finally &#123;                        countDownLatch.countDown();                    &#125;                &#125;            &#125;);        &#125;        countDownLatch.await();        System.out.println(&quot;----------------------------&gt;&quot; + seq.longValue());        if (threadNum * reqsPerThread == seq.longValue()) &#123;            System.out.println(&quot;-------------ok-----------&quot;);        &#125; else &#123;            System.err.println(&quot;-------------err-----------&quot;);        &#125;    &#125;&#125;\n\n参考资料http://blog.csdn.net/alsocoderalsogeek/article/details/50888468http://www.cnblogs.com/wuhuajun/p/5242644.html\nhttp://www.cnblogs.com/it-cen/p/4984272.html\n","categories":["博客","并发"],"tags":["Java","分布式","多线程","Redis"]},{"title":"HashMap的遍历最优方式","url":"http://leechaoqiang.github.io/2016/02/26/HashMap-best-interator-way/","content":"HashMap的遍历最优方式建议使用entrySet()的方式,因为在数据量比较大的时候，它的效率更高。\n话不多说，请看下面的源代码public static void testEfficiency()&#123;        HashMap hmap = new HashMap();        for(int i=0;i&lt;100;i++)&#123;            hmap.put(&quot;key&quot;+i, i*10);        &#125;        System.out.println(&quot;------遍历方式1：使用entrySet----遍历key和value----------------------&quot;);        long start1 = System.currentTimeMillis();        for (Iterator it = hmap.entrySet().iterator(); it.hasNext();) &#123;            Map.Entry entry = (Map.Entry) it.next();            System.out.println(entry.getKey() + &quot;=&quot; + entry.getValue());        &#125;        long end1 = System.currentTimeMillis();        System.out.println(&quot;方式一，耗时：&quot;+(end1-start1) +&quot;ms&quot;);        System.out.println(&quot;------遍历方式2：使用keySet----遍历key和value----------------------&quot;);        long start2 = System.currentTimeMillis();        for (Iterator it = hmap.keySet().iterator(); it.hasNext();) &#123;            String key=  (String) it.next();            System.out.println(key + &quot;=&quot; + hmap.get(key));        &#125;        long end2 = System.currentTimeMillis();        System.out.println(&quot;方式二，耗时：&quot;+(end2-start2) +&quot;ms&quot;);    &#125;\n执行上面的代码后，会出现下面的结果：key79=790\nkey78=780\nkey38=380\nkey39=390\nkey34=340\nkey35=350\nkey36=360······\nkey28=280\nkey76=760\nkey27=270\nkey75=750\nkey74=740\nkey29=290\n方式一，耗时：1ms\n——遍历方式2：使用keySet—-遍历key和value———————-\nkey79=790\nkey78=780\nkey38=380\nkey39=390\nkey34=340\nkey35=350\n······key71=710\nkey26=260\nkey70=700\nkey25=250\nkey77=770\nkey28=280\nkey76=760\nkey27=270\nkey75=750\nkey74=740\nkey29=290\n方式二，耗时：2ms\n\n所以，从上面的简单的比较，可以得出当我们需要遍历HashMap的时候，使用EntrySet的遍历的方式效率更高，尤其是数据量比较大的时候，效果越明显。同步更新：HashMap的遍历最优方式\n","categories":["博客","Java"],"tags":["HashMap","Java","Map"]}]